{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-04-13T03:44:57.030033Z",
     "iopub.status.busy": "2022-04-13T03:44:57.029581Z",
     "iopub.status.idle": "2022-04-13T03:44:57.452317Z",
     "shell.execute_reply": "2022-04-13T03:44:57.451424Z",
     "shell.execute_reply.started": "2022-04-13T03:44:57.029993Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data107745\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-04-13T03:44:57.558829Z",
     "iopub.status.busy": "2022-04-13T03:44:57.557934Z",
     "iopub.status.idle": "2022-04-13T03:44:57.971945Z",
     "shell.execute_reply": "2022-04-13T03:44:57.970803Z",
     "shell.execute_reply.started": "2022-04-13T03:44:57.558781Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-04-13T03:44:59.665932Z",
     "iopub.status.busy": "2022-04-13T03:44:59.665038Z",
     "iopub.status.idle": "2022-04-13T03:45:02.776229Z",
     "shell.execute_reply": "2022-04-13T03:45:02.775366Z",
     "shell.execute_reply.started": "2022-04-13T03:44:59.665891Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"/home/aistudio/external-libraries\": 文件已存在\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting beautifulsoup4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9c/d8/909c4089dbe4ade9f9705f143c9f13f065049a9d5e7d34c828aefdd0a97c/beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7d/1e/294d3cb3fc81212914043beba5eeb38882c0b449402353c549745e823fcf/soupsieve-2.3.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.11.1 soupsieve-2.3.2\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.11.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-04-13T03:45:02.788777Z",
     "iopub.status.busy": "2022-04-13T03:45:02.788375Z",
     "iopub.status.idle": "2022-04-13T03:45:02.791869Z",
     "shell.execute_reply": "2022-04-13T03:45:02.791367Z",
     "shell.execute_reply.started": "2022-04-13T03:45:02.788744Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业内容\n",
    "完成基于PaddleX钢筋计数项目\n",
    "\n",
    "1、能够完成示例模型的训练、验证、导出模型、预测过程。30分​\n",
    "\n",
    "2、能够使用vdl展示模型精度变化过程和训练过程中数据情况。 30分​\n",
    "\n",
    "3、能够进行2-3种模型优化操作。15分​\n",
    "\n",
    "4、最终项目能够上传github。15分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、包及数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T06:45:45.537504Z",
     "iopub.status.busy": "2022-04-14T06:45:45.537009Z",
     "iopub.status.idle": "2022-04-14T06:46:21.170704Z",
     "shell.execute_reply": "2022-04-14T06:46:21.169915Z",
     "shell.execute_reply.started": "2022-04-14T06:45:45.537473Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlex==2.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6b/60/ab6735f0699d002d994fd1ed9383bf5d8ac9423da2b4e3de65581905526b/paddlex-2.0.0-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.2/944.2 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting shapely>=1.7.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9d/4d/4b0d86ed737acb29c5e627a91449470a9fb914f32640db3f1cb7ba5bc19e/Shapely-1.8.1.post1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/75/5c/ac61ea715d7a89ecc31c090753bde28810238225ca8b71778dfe3e6a68bc/pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: chardet in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (3.0.4)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (0.4.4)\n",
      "Collecting scikit-learn==0.23.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: visualdl>=2.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (2.2.3)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (4.1.1.26)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (4.27.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (1.3.0)\n",
      "Collecting lap\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (5.1.2)\n",
      "Collecting paddleslim==2.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ee/e7/c6b97eb6809d14634ae5cbf287285584045d6f8949d0b436dc64cbefbf7a/paddleslim-2.1.1-py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting motmetrics\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/45/41/b019fe934eb811b9aba9b335f852305b804b9c66f098d7e35c2bdb09d1c8/motmetrics-1.2.5-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 KB\u001b[0m \u001b[31m210.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (22.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (2.2.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.0.0) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.0.0) (0.14.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (4.0.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.0.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.1.5)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (0.8.53)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (2.24.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (0.7.1.1)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.21.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (3.14.0)\n",
      "Collecting xmltodict>=0.12.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (2.4.0)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata<4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (4.2.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (3.0.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (0.16.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.1->paddlex==2.0.0) (2019.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.1->paddlex==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (3.0.7)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.1->paddlex==2.0.0) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.1->paddlex==2.0.0) (0.18.0)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.4.10)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (0.10.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (16.7.9)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (1.25.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (41.4.0)\n",
      "Building wheels for collected packages: lap, pycocotools\n",
      "  Building wheel for lap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1593866 sha256=bc2ccb9939b7bebfb41b879b4c927866476aded497504f19b97f65665f60aa29\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/5c/d0/d2/e331d17a999666b1e2eb99743cfa1742629f9d26c55c657001\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=273805 sha256=073dc1dff35512132dfea83f07df6883316cba5b39cbd98fd09219b41cf0c379\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/c0/01/5f/670dfd20204fc9cc6bf843db4e014acb998f411922e3abc49f\n",
      "Successfully built lap pycocotools\n",
      "Installing collected packages: lap, xmltodict, threadpoolctl, shapely, scikit-learn, pycocotools, paddleslim, motmetrics, paddlex\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "Successfully installed lap-0.4.0 motmetrics-1.2.5 paddleslim-2.1.1 paddlex-2.0.0 pycocotools-2.0.4 scikit-learn-0.23.2 shapely-1.8.1.post1 threadpoolctl-3.1.0 xmltodict-0.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install paddlex==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T03:45:41.380906Z",
     "iopub.status.busy": "2022-04-13T03:45:41.380406Z",
     "iopub.status.idle": "2022-04-13T03:45:45.893449Z",
     "shell.execute_reply": "2022-04-13T03:45:45.892751Z",
     "shell.execute_reply.started": "2022-04-13T03:45:41.380880Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:136: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\n",
      "  \"Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04-13 11:45:42 MainThread @utils.py:79] WRN paddlepaddle version: 2.2.2. The dynamic graph version of PARL is under development, not fully tested and supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle's version is:2.2.2\n",
      "paddlex's version is:2.0.0\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlex as pdx\n",
    "from paddlex import transforms\n",
    "\n",
    "print('paddle\\'s version is:{}'.format(paddle.__version__))\n",
    "print('paddlex\\'s version is:{}'.format(pdx.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T03:46:19.335558Z",
     "iopub.status.busy": "2022-04-13T03:46:19.334587Z",
     "iopub.status.idle": "2022-04-13T03:46:23.491764Z",
     "shell.execute_reply": "2022-04-13T03:46:23.490713Z",
     "shell.execute_reply.started": "2022-04-13T03:46:19.335514Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/aistudio/data/data107745/dataset_reinforcing_steel_bar_counting.zip\n",
      "   creating: data/dataset_reinforcing_steel_bar_counting/\n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/.DS_Store  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/labels.txt  \n",
      "   creating: data/dataset_reinforcing_steel_bar_counting/Annotations/\n",
      "   creating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/\n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1E45CAAA.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3EA15847.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B109F092.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/EDB2FA69.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/46D2A288.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/02EDEB01.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/01D4FEFB.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/881B376F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/DCCA8144.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8654EDAC.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C7915946.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A47F943C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/BB4402AE.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F8C0AD90.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/BB917D5A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E636D4C4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/256C1DBD.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/07DD5503.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9F1740D8.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F1477D62.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/99E783B2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/603CC53F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/679C0C8D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/570D8DA2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/BA9F0F0D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/13641B22.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/D2B83E2C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C3FCD4A6.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/D0D2EED9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/CCB5DBEF.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/6000BA04.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/EAAB35B1.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C03D16D6.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/94DD9B86.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/97652B3F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4CF58401.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0E8C93E4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/6DA0B6D4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/.DS_Store  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F2011360.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C2871199.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3ABBD9FD.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B3C96BEB.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3C398D0A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/7B5B8E84.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4718DA7F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F5164D4F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9446D773.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/CCF6E9EE.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/98D5984B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3BF8EE47.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/ACEA2A10.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C911FE0A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1DFCCF4B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1E0FA40B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A6F01C78.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1E5FB1FF.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/AC90DBBB.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9CC98D4D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/03CF22F1.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/550E6EB2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/DFE17F7D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/ABB2195A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2338148B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E42F504E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4976E3AB.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/162EF44D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/AD351F54.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1F68F120.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/000C7C0E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E646C7E9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2798F642.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/41B2160E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/5858D941.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3EB92931.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8777E599.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E802A308.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F5501E38.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/85295B74.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0B4F3CC3.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/65E9CDC8.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8509E501.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8ADCAE58.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/7EBD1524.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/038D7000.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/6B898244.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/727C2F0F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/147DAD30.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/5A589275.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8EF392EA.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/92AB4085.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0BFB817C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3A73D147.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C211CFD4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F6E0119D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C99C4D23.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/20CC2D44.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C2A82415.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A48928D0.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/738E01F9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/62167111.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/D6378505.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B3DF643D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/5BCDAEB8.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/D4C4E4DB.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/67B4B0A2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F0779891.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/04BD494B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/BB32A6B9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/5A7370CF.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A3EEA8A1.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C374F841.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2FDC9E0E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/AEF131E0.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/6D51E30D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/DBA90206.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1688B30E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/EB8ECF1A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/DB8345F7.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F5129F56.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/18C1A02C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/6B91D242.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/92A107D5.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/D8146090.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/52575287.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2C1FC077.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/34AEBFA3.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E8A7BB7D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B4EEFB95.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/CE4841E1.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3F343E06.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0C7CB7B9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/38ED68D2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0631BF82.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9EA71EB4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C85E0C57.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/5C94381A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A8658634.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/982B1C73.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3D218F21.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/296A3EA4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E46D744F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/353E85DF.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8A057EB9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/49AD1015.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A49FFA35.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4B145787.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/898E0058.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/95D0521E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A6EE237B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C969355E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F4CDD578.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/EFE77AB2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/ED64EFB9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8DF7800C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/469EB470.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/AFD1AE2E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/08F7E2BB.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/638FA776.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/09B27635.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/D4E8F388.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/5BE19523.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9D496EBE.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/DEBA2239.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/FE4C5D3F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8DE6C059.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F8656E74.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C378D66B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2A35EC79.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/88292AF2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/60639D0F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0009496A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F2179DD4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8702EAB5.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/7099AEF0.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F6309AF1.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0EDF9500.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9F1F4BE9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C32AC471.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8DA1B939.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B9E60B56.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E6D7C4C8.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/BF5A2B05.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8D9FAC03.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/6F76366B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/35346247.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0EAC74AF.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/66D2893E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C06245D1.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/BD968624.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/FAC06BA2.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/840B846E.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/574E9C80.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4463FA64.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2723542B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0EED02C3.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/DD6C6F82.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4FA1275D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/452A534A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/926A4C0C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/474BD568.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A1A37A49.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1594D4CC.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B943B927.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/E05ABCF0.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/EAC26CCD.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1B82FF85.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9538AC60.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/36A7E5D4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8E24C2B6.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/554F4CE0.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/DF9DBCB9.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8BD7A993.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8128955A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/046F4967.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C39C9B97.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/02B90DB7.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4BC3FA29.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/41CF3100.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/F766C97D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2E15279D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/7E0BEC70.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/54CE2153.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2A7090FC.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3794BD4B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/CD496125.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9BC2B7EC.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/C1F90358.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/408EAD06.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/52CC0B19.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/2E197EF1.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9D46BC0C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/08923C9F.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/4D3BE5D5.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/FCE7645C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/21B83F9D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/9D66CF7D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/8343D02C.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B7DC39A4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/0492570A.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/3BA38AEA.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/57CC2B0B.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/B905D0AB.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/CC61344D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/A2A2E11D.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/BFC85CA0.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/7421D3CD.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1EFC66A0.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/88C4F6E4.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/720333BC.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/Annotations/1099EFCE.xml  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1E45CAAA.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3EA15847.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B109F092.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/01D4FEFB.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/02EDEB01.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/46D2A288.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/EDB2FA69.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/881B376F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/DCCA8144.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/BB4402AE.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A47F943C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C7915946.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8654EDAC.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F8C0AD90.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E636D4C4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/BB917D5A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/256C1DBD.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F1477D62.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9F1740D8.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/07DD5503.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/99E783B2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/603CC53F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/679C0C8D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/570D8DA2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/13641B22.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/BA9F0F0D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/CCB5DBEF.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/D0D2EED9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C3FCD4A6.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/D2B83E2C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/94DD9B86.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C03D16D6.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/6000BA04.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/EAAB35B1.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/6DA0B6D4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4CF58401.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0E8C93E4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/97652B3F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C2871199.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F2011360.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B3C96BEB.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3ABBD9FD.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4718DA7F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/7B5B8E84.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3C398D0A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3BF8EE47.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/ACEA2A10.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C911FE0A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/CCF6E9EE.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/98D5984B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F5164D4F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9446D773.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1E0FA40B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1DFCCF4B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1E5FB1FF.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/AC90DBBB.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A6F01C78.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9CC98D4D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/550E6EB2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/03CF22F1.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/ABB2195A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2338148B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/DFE17F7D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E42F504E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4976E3AB.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/162EF44D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/AD351F54.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1F68F120.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/000C7C0E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E646C7E9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3EB92931.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/41B2160E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/5858D941.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2798F642.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8777E599.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/85295B74.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F5501E38.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E802A308.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/7EBD1524.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8509E501.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8ADCAE58.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0B4F3CC3.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/65E9CDC8.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/6B898244.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/038D7000.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/727C2F0F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8EF392EA.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/92AB4085.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/5A589275.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/147DAD30.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0BFB817C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C211CFD4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3A73D147.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/20CC2D44.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C99C4D23.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F6E0119D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C2A82415.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A48928D0.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/62167111.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/738E01F9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/D6378505.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B3DF643D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/5BCDAEB8.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/67B4B0A2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/D4C4E4DB.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/5A7370CF.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/BB32A6B9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/04BD494B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F0779891.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C374F841.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A3EEA8A1.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2FDC9E0E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/AEF131E0.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1688B30E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/EB8ECF1A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/6D51E30D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/DBA90206.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/DB8345F7.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/6B91D242.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/18C1A02C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F5129F56.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/92A107D5.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/52575287.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/D8146090.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2C1FC077.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/34AEBFA3.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E8A7BB7D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/CE4841E1.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B4EEFB95.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3F343E06.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0C7CB7B9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/5C94381A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A8658634.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/982B1C73.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9EA71EB4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C85E0C57.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0631BF82.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/38ED68D2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E46D744F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/353E85DF.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/296A3EA4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3D218F21.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/49AD1015.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8A057EB9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/898E0058.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4B145787.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A49FFA35.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/95D0521E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A6EE237B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/ED64EFB9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/EFE77AB2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C969355E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F4CDD578.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/AFD1AE2E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/469EB470.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8DF7800C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/638FA776.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/09B27635.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/08F7E2BB.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/DEBA2239.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9D496EBE.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/5BE19523.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/D4E8F388.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F8656E74.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/FE4C5D3F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8DE6C059.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C378D66B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/88292AF2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2A35EC79.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F2179DD4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0009496A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/60639D0F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8702EAB5.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F6309AF1.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/7099AEF0.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C32AC471.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8DA1B939.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9F1F4BE9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0EDF9500.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B9E60B56.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E6D7C4C8.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/BF5A2B05.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/6F76366B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8D9FAC03.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/35346247.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/66D2893E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0EAC74AF.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/574E9C80.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/840B846E.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/FAC06BA2.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/BD968624.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C06245D1.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4463FA64.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2723542B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0EED02C3.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4FA1275D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/DD6C6F82.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/926A4C0C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/452A534A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/474BD568.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9538AC60.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/EAC26CCD.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1B82FF85.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1594D4CC.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/E05ABCF0.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B943B927.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A1A37A49.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/554F4CE0.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8E24C2B6.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/36A7E5D4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/DF9DBCB9.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/046F4967.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/02B90DB7.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C39C9B97.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8BD7A993.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8128955A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4BC3FA29.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/7E0BEC70.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2E15279D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/41CF3100.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/F766C97D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2A7090FC.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/54CE2153.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/C1F90358.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9BC2B7EC.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3794BD4B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/CD496125.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/2E197EF1.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/408EAD06.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/52CC0B19.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/08923C9F.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9D46BC0C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/9D66CF7D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/8343D02C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/FCE7645C.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/21B83F9D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/4D3BE5D5.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B7DC39A4.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/0492570A.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/3BA38AEA.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/57CC2B0B.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/CC61344D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/B905D0AB.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/A2A2E11D.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/7421D3CD.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/BFC85CA0.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/720333BC.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1099EFCE.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/1EFC66A0.jpg  \n",
      "  inflating: data/dataset_reinforcing_steel_bar_counting/JPEGImages/88C4F6E4.jpg  \n"
     ]
    }
   ],
   "source": [
    "! unzip /home/aistudio/data/data107745/dataset_reinforcing_steel_bar_counting.zip -d data/\n",
    "!mv data/dataset_reinforcing_steel_bar_counting/ data/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T04:00:55.903271Z",
     "iopub.status.busy": "2022-04-13T04:00:55.902641Z",
     "iopub.status.idle": "2022-04-13T04:00:55.907385Z",
     "shell.execute_reply": "2022-04-13T04:00:55.906692Z",
     "shell.execute_reply.started": "2022-04-13T04:00:55.903233Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T04:01:17.760483Z",
     "iopub.status.busy": "2022-04-13T04:01:17.759866Z",
     "iopub.status.idle": "2022-04-13T04:01:23.128827Z",
     "shell.execute_reply": "2022-04-13T04:01:23.127982Z",
     "shell.execute_reply.started": "2022-04-13T04:01:17.760447Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:136: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\n",
      "  \"Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\"\n",
      "[04-13 12:01:19 MainThread @logger.py:242] Argv: /opt/conda/envs/python35-paddle120-env/bin/paddlex --split_dataset --format VOC --dataset_dir ./data/dataset/ --val_value 0.2 --test_value 0.1\n",
      "[04-13 12:01:19 MainThread @utils.py:79] WRN paddlepaddle version: 2.2.2. The dynamic graph version of PARL is under development, not fully tested and supported\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "2022-04-13 12:01:21 [INFO]\tDataset split starts...\n",
      "2022-04-13 12:01:22 [INFO]\tDataset split done.\n",
      "2022-04-13 12:01:22 [INFO]\tTrain samples: 175\n",
      "2022-04-13 12:01:22 [INFO]\tEval samples: 50\n",
      "2022-04-13 12:01:22 [INFO]\tTest samples: 25\n",
      "2022-04-13 12:01:22 [INFO]\tSplit files saved in ./data/dataset/\n"
     ]
    }
   ],
   "source": [
    "!paddlex --split_dataset --format VOC --dataset_dir ./data/dataset/ --val_value 0.2 --test_value 0.1\n",
    "# --split_dataset --format VOC --dataset_dir /home/aistudio/data/dataset/--val_value 0.2 --test_value 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T04:01:55.568334Z",
     "iopub.status.busy": "2022-04-13T04:01:55.567518Z",
     "iopub.status.idle": "2022-04-13T04:02:08.137612Z",
     "shell.execute_reply": "2022-04-13T04:02:08.137008Z",
     "shell.execute_reply.started": "2022-04-13T04:01:55.568298Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:01:55 [INFO]\tStarting to read file list from dataset...\n",
      "2022-04-13 12:02:05 [INFO]\t175 samples in file data/dataset/train_list.txt, including 175 positive samples and 0 negative samples.\n",
      "creating index...\n",
      "index created!\n",
      "2022-04-13 12:02:05 [INFO]\tStarting to read file list from dataset...\n",
      "2022-04-13 12:02:08 [INFO]\t50 samples in file data/dataset/val_list.txt, including 50 positive samples and 0 negative samples.\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# 定义训练和验证时的transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.MixupImage(mixup_epoch=-1),\n",
    "    transforms.RandomDistort(),\n",
    "    transforms.RandomExpand(),\n",
    "    transforms.RandomCrop(),\n",
    "    transforms.Resize(\n",
    "        target_size=480, interp='RANDOM'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize(\n",
    "        target_size=480, interp='CUBIC'),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "# 定义训练集与验证集\n",
    "train_dataset =  pdx.datasets.VOCDetection(\n",
    "    data_dir='data/dataset',\n",
    "    file_list='data/dataset/train_list.txt',\n",
    "    label_list='data/dataset/labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataset = pdx.datasets.VOCDetection(\n",
    "    data_dir='data/dataset',\n",
    "    file_list='data/dataset/val_list.txt',\n",
    "    label_list='data/dataset/labels.txt',\n",
    "    transforms=eval_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T04:03:13.915063Z",
     "iopub.status.busy": "2022-04-13T04:03:13.914310Z",
     "iopub.status.idle": "2022-04-13T04:13:51.759940Z",
     "shell.execute_reply": "2022-04-13T04:13:51.759180Z",
     "shell.execute_reply.started": "2022-04-13T04:03:13.915031Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0413 12:03:13.918869   259 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0413 12:03:13.923177   259 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:03:15 [INFO]\tDownloading yolov3_mobilenet_v1_270e_coco.pdparams from https://paddledet.bj.bcebos.com/models/yolov3_mobilenet_v1_270e_coco.pdparams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144694/144694 [00:06<00:00, 23062.61KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:03:22 [INFO]\tLoading pretrained model from output/yolov3_mobilnetv1/pretrain/yolov3_mobilenet_v1_270e_coco.pdparams\n",
      "2022-04-13 12:03:22 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.0.weight doesn't match.(Pretrained: [255, 1024, 1, 1], Actual: [18, 1024, 1, 1])\n",
      "2022-04-13 12:03:22 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.0.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-04-13 12:03:22 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.1.weight doesn't match.(Pretrained: [255, 512, 1, 1], Actual: [18, 512, 1, 1])\n",
      "2022-04-13 12:03:22 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.1.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-04-13 12:03:22 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.2.weight doesn't match.(Pretrained: [255, 256, 1, 1], Actual: [18, 256, 1, 1])\n",
      "2022-04-13 12:03:22 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.2.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-04-13 12:03:23 [INFO]\tThere are 235/241 variables loaded into YOLOv3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:03:39 [INFO]\t[TRAIN] Epoch=1/5, Step=10/87, loss_xy=139.010849, loss_wh=137.453949, loss_obj=4386.095703, loss_cls=47.718910, loss=4710.279297, lr=0.000001, time_each_step=1.61s, eta=0:12:5\n",
      "2022-04-13 12:03:54 [INFO]\t[TRAIN] Epoch=1/5, Step=20/87, loss_xy=465.246948, loss_wh=361.894684, loss_obj=1397.493042, loss_cls=88.815956, loss=2313.450684, lr=0.000002, time_each_step=1.46s, eta=0:10:42\n",
      "2022-04-13 12:04:07 [INFO]\t[TRAIN] Epoch=1/5, Step=30/87, loss_xy=356.114807, loss_wh=242.786530, loss_obj=852.341980, loss_cls=108.470322, loss=1559.713745, lr=0.000003, time_each_step=1.32s, eta=0:9:26\n",
      "2022-04-13 12:04:21 [INFO]\t[TRAIN] Epoch=1/5, Step=40/87, loss_xy=379.867645, loss_wh=153.961029, loss_obj=726.686340, loss_cls=47.346283, loss=1307.861328, lr=0.000004, time_each_step=1.45s, eta=0:10:8\n",
      "2022-04-13 12:04:33 [INFO]\t[TRAIN] Epoch=1/5, Step=50/87, loss_xy=487.615265, loss_wh=210.267410, loss_obj=907.480591, loss_cls=76.548706, loss=1681.911987, lr=0.000005, time_each_step=1.19s, eta=0:8:9\n",
      "2022-04-13 12:04:50 [INFO]\t[TRAIN] Epoch=1/5, Step=60/87, loss_xy=352.104523, loss_wh=119.572952, loss_obj=546.336975, loss_cls=48.473259, loss=1066.487671, lr=0.000006, time_each_step=1.68s, eta=0:11:11\n",
      "2022-04-13 12:05:02 [INFO]\t[TRAIN] Epoch=1/5, Step=70/87, loss_xy=200.234665, loss_wh=78.663689, loss_obj=348.386902, loss_cls=23.351852, loss=650.637146, lr=0.000007, time_each_step=1.24s, eta=0:8:4\n",
      "2022-04-13 12:05:17 [INFO]\t[TRAIN] Epoch=1/5, Step=80/87, loss_xy=348.770905, loss_wh=86.593338, loss_obj=375.049133, loss_cls=26.825933, loss=837.239319, lr=0.000008, time_each_step=1.49s, eta=0:9:26\n",
      "2022-04-13 12:05:27 [INFO]\t[TRAIN] Epoch 1 finished, loss_xy=309.0139, loss_wh=173.54349, loss_obj=1509.2283, loss_cls=55.360077, loss=2047.1459 .\n",
      "2022-04-13 12:05:32 [INFO]\t[TRAIN] Epoch=2/5, Step=3/87, loss_xy=423.132263, loss_wh=111.321434, loss_obj=531.842468, loss_cls=32.343449, loss=1098.639648, lr=0.000009, time_each_step=1.42s, eta=0:8:46\n",
      "2022-04-13 12:05:46 [INFO]\t[TRAIN] Epoch=2/5, Step=13/87, loss_xy=192.831039, loss_wh=74.576813, loss_obj=290.239624, loss_cls=17.541637, loss=575.189087, lr=0.000010, time_each_step=1.47s, eta=0:8:47\n",
      "2022-04-13 12:06:01 [INFO]\t[TRAIN] Epoch=2/5, Step=23/87, loss_xy=296.484955, loss_wh=102.202766, loss_obj=259.146515, loss_cls=16.370121, loss=674.204346, lr=0.000011, time_each_step=1.51s, eta=0:8:50\n",
      "2022-04-13 12:06:15 [INFO]\t[TRAIN] Epoch=2/5, Step=33/87, loss_xy=218.539612, loss_wh=65.067642, loss_obj=260.421997, loss_cls=16.028362, loss=560.057617, lr=0.000012, time_each_step=1.32s, eta=0:7:28\n",
      "2022-04-13 12:06:29 [INFO]\t[TRAIN] Epoch=2/5, Step=43/87, loss_xy=213.242798, loss_wh=70.434990, loss_obj=236.202484, loss_cls=11.857431, loss=531.737671, lr=0.000013, time_each_step=1.42s, eta=0:7:47\n",
      "2022-04-13 12:06:45 [INFO]\t[TRAIN] Epoch=2/5, Step=53/87, loss_xy=212.232452, loss_wh=96.958305, loss_obj=240.263214, loss_cls=13.158521, loss=562.612488, lr=0.000014, time_each_step=1.61s, eta=0:8:34\n",
      "2022-04-13 12:06:56 [INFO]\t[TRAIN] Epoch=2/5, Step=63/87, loss_xy=384.919708, loss_wh=113.517281, loss_obj=380.897247, loss_cls=21.588696, loss=900.922913, lr=0.000015, time_each_step=1.15s, eta=0:5:56\n",
      "2022-04-13 12:07:14 [INFO]\t[TRAIN] Epoch=2/5, Step=73/87, loss_xy=317.243835, loss_wh=190.985840, loss_obj=322.779083, loss_cls=17.848469, loss=848.857239, lr=0.000016, time_each_step=1.76s, eta=0:8:48\n",
      "2022-04-13 12:07:29 [INFO]\t[TRAIN] Epoch=2/5, Step=83/87, loss_xy=291.715698, loss_wh=62.506363, loss_obj=182.745605, loss_cls=16.865412, loss=553.833069, lr=0.000017, time_each_step=1.53s, eta=0:7:24\n",
      "2022-04-13 12:07:35 [INFO]\t[TRAIN] Epoch 2 finished, loss_xy=272.73895, loss_wh=94.42502, loss_obj=289.88037, loss_cls=17.216814, loss=674.26117 .\n",
      "2022-04-13 12:07:45 [INFO]\t[TRAIN] Epoch=3/5, Step=6/87, loss_xy=373.629120, loss_wh=245.844864, loss_obj=288.956940, loss_cls=20.559704, loss=928.990601, lr=0.000018, time_each_step=1.51s, eta=0:7:3\n",
      "2022-04-13 12:07:59 [INFO]\t[TRAIN] Epoch=3/5, Step=16/87, loss_xy=409.702118, loss_wh=130.900497, loss_obj=493.541077, loss_cls=23.703043, loss=1057.846680, lr=0.000019, time_each_step=1.45s, eta=0:6:32\n",
      "2022-04-13 12:08:13 [INFO]\t[TRAIN] Epoch=3/5, Step=26/87, loss_xy=242.169312, loss_wh=105.225113, loss_obj=136.352203, loss_cls=11.937515, loss=495.684143, lr=0.000020, time_each_step=1.35s, eta=0:5:50\n",
      "2022-04-13 12:08:31 [INFO]\t[TRAIN] Epoch=3/5, Step=36/87, loss_xy=260.551910, loss_wh=104.481216, loss_obj=260.308716, loss_cls=16.311050, loss=641.652893, lr=0.000021, time_each_step=1.84s, eta=0:7:39\n",
      "2022-04-13 12:08:44 [INFO]\t[TRAIN] Epoch=3/5, Step=46/87, loss_xy=355.923706, loss_wh=104.446793, loss_obj=294.654816, loss_cls=20.662636, loss=775.687927, lr=0.000022, time_each_step=1.29s, eta=0:5:10\n",
      "2022-04-13 12:08:57 [INFO]\t[TRAIN] Epoch=3/5, Step=56/87, loss_xy=220.792328, loss_wh=78.908737, loss_obj=276.084290, loss_cls=11.922426, loss=587.707764, lr=0.000023, time_each_step=1.31s, eta=0:5:0\n",
      "2022-04-13 12:09:10 [INFO]\t[TRAIN] Epoch=3/5, Step=66/87, loss_xy=264.889618, loss_wh=74.628616, loss_obj=277.202789, loss_cls=15.188831, loss=631.909912, lr=0.000024, time_each_step=1.29s, eta=0:4:43\n",
      "2022-04-13 12:09:22 [INFO]\t[TRAIN] Epoch=3/5, Step=76/87, loss_xy=280.143433, loss_wh=139.397949, loss_obj=246.316772, loss_cls=17.401949, loss=683.260132, lr=0.000025, time_each_step=1.16s, eta=0:4:4\n",
      "2022-04-13 12:09:37 [INFO]\t[TRAIN] Epoch=3/5, Step=86/87, loss_xy=280.954651, loss_wh=61.251869, loss_obj=284.844604, loss_cls=16.159880, loss=643.210999, lr=0.000026, time_each_step=1.51s, eta=0:5:2\n",
      "2022-04-13 12:09:38 [INFO]\t[TRAIN] Epoch 3 finished, loss_xy=272.01324, loss_wh=100.8584, loss_obj=289.01764, loss_cls=15.684347, loss=677.5736 .\n",
      "2022-04-13 12:09:52 [INFO]\t[TRAIN] Epoch=4/5, Step=9/87, loss_xy=422.324585, loss_wh=112.082474, loss_obj=264.108215, loss_cls=22.004528, loss=820.519775, lr=0.000027, time_each_step=1.51s, eta=0:4:47\n",
      "2022-04-13 12:10:05 [INFO]\t[TRAIN] Epoch=4/5, Step=19/87, loss_xy=283.035492, loss_wh=77.085190, loss_obj=259.589874, loss_cls=15.026015, loss=634.736572, lr=0.000028, time_each_step=1.35s, eta=0:4:2\n",
      "2022-04-13 12:10:20 [INFO]\t[TRAIN] Epoch=4/5, Step=29/87, loss_xy=182.365692, loss_wh=60.655434, loss_obj=174.320267, loss_cls=9.553396, loss=426.894775, lr=0.000029, time_each_step=1.41s, eta=0:4:0\n",
      "2022-04-13 12:10:32 [INFO]\t[TRAIN] Epoch=4/5, Step=39/87, loss_xy=335.011169, loss_wh=157.280701, loss_obj=306.493469, loss_cls=16.697229, loss=815.482544, lr=0.000030, time_each_step=1.27s, eta=0:3:22\n",
      "2022-04-13 12:10:45 [INFO]\t[TRAIN] Epoch=4/5, Step=49/87, loss_xy=226.385178, loss_wh=76.608597, loss_obj=238.374420, loss_cls=12.038580, loss=553.406738, lr=0.000031, time_each_step=1.28s, eta=0:3:11\n",
      "2022-04-13 12:11:01 [INFO]\t[TRAIN] Epoch=4/5, Step=59/87, loss_xy=128.478165, loss_wh=94.007225, loss_obj=134.756714, loss_cls=6.790397, loss=364.032501, lr=0.000032, time_each_step=1.63s, eta=0:3:48\n",
      "2022-04-13 12:11:16 [INFO]\t[TRAIN] Epoch=4/5, Step=69/87, loss_xy=336.779083, loss_wh=79.276947, loss_obj=366.868317, loss_cls=17.853428, loss=800.777771, lr=0.000033, time_each_step=1.43s, eta=0:3:6\n",
      "2022-04-13 12:11:28 [INFO]\t[TRAIN] Epoch=4/5, Step=79/87, loss_xy=270.715271, loss_wh=72.288246, loss_obj=234.002838, loss_cls=14.398955, loss=591.405273, lr=0.000034, time_each_step=1.27s, eta=0:2:32\n",
      "2022-04-13 12:11:39 [INFO]\t[TRAIN] Epoch 4 finished, loss_xy=253.41171, loss_wh=86.581764, loss_obj=261.3285, loss_cls=13.758594, loss=615.08057 .\n",
      "2022-04-13 12:11:41 [INFO]\t[TRAIN] Epoch=5/5, Step=2/87, loss_xy=362.781403, loss_wh=132.827728, loss_obj=578.113220, loss_cls=21.052580, loss=1094.775024, lr=0.000035, time_each_step=1.29s, eta=0:2:22\n",
      "2022-04-13 12:11:56 [INFO]\t[TRAIN] Epoch=5/5, Step=12/87, loss_xy=196.311554, loss_wh=92.374870, loss_obj=215.941177, loss_cls=10.934185, loss=515.561829, lr=0.000036, time_each_step=1.48s, eta=0:2:28\n",
      "2022-04-13 12:12:11 [INFO]\t[TRAIN] Epoch=5/5, Step=22/87, loss_xy=374.079834, loss_wh=116.055069, loss_obj=403.222504, loss_cls=20.806200, loss=914.163635, lr=0.000037, time_each_step=1.48s, eta=0:2:12\n",
      "2022-04-13 12:12:24 [INFO]\t[TRAIN] Epoch=5/5, Step=32/87, loss_xy=157.400711, loss_wh=53.366245, loss_obj=188.120331, loss_cls=9.379909, loss=408.267181, lr=0.000038, time_each_step=1.32s, eta=0:1:45\n",
      "2022-04-13 12:12:40 [INFO]\t[TRAIN] Epoch=5/5, Step=42/87, loss_xy=167.817551, loss_wh=43.999832, loss_obj=292.781128, loss_cls=11.305068, loss=515.903564, lr=0.000039, time_each_step=1.58s, eta=0:1:50\n",
      "2022-04-13 12:12:53 [INFO]\t[TRAIN] Epoch=5/5, Step=52/87, loss_xy=213.672882, loss_wh=41.194328, loss_obj=230.539047, loss_cls=12.003977, loss=497.410217, lr=0.000040, time_each_step=1.33s, eta=0:1:19\n",
      "2022-04-13 12:13:07 [INFO]\t[TRAIN] Epoch=5/5, Step=62/87, loss_xy=259.776703, loss_wh=55.769520, loss_obj=223.242432, loss_cls=13.698264, loss=552.486938, lr=0.000041, time_each_step=1.4s, eta=0:1:10\n",
      "2022-04-13 12:13:22 [INFO]\t[TRAIN] Epoch=5/5, Step=72/87, loss_xy=163.144424, loss_wh=97.210007, loss_obj=149.835968, loss_cls=8.336451, loss=418.526855, lr=0.000042, time_each_step=1.51s, eta=0:1:0\n",
      "2022-04-13 12:13:36 [INFO]\t[TRAIN] Epoch=5/5, Step=82/87, loss_xy=205.130081, loss_wh=110.298927, loss_obj=171.456131, loss_cls=10.523911, loss=497.409058, lr=0.000043, time_each_step=1.38s, eta=0:0:41\n",
      "2022-04-13 12:13:44 [INFO]\t[TRAIN] Epoch 5 finished, loss_xy=261.28256, loss_wh=96.4639, loss_obj=246.76659, loss_cls=14.500949, loss=619.0139 .\n",
      "2022-04-13 12:13:44 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 12:13:45 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 12:13:50 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 12:13:50 [INFO]\t[EVAL] Finished, Epoch=5, bbox_map=63.522439 .\n",
      "2022-04-13 12:13:51 [INFO]\tModel saved in output/yolov3_mobilnetv1/best_model.\n",
      "2022-04-13 12:13:51 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=63.52243858074053\n",
      "2022-04-13 12:13:51 [INFO]\tModel saved in output/yolov3_mobilnetv1/epoch_5.\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.labels)\n",
    "model = pdx.det.YOLOv3(num_classes=num_classes, backbone='MobileNetV1', label_smooth=True, ignore_threshold=0.7)\n",
    "model.train(\n",
    "    num_epochs=5,                     \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=eval_dataset,           \n",
    "    train_batch_size=2,                  \n",
    "    pretrain_weights='COCO',             \n",
    "    learning_rate=0.0001,   \n",
    "    warmup_steps=1000,                   \n",
    "    warmup_start_lr=0.0,                                         \n",
    "    save_interval_epochs=5,              \n",
    "    lr_decay_epochs=[210, 240],          \n",
    "    save_dir='output/yolov3_mobilnetv1', \n",
    "    use_vdl=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T04:13:51.825175Z",
     "iopub.status.busy": "2022-04-13T04:13:51.824917Z",
     "iopub.status.idle": "2022-04-13T07:46:48.310268Z",
     "shell.execute_reply": "2022-04-13T07:46:48.309544Z",
     "shell.execute_reply.started": "2022-04-13T04:13:51.825150Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:13:51 [INFO]\tDownloading yolov3_darknet53_270e_coco.pdparams from https://paddledet.bj.bcebos.com/models/yolov3_darknet53_270e_coco.pdparams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242236/242236 [00:06<00:00, 39558.49KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 12:13:58 [INFO]\tLoading pretrained model from output/yolov3_DarkNet53/pretrain/yolov3_darknet53_270e_coco.pdparams\n",
      "2022-04-13 12:13:58 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.0.weight doesn't match.(Pretrained: [255, 1024, 1, 1], Actual: [18, 1024, 1, 1])\n",
      "2022-04-13 12:13:58 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.0.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-04-13 12:13:58 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.1.weight doesn't match.(Pretrained: [255, 512, 1, 1], Actual: [18, 512, 1, 1])\n",
      "2022-04-13 12:13:58 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.1.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-04-13 12:13:58 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.2.weight doesn't match.(Pretrained: [255, 256, 1, 1], Actual: [18, 256, 1, 1])\n",
      "2022-04-13 12:13:58 [WARNING]\t[SKIP] Shape of pretrained params yolo_head.yolo_output.2.bias doesn't match.(Pretrained: [255], Actual: [18])\n",
      "2022-04-13 12:13:58 [INFO]\tThere are 360/366 variables loaded into YOLOv3.\n",
      "2022-04-13 12:14:15 [INFO]\t[TRAIN] Epoch=1/100, Step=10/87, loss_xy=315.299591, loss_wh=179.007507, loss_obj=708.037720, loss_cls=45.635464, loss=1247.980347, lr=0.000009, time_each_step=1.65s, eta=4:0:10\n",
      "2022-04-13 12:14:28 [INFO]\t[TRAIN] Epoch=1/100, Step=20/87, loss_xy=411.989655, loss_wh=176.580566, loss_obj=451.641022, loss_cls=44.620556, loss=1084.831787, lr=0.000019, time_each_step=1.32s, eta=3:11:23\n",
      "2022-04-13 12:14:42 [INFO]\t[TRAIN] Epoch=1/100, Step=30/87, loss_xy=465.580261, loss_wh=199.111694, loss_obj=732.092773, loss_cls=44.743736, loss=1441.528442, lr=0.000029, time_each_step=1.43s, eta=3:27:6\n",
      "2022-04-13 12:14:57 [INFO]\t[TRAIN] Epoch=1/100, Step=40/87, loss_xy=233.127274, loss_wh=135.024109, loss_obj=235.494461, loss_cls=17.012299, loss=620.658081, lr=0.000039, time_each_step=1.49s, eta=3:35:32\n",
      "2022-04-13 12:15:12 [INFO]\t[TRAIN] Epoch=1/100, Step=50/87, loss_xy=240.206665, loss_wh=288.935425, loss_obj=168.849304, loss_cls=12.804170, loss=710.795593, lr=0.000049, time_each_step=1.51s, eta=3:37:44\n",
      "2022-04-13 12:15:25 [INFO]\t[TRAIN] Epoch=1/100, Step=60/87, loss_xy=274.834259, loss_wh=63.936539, loss_obj=408.539337, loss_cls=26.240421, loss=773.550598, lr=0.000059, time_each_step=1.22s, eta=2:56:52\n",
      "2022-04-13 12:15:39 [INFO]\t[TRAIN] Epoch=1/100, Step=70/87, loss_xy=137.972458, loss_wh=69.805252, loss_obj=434.156464, loss_cls=14.981941, loss=656.916138, lr=0.000069, time_each_step=1.48s, eta=3:32:57\n",
      "2022-04-13 12:15:56 [INFO]\t[TRAIN] Epoch=1/100, Step=80/87, loss_xy=393.688812, loss_wh=151.158661, loss_obj=569.708130, loss_cls=23.172327, loss=1137.728027, lr=0.000079, time_each_step=1.62s, eta=3:53:47\n",
      "2022-04-13 12:16:05 [INFO]\t[TRAIN] Epoch 1 finished, loss_xy=297.95206, loss_wh=179.62376, loss_obj=910.65955, loss_cls=30.308485, loss=1418.544 .\n",
      "2022-04-13 12:16:10 [INFO]\t[TRAIN] Epoch=2/100, Step=3/87, loss_xy=320.797943, loss_wh=145.714294, loss_obj=405.293884, loss_cls=20.838842, loss=892.645020, lr=0.000089, time_each_step=1.42s, eta=3:25:3\n",
      "2022-04-13 12:16:27 [INFO]\t[TRAIN] Epoch=2/100, Step=13/87, loss_xy=141.700729, loss_wh=85.892319, loss_obj=141.068359, loss_cls=8.334766, loss=376.996185, lr=0.000099, time_each_step=1.66s, eta=3:58:27\n",
      "2022-04-13 12:16:39 [INFO]\t[TRAIN] Epoch=2/100, Step=23/87, loss_xy=385.122131, loss_wh=887.994995, loss_obj=3693.955811, loss_cls=15.373692, loss=4982.446777, lr=0.000109, time_each_step=1.29s, eta=3:4:34\n",
      "2022-04-13 12:16:56 [INFO]\t[TRAIN] Epoch=2/100, Step=33/87, loss_xy=292.236938, loss_wh=145.886795, loss_obj=660.108398, loss_cls=13.400681, loss=1111.632812, lr=0.000119, time_each_step=1.65s, eta=3:56:25\n",
      "2022-04-13 12:17:08 [INFO]\t[TRAIN] Epoch=2/100, Step=43/87, loss_xy=302.059998, loss_wh=285.085785, loss_obj=626.599548, loss_cls=17.043777, loss=1230.789185, lr=0.000129, time_each_step=1.2s, eta=2:52:13\n",
      "2022-04-13 12:17:22 [INFO]\t[TRAIN] Epoch=2/100, Step=53/87, loss_xy=254.280182, loss_wh=155.396072, loss_obj=660.073608, loss_cls=19.131552, loss=1088.881470, lr=0.000139, time_each_step=1.37s, eta=3:15:24\n",
      "2022-04-13 12:17:34 [INFO]\t[TRAIN] Epoch=2/100, Step=63/87, loss_xy=408.774780, loss_wh=259.938782, loss_obj=727.522644, loss_cls=18.707567, loss=1414.943726, lr=0.000149, time_each_step=1.25s, eta=2:58:26\n",
      "2022-04-13 12:17:48 [INFO]\t[TRAIN] Epoch=2/100, Step=73/87, loss_xy=377.919922, loss_wh=204.244720, loss_obj=778.764893, loss_cls=19.931995, loss=1380.861572, lr=0.000159, time_each_step=1.35s, eta=3:13:14\n",
      "2022-04-13 12:18:03 [INFO]\t[TRAIN] Epoch=2/100, Step=83/87, loss_xy=366.078125, loss_wh=258.391083, loss_obj=686.223450, loss_cls=19.275196, loss=1329.967773, lr=0.000169, time_each_step=1.51s, eta=3:35:25\n",
      "2022-04-13 12:18:09 [INFO]\t[TRAIN] Epoch 2 finished, loss_xy=301.07455, loss_wh=235.51862, loss_obj=773.0113, loss_cls=17.248621, loss=1326.853 .\n",
      "2022-04-13 12:18:18 [INFO]\t[TRAIN] Epoch=3/100, Step=6/87, loss_xy=313.929596, loss_wh=110.202621, loss_obj=620.567322, loss_cls=16.262836, loss=1060.962280, lr=0.000179, time_each_step=1.51s, eta=3:34:24\n",
      "2022-04-13 12:18:32 [INFO]\t[TRAIN] Epoch=3/100, Step=16/87, loss_xy=404.442047, loss_wh=241.300079, loss_obj=846.943115, loss_cls=28.878899, loss=1521.564209, lr=0.000189, time_each_step=1.44s, eta=3:24:19\n",
      "2022-04-13 12:18:45 [INFO]\t[TRAIN] Epoch=3/100, Step=26/87, loss_xy=266.065857, loss_wh=190.343292, loss_obj=502.525208, loss_cls=13.547203, loss=972.481506, lr=0.000199, time_each_step=1.27s, eta=3:1:3\n",
      "2022-04-13 12:18:58 [INFO]\t[TRAIN] Epoch=3/100, Step=36/87, loss_xy=380.583618, loss_wh=125.184036, loss_obj=682.699463, loss_cls=18.821114, loss=1207.288208, lr=0.000209, time_each_step=1.33s, eta=3:9:26\n",
      "2022-04-13 12:19:14 [INFO]\t[TRAIN] Epoch=3/100, Step=46/87, loss_xy=275.875183, loss_wh=57.660938, loss_obj=542.090576, loss_cls=13.168774, loss=888.795471, lr=0.000219, time_each_step=1.55s, eta=3:39:40\n",
      "2022-04-13 12:19:28 [INFO]\t[TRAIN] Epoch=3/100, Step=56/87, loss_xy=337.742889, loss_wh=59.090298, loss_obj=658.971436, loss_cls=18.376122, loss=1074.180786, lr=0.000229, time_each_step=1.38s, eta=3:15:23\n",
      "2022-04-13 12:19:42 [INFO]\t[TRAIN] Epoch=3/100, Step=66/87, loss_xy=335.000336, loss_wh=210.185135, loss_obj=679.698792, loss_cls=17.449209, loss=1242.333496, lr=0.000239, time_each_step=1.46s, eta=3:26:27\n",
      "2022-04-13 12:19:57 [INFO]\t[TRAIN] Epoch=3/100, Step=76/87, loss_xy=251.718231, loss_wh=101.141609, loss_obj=533.005371, loss_cls=15.372508, loss=901.237732, lr=0.000249, time_each_step=1.47s, eta=3:27:2\n",
      "2022-04-13 12:20:10 [INFO]\t[TRAIN] Epoch=3/100, Step=86/87, loss_xy=277.692139, loss_wh=181.866516, loss_obj=589.232544, loss_cls=13.711622, loss=1062.502930, lr=0.000259, time_each_step=1.33s, eta=3:7:32\n",
      "2022-04-13 12:20:13 [INFO]\t[TRAIN] Epoch 3 finished, loss_xy=287.47092, loss_wh=154.61913, loss_obj=575.5705, loss_cls=15.39126, loss=1033.0518 .\n",
      "2022-04-13 12:20:31 [INFO]\t[TRAIN] Epoch=4/100, Step=9/87, loss_xy=194.332001, loss_wh=165.759857, loss_obj=383.867981, loss_cls=10.371750, loss=754.331604, lr=0.000269, time_each_step=2.11s, eta=4:57:14\n",
      "2022-04-13 12:20:46 [INFO]\t[TRAIN] Epoch=4/100, Step=19/87, loss_xy=324.428680, loss_wh=97.938858, loss_obj=550.400635, loss_cls=17.925917, loss=990.694092, lr=0.000279, time_each_step=1.47s, eta=3:27:17\n",
      "2022-04-13 12:20:59 [INFO]\t[TRAIN] Epoch=4/100, Step=29/87, loss_xy=260.716309, loss_wh=97.668106, loss_obj=568.524658, loss_cls=13.056212, loss=939.965271, lr=0.000289, time_each_step=1.32s, eta=3:4:56\n",
      "2022-04-13 12:21:11 [INFO]\t[TRAIN] Epoch=4/100, Step=39/87, loss_xy=314.697296, loss_wh=141.084320, loss_obj=612.897766, loss_cls=14.115856, loss=1082.795288, lr=0.000299, time_each_step=1.14s, eta=2:40:29\n",
      "2022-04-13 12:21:25 [INFO]\t[TRAIN] Epoch=4/100, Step=49/87, loss_xy=208.197205, loss_wh=116.216324, loss_obj=388.722931, loss_cls=9.186862, loss=722.323364, lr=0.000309, time_each_step=1.4s, eta=3:16:5\n",
      "2022-04-13 12:21:37 [INFO]\t[TRAIN] Epoch=4/100, Step=59/87, loss_xy=263.653870, loss_wh=118.193558, loss_obj=554.073792, loss_cls=11.700569, loss=947.621765, lr=0.000319, time_each_step=1.2s, eta=2:48:35\n",
      "2022-04-13 12:21:51 [INFO]\t[TRAIN] Epoch=4/100, Step=69/87, loss_xy=351.262268, loss_wh=110.260757, loss_obj=634.065552, loss_cls=15.907631, loss=1111.496216, lr=0.000329, time_each_step=1.38s, eta=3:13:12\n",
      "2022-04-13 12:22:04 [INFO]\t[TRAIN] Epoch=4/100, Step=79/87, loss_xy=296.222076, loss_wh=102.265091, loss_obj=546.793457, loss_cls=14.411987, loss=959.692627, lr=0.000339, time_each_step=1.34s, eta=3:6:43\n",
      "2022-04-13 12:22:15 [INFO]\t[TRAIN] Epoch 4 finished, loss_xy=286.4999, loss_wh=132.22768, loss_obj=562.4697, loss_cls=14.668487, loss=995.8659 .\n",
      "2022-04-13 12:22:20 [INFO]\t[TRAIN] Epoch=5/100, Step=2/87, loss_xy=387.590210, loss_wh=212.935699, loss_obj=704.108093, loss_cls=18.951647, loss=1323.585693, lr=0.000349, time_each_step=1.6s, eta=3:43:58\n",
      "2022-04-13 12:22:32 [INFO]\t[TRAIN] Epoch=5/100, Step=12/87, loss_xy=222.821259, loss_wh=65.371544, loss_obj=498.685486, loss_cls=14.219176, loss=801.097473, lr=0.000359, time_each_step=1.23s, eta=2:51:47\n",
      "2022-04-13 12:22:44 [INFO]\t[TRAIN] Epoch=5/100, Step=22/87, loss_xy=390.669586, loss_wh=113.887794, loss_obj=627.428772, loss_cls=19.267891, loss=1151.254028, lr=0.000369, time_each_step=1.19s, eta=2:45:26\n",
      "2022-04-13 12:22:59 [INFO]\t[TRAIN] Epoch=5/100, Step=32/87, loss_xy=238.760284, loss_wh=90.871735, loss_obj=466.775543, loss_cls=14.369102, loss=810.776672, lr=0.000379, time_each_step=1.46s, eta=3:23:9\n",
      "2022-04-13 12:23:12 [INFO]\t[TRAIN] Epoch=5/100, Step=42/87, loss_xy=449.937195, loss_wh=228.849991, loss_obj=780.976379, loss_cls=23.584394, loss=1483.347900, lr=0.000389, time_each_step=1.35s, eta=3:7:24\n",
      "2022-04-13 12:23:27 [INFO]\t[TRAIN] Epoch=5/100, Step=52/87, loss_xy=255.529373, loss_wh=67.235291, loss_obj=477.787231, loss_cls=11.330195, loss=811.882080, lr=0.000399, time_each_step=1.42s, eta=3:17:12\n",
      "2022-04-13 12:23:45 [INFO]\t[TRAIN] Epoch=5/100, Step=62/87, loss_xy=202.230560, loss_wh=83.043114, loss_obj=382.194885, loss_cls=9.646947, loss=677.115540, lr=0.000409, time_each_step=1.83s, eta=4:13:33\n",
      "2022-04-13 12:23:57 [INFO]\t[TRAIN] Epoch=5/100, Step=72/87, loss_xy=245.994324, loss_wh=126.399033, loss_obj=458.811249, loss_cls=14.304735, loss=845.509338, lr=0.000419, time_each_step=1.16s, eta=2:41:13\n",
      "2022-04-13 12:24:14 [INFO]\t[TRAIN] Epoch=5/100, Step=82/87, loss_xy=338.609528, loss_wh=126.173058, loss_obj=671.305603, loss_cls=14.678630, loss=1150.766724, lr=0.000429, time_each_step=1.72s, eta=3:57:36\n",
      "2022-04-13 12:24:19 [INFO]\t[TRAIN] Epoch 5 finished, loss_xy=293.8458, loss_wh=123.46337, loss_obj=537.8741, loss_cls=14.657601, loss=969.84076 .\n",
      "2022-04-13 12:24:19 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 12:24:19 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 12:24:25 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 12:24:25 [INFO]\t[EVAL] Finished, Epoch=5, bbox_map=0.113071 .\n",
      "2022-04-13 12:24:27 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 12:24:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=0.11307100859339667\n",
      "2022-04-13 12:24:28 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_5.\n",
      "2022-04-13 12:24:36 [INFO]\t[TRAIN] Epoch=6/100, Step=5/87, loss_xy=373.570190, loss_wh=344.558899, loss_obj=601.727539, loss_cls=15.940449, loss=1335.797119, lr=0.000439, time_each_step=1.27s, eta=2:57:15\n",
      "2022-04-13 12:24:49 [INFO]\t[TRAIN] Epoch=6/100, Step=15/87, loss_xy=371.964539, loss_wh=112.119400, loss_obj=601.818848, loss_cls=15.941201, loss=1101.843994, lr=0.000449, time_each_step=1.35s, eta=3:7:28\n",
      "2022-04-13 12:25:01 [INFO]\t[TRAIN] Epoch=6/100, Step=25/87, loss_xy=282.199799, loss_wh=152.538986, loss_obj=367.036316, loss_cls=15.177271, loss=816.952332, lr=0.000459, time_each_step=1.21s, eta=2:48:0\n",
      "2022-04-13 12:25:15 [INFO]\t[TRAIN] Epoch=6/100, Step=35/87, loss_xy=553.203918, loss_wh=195.495132, loss_obj=831.615417, loss_cls=25.327866, loss=1605.642334, lr=0.000469, time_each_step=1.39s, eta=3:13:19\n",
      "2022-04-13 12:25:30 [INFO]\t[TRAIN] Epoch=6/100, Step=45/87, loss_xy=229.204117, loss_wh=131.419052, loss_obj=511.724976, loss_cls=15.517603, loss=887.865723, lr=0.000479, time_each_step=1.43s, eta=3:17:45\n",
      "2022-04-13 12:25:41 [INFO]\t[TRAIN] Epoch=6/100, Step=55/87, loss_xy=310.120331, loss_wh=97.093948, loss_obj=490.485535, loss_cls=16.901285, loss=914.601135, lr=0.000489, time_each_step=1.18s, eta=2:44:18\n",
      "2022-04-13 12:25:55 [INFO]\t[TRAIN] Epoch=6/100, Step=65/87, loss_xy=259.139191, loss_wh=61.806732, loss_obj=496.817566, loss_cls=12.614647, loss=830.378113, lr=0.000499, time_each_step=1.38s, eta=3:11:12\n",
      "2022-04-13 12:26:06 [INFO]\t[TRAIN] Epoch=6/100, Step=75/87, loss_xy=245.079117, loss_wh=63.352802, loss_obj=476.650085, loss_cls=12.931714, loss=798.013733, lr=0.000509, time_each_step=1.1s, eta=2:32:31\n",
      "2022-04-13 12:26:22 [INFO]\t[TRAIN] Epoch=6/100, Step=85/87, loss_xy=456.270386, loss_wh=278.265717, loss_obj=762.653198, loss_cls=21.006748, loss=1518.196045, lr=0.000519, time_each_step=1.53s, eta=3:31:40\n",
      "2022-04-13 12:26:24 [INFO]\t[TRAIN] Epoch 6 finished, loss_xy=297.55023, loss_wh=131.46489, loss_obj=526.06274, loss_cls=14.996644, loss=970.07434 .\n",
      "2022-04-13 12:26:38 [INFO]\t[TRAIN] Epoch=7/100, Step=8/87, loss_xy=283.051636, loss_wh=110.991341, loss_obj=494.360626, loss_cls=13.479674, loss=901.883240, lr=0.000529, time_each_step=1.66s, eta=3:48:10\n",
      "2022-04-13 12:26:54 [INFO]\t[TRAIN] Epoch=7/100, Step=18/87, loss_xy=280.579529, loss_wh=263.871338, loss_obj=468.402039, loss_cls=14.038618, loss=1026.891479, lr=0.000539, time_each_step=1.56s, eta=3:34:59\n",
      "2022-04-13 12:27:09 [INFO]\t[TRAIN] Epoch=7/100, Step=28/87, loss_xy=279.648712, loss_wh=85.793228, loss_obj=489.157898, loss_cls=13.196230, loss=867.796082, lr=0.000549, time_each_step=1.47s, eta=3:22:1\n",
      "2022-04-13 12:27:22 [INFO]\t[TRAIN] Epoch=7/100, Step=38/87, loss_xy=254.798065, loss_wh=131.361435, loss_obj=537.208679, loss_cls=13.494419, loss=936.862610, lr=0.000559, time_each_step=1.36s, eta=3:7:0\n",
      "2022-04-13 12:27:38 [INFO]\t[TRAIN] Epoch=7/100, Step=48/87, loss_xy=190.829498, loss_wh=105.645920, loss_obj=415.788177, loss_cls=10.229866, loss=722.493408, lr=0.000569, time_each_step=1.56s, eta=3:33:24\n",
      "2022-04-13 12:27:55 [INFO]\t[TRAIN] Epoch=7/100, Step=58/87, loss_xy=277.765045, loss_wh=129.922104, loss_obj=482.902130, loss_cls=14.728624, loss=905.317871, lr=0.000579, time_each_step=1.75s, eta=3:59:29\n",
      "2022-04-13 12:28:08 [INFO]\t[TRAIN] Epoch=7/100, Step=68/87, loss_xy=253.644684, loss_wh=101.812263, loss_obj=502.529572, loss_cls=13.983559, loss=871.970093, lr=0.000589, time_each_step=1.32s, eta=3:1:32\n",
      "2022-04-13 12:28:21 [INFO]\t[TRAIN] Epoch=7/100, Step=78/87, loss_xy=382.579224, loss_wh=110.813606, loss_obj=577.292419, loss_cls=18.447054, loss=1089.132324, lr=0.000599, time_each_step=1.24s, eta=2:49:32\n",
      "2022-04-13 12:28:32 [INFO]\t[TRAIN] Epoch 7 finished, loss_xy=289.83148, loss_wh=123.694626, loss_obj=531.0972, loss_cls=14.461905, loss=959.0853 .\n",
      "2022-04-13 12:28:34 [INFO]\t[TRAIN] Epoch=8/100, Step=1/87, loss_xy=186.696320, loss_wh=62.933727, loss_obj=499.139679, loss_cls=12.712193, loss=761.481934, lr=0.000609, time_each_step=1.28s, eta=2:54:34\n",
      "2022-04-13 12:28:49 [INFO]\t[TRAIN] Epoch=8/100, Step=11/87, loss_xy=463.477386, loss_wh=83.516129, loss_obj=757.481812, loss_cls=20.752234, loss=1325.227539, lr=0.000619, time_each_step=1.5s, eta=3:24:24\n",
      "2022-04-13 12:29:05 [INFO]\t[TRAIN] Epoch=8/100, Step=21/87, loss_xy=276.082245, loss_wh=125.904945, loss_obj=563.497498, loss_cls=14.709303, loss=980.193970, lr=0.000629, time_each_step=1.6s, eta=3:38:4\n",
      "2022-04-13 12:29:18 [INFO]\t[TRAIN] Epoch=8/100, Step=31/87, loss_xy=403.530151, loss_wh=272.953735, loss_obj=620.825073, loss_cls=18.590286, loss=1315.899292, lr=0.000639, time_each_step=1.37s, eta=3:6:34\n",
      "2022-04-13 12:29:32 [INFO]\t[TRAIN] Epoch=8/100, Step=41/87, loss_xy=207.403946, loss_wh=59.725456, loss_obj=387.794952, loss_cls=9.284719, loss=664.209045, lr=0.000649, time_each_step=1.39s, eta=3:8:20\n",
      "2022-04-13 12:29:45 [INFO]\t[TRAIN] Epoch=8/100, Step=51/87, loss_xy=218.942993, loss_wh=112.624321, loss_obj=364.196045, loss_cls=9.793101, loss=705.556458, lr=0.000659, time_each_step=1.31s, eta=2:58:23\n",
      "2022-04-13 12:29:58 [INFO]\t[TRAIN] Epoch=8/100, Step=61/87, loss_xy=304.360870, loss_wh=124.622604, loss_obj=492.807098, loss_cls=13.599565, loss=935.390076, lr=0.000669, time_each_step=1.23s, eta=2:47:29\n",
      "2022-04-13 12:30:15 [INFO]\t[TRAIN] Epoch=8/100, Step=71/87, loss_xy=264.563965, loss_wh=125.833603, loss_obj=546.440613, loss_cls=11.727767, loss=948.565979, lr=0.000679, time_each_step=1.73s, eta=3:54:16\n",
      "2022-04-13 12:30:28 [INFO]\t[TRAIN] Epoch=8/100, Step=81/87, loss_xy=392.062195, loss_wh=156.024338, loss_obj=694.984070, loss_cls=16.996571, loss=1260.067139, lr=0.000689, time_each_step=1.31s, eta=2:57:32\n",
      "2022-04-13 12:30:37 [INFO]\t[TRAIN] Epoch 8 finished, loss_xy=294.03183, loss_wh=119.29952, loss_obj=503.3675, loss_cls=13.70181, loss=930.40094 .\n",
      "2022-04-13 12:30:42 [INFO]\t[TRAIN] Epoch=9/100, Step=4/87, loss_xy=218.854218, loss_wh=94.389816, loss_obj=458.485779, loss_cls=12.286666, loss=784.016479, lr=0.000699, time_each_step=1.32s, eta=2:58:4\n",
      "2022-04-13 12:30:55 [INFO]\t[TRAIN] Epoch=9/100, Step=14/87, loss_xy=253.314224, loss_wh=172.278625, loss_obj=386.405914, loss_cls=11.538924, loss=823.537720, lr=0.000709, time_each_step=1.37s, eta=3:5:17\n",
      "2022-04-13 12:31:07 [INFO]\t[TRAIN] Epoch=9/100, Step=24/87, loss_xy=179.784714, loss_wh=122.781982, loss_obj=234.016418, loss_cls=7.978356, loss=544.561462, lr=0.000719, time_each_step=1.22s, eta=2:44:56\n",
      "2022-04-13 12:31:21 [INFO]\t[TRAIN] Epoch=9/100, Step=34/87, loss_xy=432.128021, loss_wh=301.052094, loss_obj=677.947083, loss_cls=18.865978, loss=1429.993164, lr=0.000729, time_each_step=1.34s, eta=3:0:30\n",
      "2022-04-13 12:31:34 [INFO]\t[TRAIN] Epoch=9/100, Step=44/87, loss_xy=475.729553, loss_wh=187.800018, loss_obj=722.801880, loss_cls=20.800882, loss=1407.132324, lr=0.000739, time_each_step=1.27s, eta=2:50:36\n",
      "2022-04-13 12:31:47 [INFO]\t[TRAIN] Epoch=9/100, Step=54/87, loss_xy=226.833557, loss_wh=173.076019, loss_obj=310.272491, loss_cls=9.833361, loss=720.015442, lr=0.000749, time_each_step=1.37s, eta=3:4:23\n",
      "2022-04-13 12:32:00 [INFO]\t[TRAIN] Epoch=9/100, Step=64/87, loss_xy=393.333374, loss_wh=270.398895, loss_obj=754.952515, loss_cls=17.499426, loss=1436.184204, lr=0.000759, time_each_step=1.26s, eta=2:49:9\n",
      "2022-04-13 12:32:14 [INFO]\t[TRAIN] Epoch=9/100, Step=74/87, loss_xy=204.035049, loss_wh=129.967987, loss_obj=424.243622, loss_cls=8.978348, loss=767.225037, lr=0.000769, time_each_step=1.44s, eta=3:12:34\n",
      "2022-04-13 12:32:30 [INFO]\t[TRAIN] Epoch=9/100, Step=84/87, loss_xy=279.840668, loss_wh=469.748932, loss_obj=327.938110, loss_cls=11.813745, loss=1089.341431, lr=0.000779, time_each_step=1.56s, eta=3:27:55\n",
      "2022-04-13 12:32:34 [INFO]\t[TRAIN] Epoch 9 finished, loss_xy=293.37378, loss_wh=199.75635, loss_obj=503.40128, loss_cls=13.194563, loss=1009.72614 .\n",
      "2022-04-13 12:32:50 [INFO]\t[TRAIN] Epoch=10/100, Step=7/87, loss_xy=387.977905, loss_wh=165.873932, loss_obj=492.312317, loss_cls=17.017651, loss=1063.181763, lr=0.000789, time_each_step=2.04s, eta=4:30:47\n",
      "2022-04-13 12:33:05 [INFO]\t[TRAIN] Epoch=10/100, Step=17/87, loss_xy=193.783386, loss_wh=82.160149, loss_obj=348.623535, loss_cls=8.445055, loss=633.012146, lr=0.000799, time_each_step=1.47s, eta=3:15:40\n",
      "2022-04-13 12:33:20 [INFO]\t[TRAIN] Epoch=10/100, Step=27/87, loss_xy=272.270172, loss_wh=77.799103, loss_obj=423.535858, loss_cls=11.940045, loss=785.545166, lr=0.000809, time_each_step=1.47s, eta=3:15:40\n",
      "2022-04-13 12:33:32 [INFO]\t[TRAIN] Epoch=10/100, Step=37/87, loss_xy=305.916565, loss_wh=163.572433, loss_obj=468.362427, loss_cls=13.320701, loss=951.172119, lr=0.000819, time_each_step=1.23s, eta=2:44:21\n",
      "2022-04-13 12:33:46 [INFO]\t[TRAIN] Epoch=10/100, Step=47/87, loss_xy=162.378281, loss_wh=104.293625, loss_obj=353.602844, loss_cls=8.481607, loss=628.756409, lr=0.000829, time_each_step=1.35s, eta=2:58:57\n",
      "2022-04-13 12:34:04 [INFO]\t[TRAIN] Epoch=10/100, Step=57/87, loss_xy=202.151611, loss_wh=114.982376, loss_obj=341.244476, loss_cls=8.735925, loss=667.114319, lr=0.000839, time_each_step=1.79s, eta=3:56:44\n",
      "2022-04-13 12:34:18 [INFO]\t[TRAIN] Epoch=10/100, Step=67/87, loss_xy=304.321869, loss_wh=94.054024, loss_obj=452.222626, loss_cls=13.158389, loss=863.756897, lr=0.000849, time_each_step=1.42s, eta=3:7:39\n",
      "2022-04-13 12:34:31 [INFO]\t[TRAIN] Epoch=10/100, Step=77/87, loss_xy=212.442200, loss_wh=54.377815, loss_obj=442.308014, loss_cls=10.462275, loss=719.590332, lr=0.000859, time_each_step=1.32s, eta=2:55:27\n",
      "2022-04-13 12:34:42 [INFO]\t[TRAIN] Epoch=10/100, Step=87/87, loss_xy=191.449951, loss_wh=128.526123, loss_obj=328.227905, loss_cls=8.255313, loss=656.459290, lr=0.000869, time_each_step=1.15s, eta=2:31:48\n",
      "2022-04-13 12:34:43 [INFO]\t[TRAIN] Epoch 10 finished, loss_xy=288.6145, loss_wh=133.79533, loss_obj=470.88403, loss_cls=12.671802, loss=905.9657 .\n",
      "2022-04-13 12:34:43 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 12:34:43 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 12:34:49 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 12:34:49 [INFO]\t[EVAL] Finished, Epoch=10, bbox_map=0.060072 .\n",
      "2022-04-13 12:34:49 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=0.11307100859339667\n",
      "2022-04-13 12:34:51 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_10.\n",
      "2022-04-13 12:35:07 [INFO]\t[TRAIN] Epoch=11/100, Step=10/87, loss_xy=452.101746, loss_wh=353.109711, loss_obj=438.845337, loss_cls=19.117073, loss=1263.173828, lr=0.000879, time_each_step=1.68s, eta=3:41:21\n",
      "2022-04-13 12:35:20 [INFO]\t[TRAIN] Epoch=11/100, Step=20/87, loss_xy=396.754517, loss_wh=429.204987, loss_obj=641.587952, loss_cls=16.712452, loss=1484.259766, lr=0.000889, time_each_step=1.3s, eta=2:51:22\n",
      "2022-04-13 12:35:35 [INFO]\t[TRAIN] Epoch=11/100, Step=30/87, loss_xy=297.051575, loss_wh=167.985718, loss_obj=499.274506, loss_cls=12.699943, loss=977.011719, lr=0.000899, time_each_step=1.49s, eta=3:15:37\n",
      "2022-04-13 12:35:50 [INFO]\t[TRAIN] Epoch=11/100, Step=40/87, loss_xy=325.845642, loss_wh=204.258301, loss_obj=333.190399, loss_cls=13.714962, loss=877.009277, lr=0.000909, time_each_step=1.43s, eta=3:7:12\n",
      "2022-04-13 12:36:04 [INFO]\t[TRAIN] Epoch=11/100, Step=50/87, loss_xy=246.679047, loss_wh=184.557510, loss_obj=503.521362, loss_cls=11.173593, loss=945.931519, lr=0.000919, time_each_step=1.44s, eta=3:9:12\n",
      "2022-04-13 12:36:19 [INFO]\t[TRAIN] Epoch=11/100, Step=60/87, loss_xy=404.579987, loss_wh=259.523743, loss_obj=620.044983, loss_cls=17.215567, loss=1301.364258, lr=0.000929, time_each_step=1.49s, eta=3:14:37\n",
      "2022-04-13 12:36:34 [INFO]\t[TRAIN] Epoch=11/100, Step=70/87, loss_xy=371.330231, loss_wh=163.754425, loss_obj=568.363220, loss_cls=15.853547, loss=1119.301392, lr=0.000939, time_each_step=1.5s, eta=3:16:21\n",
      "2022-04-13 12:36:47 [INFO]\t[TRAIN] Epoch=11/100, Step=80/87, loss_xy=262.901917, loss_wh=77.643440, loss_obj=531.320740, loss_cls=11.598183, loss=883.464294, lr=0.000949, time_each_step=1.3s, eta=2:49:15\n",
      "2022-04-13 12:37:00 [INFO]\t[TRAIN] Epoch 11 finished, loss_xy=301.7744, loss_wh=188.81932, loss_obj=501.37946, loss_cls=13.018078, loss=1004.9912 .\n",
      "2022-04-13 12:37:06 [INFO]\t[TRAIN] Epoch=12/100, Step=3/87, loss_xy=326.629181, loss_wh=183.443726, loss_obj=760.324036, loss_cls=14.411342, loss=1284.808350, lr=0.000959, time_each_step=1.91s, eta=4:8:11\n",
      "2022-04-13 12:37:20 [INFO]\t[TRAIN] Epoch=12/100, Step=13/87, loss_xy=294.534943, loss_wh=107.048378, loss_obj=539.590271, loss_cls=12.632203, loss=953.805786, lr=0.000969, time_each_step=1.37s, eta=2:58:0\n",
      "2022-04-13 12:37:37 [INFO]\t[TRAIN] Epoch=12/100, Step=23/87, loss_xy=304.419922, loss_wh=113.227676, loss_obj=622.318359, loss_cls=13.220730, loss=1053.186646, lr=0.000979, time_each_step=1.71s, eta=3:42:24\n",
      "2022-04-13 12:37:52 [INFO]\t[TRAIN] Epoch=12/100, Step=33/87, loss_xy=147.768600, loss_wh=122.678345, loss_obj=249.543732, loss_cls=6.374403, loss=526.365112, lr=0.000989, time_each_step=1.48s, eta=3:12:15\n",
      "2022-04-13 12:38:06 [INFO]\t[TRAIN] Epoch=12/100, Step=43/87, loss_xy=257.909027, loss_wh=185.502548, loss_obj=353.137817, loss_cls=11.486986, loss=808.036377, lr=0.000999, time_each_step=1.46s, eta=3:8:54\n",
      "2022-04-13 12:38:22 [INFO]\t[TRAIN] Epoch=12/100, Step=53/87, loss_xy=164.166016, loss_wh=262.529755, loss_obj=132.212219, loss_cls=6.952589, loss=565.860535, lr=0.001000, time_each_step=1.53s, eta=3:17:58\n",
      "2022-04-13 12:38:37 [INFO]\t[TRAIN] Epoch=12/100, Step=63/87, loss_xy=283.965607, loss_wh=129.434464, loss_obj=557.680725, loss_cls=12.217506, loss=983.298340, lr=0.001000, time_each_step=1.55s, eta=3:20:19\n",
      "2022-04-13 12:38:56 [INFO]\t[TRAIN] Epoch=12/100, Step=73/87, loss_xy=358.404633, loss_wh=174.668610, loss_obj=497.682739, loss_cls=15.324599, loss=1046.080566, lr=0.001000, time_each_step=1.87s, eta=4:1:35\n",
      "2022-04-13 12:39:09 [INFO]\t[TRAIN] Epoch=12/100, Step=83/87, loss_xy=306.179382, loss_wh=151.707443, loss_obj=489.394135, loss_cls=13.072870, loss=960.353882, lr=0.001000, time_each_step=1.35s, eta=2:54:12\n",
      "2022-04-13 12:39:14 [INFO]\t[TRAIN] Epoch 12 finished, loss_xy=275.24887, loss_wh=175.35812, loss_obj=442.02408, loss_cls=11.939112, loss=904.57007 .\n",
      "2022-04-13 12:39:25 [INFO]\t[TRAIN] Epoch=13/100, Step=6/87, loss_xy=227.581421, loss_wh=122.413933, loss_obj=386.713898, loss_cls=9.682223, loss=746.391479, lr=0.001000, time_each_step=1.54s, eta=3:18:3\n",
      "2022-04-13 12:39:37 [INFO]\t[TRAIN] Epoch=13/100, Step=16/87, loss_xy=350.179138, loss_wh=123.790283, loss_obj=631.466614, loss_cls=15.601751, loss=1121.037842, lr=0.001000, time_each_step=1.23s, eta=2:38:49\n",
      "2022-04-13 12:39:52 [INFO]\t[TRAIN] Epoch=13/100, Step=26/87, loss_xy=426.343384, loss_wh=199.185440, loss_obj=787.682983, loss_cls=18.237680, loss=1431.449463, lr=0.001000, time_each_step=1.46s, eta=3:7:17\n",
      "2022-04-13 12:40:09 [INFO]\t[TRAIN] Epoch=13/100, Step=36/87, loss_xy=131.766937, loss_wh=113.902863, loss_obj=144.064499, loss_cls=5.565042, loss=395.299347, lr=0.001000, time_each_step=1.76s, eta=3:44:59\n",
      "2022-04-13 12:40:26 [INFO]\t[TRAIN] Epoch=13/100, Step=46/87, loss_xy=254.240814, loss_wh=119.145172, loss_obj=462.755005, loss_cls=10.861913, loss=847.002930, lr=0.001000, time_each_step=1.68s, eta=3:35:30\n",
      "2022-04-13 12:40:39 [INFO]\t[TRAIN] Epoch=13/100, Step=56/87, loss_xy=239.542023, loss_wh=136.427048, loss_obj=423.860962, loss_cls=10.550344, loss=810.380371, lr=0.001000, time_each_step=1.26s, eta=2:41:49\n",
      "2022-04-13 12:40:52 [INFO]\t[TRAIN] Epoch=13/100, Step=66/87, loss_xy=307.285645, loss_wh=115.556694, loss_obj=475.963165, loss_cls=13.128196, loss=911.933716, lr=0.001000, time_each_step=1.29s, eta=2:45:41\n",
      "2022-04-13 12:41:11 [INFO]\t[TRAIN] Epoch=13/100, Step=76/87, loss_xy=330.936798, loss_wh=207.183517, loss_obj=706.192993, loss_cls=14.040709, loss=1258.353882, lr=0.001000, time_each_step=1.91s, eta=4:2:45\n",
      "2022-04-13 12:41:24 [INFO]\t[TRAIN] Epoch=13/100, Step=86/87, loss_xy=248.175110, loss_wh=92.479431, loss_obj=272.606171, loss_cls=10.484736, loss=623.745483, lr=0.001000, time_each_step=1.36s, eta=2:53:47\n",
      "2022-04-13 12:41:27 [INFO]\t[TRAIN] Epoch 13 finished, loss_xy=275.87683, loss_wh=145.93762, loss_obj=433.3032, loss_cls=11.902794, loss=867.02045 .\n",
      "2022-04-13 12:41:40 [INFO]\t[TRAIN] Epoch=14/100, Step=9/87, loss_xy=233.204971, loss_wh=158.443237, loss_obj=404.678223, loss_cls=10.245235, loss=806.571655, lr=0.001000, time_each_step=1.58s, eta=3:20:58\n",
      "2022-04-13 12:41:54 [INFO]\t[TRAIN] Epoch=14/100, Step=19/87, loss_xy=193.842468, loss_wh=177.860321, loss_obj=242.541779, loss_cls=8.189114, loss=622.433655, lr=0.001000, time_each_step=1.33s, eta=2:49:31\n",
      "2022-04-13 12:42:08 [INFO]\t[TRAIN] Epoch=14/100, Step=29/87, loss_xy=267.244781, loss_wh=186.900803, loss_obj=426.762665, loss_cls=11.325686, loss=892.233887, lr=0.001000, time_each_step=1.42s, eta=3:0:33\n",
      "2022-04-13 12:42:21 [INFO]\t[TRAIN] Epoch=14/100, Step=39/87, loss_xy=238.641922, loss_wh=233.502380, loss_obj=453.698364, loss_cls=10.133869, loss=935.976501, lr=0.001000, time_each_step=1.29s, eta=2:44:27\n",
      "2022-04-13 12:42:37 [INFO]\t[TRAIN] Epoch=14/100, Step=49/87, loss_xy=318.678558, loss_wh=105.353813, loss_obj=613.689514, loss_cls=13.551888, loss=1051.273804, lr=0.001000, time_each_step=1.66s, eta=3:29:52\n",
      "2022-04-13 12:42:53 [INFO]\t[TRAIN] Epoch=14/100, Step=59/87, loss_xy=207.866745, loss_wh=98.804382, loss_obj=292.849548, loss_cls=8.778697, loss=608.299377, lr=0.001000, time_each_step=1.56s, eta=3:16:37\n",
      "2022-04-13 12:43:08 [INFO]\t[TRAIN] Epoch=14/100, Step=69/87, loss_xy=244.508865, loss_wh=162.344009, loss_obj=357.664612, loss_cls=10.378365, loss=774.895813, lr=0.001000, time_each_step=1.48s, eta=3:6:39\n",
      "2022-04-13 12:43:24 [INFO]\t[TRAIN] Epoch=14/100, Step=79/87, loss_xy=317.025024, loss_wh=289.052551, loss_obj=437.131714, loss_cls=13.409031, loss=1056.618286, lr=0.001000, time_each_step=1.63s, eta=3:25:43\n",
      "2022-04-13 12:43:34 [INFO]\t[TRAIN] Epoch 14 finished, loss_xy=272.09573, loss_wh=178.37498, loss_obj=437.1193, loss_cls=11.654348, loss=899.2443 .\n",
      "2022-04-13 12:43:38 [INFO]\t[TRAIN] Epoch=15/100, Step=2/87, loss_xy=237.274765, loss_wh=100.573410, loss_obj=444.768555, loss_cls=10.303612, loss=792.920288, lr=0.001000, time_each_step=1.39s, eta=2:54:33\n",
      "2022-04-13 12:43:52 [INFO]\t[TRAIN] Epoch=15/100, Step=12/87, loss_xy=493.448242, loss_wh=318.670746, loss_obj=732.862488, loss_cls=20.761354, loss=1565.742798, lr=0.001000, time_each_step=1.36s, eta=2:51:10\n",
      "2022-04-13 12:44:07 [INFO]\t[TRAIN] Epoch=15/100, Step=22/87, loss_xy=314.105011, loss_wh=122.490669, loss_obj=533.978821, loss_cls=13.339126, loss=983.913574, lr=0.001000, time_each_step=1.5s, eta=3:8:1\n",
      "2022-04-13 12:44:22 [INFO]\t[TRAIN] Epoch=15/100, Step=32/87, loss_xy=284.148285, loss_wh=55.571396, loss_obj=513.134399, loss_cls=12.205576, loss=865.059631, lr=0.001000, time_each_step=1.5s, eta=3:8:29\n",
      "2022-04-13 12:44:35 [INFO]\t[TRAIN] Epoch=15/100, Step=42/87, loss_xy=311.711151, loss_wh=184.680237, loss_obj=577.278137, loss_cls=13.273459, loss=1086.942993, lr=0.001000, time_each_step=1.29s, eta=2:41:39\n",
      "2022-04-13 12:44:49 [INFO]\t[TRAIN] Epoch=15/100, Step=52/87, loss_xy=212.817841, loss_wh=92.434547, loss_obj=437.679993, loss_cls=9.271967, loss=752.204346, lr=0.001000, time_each_step=1.48s, eta=3:5:8\n",
      "2022-04-13 12:45:03 [INFO]\t[TRAIN] Epoch=15/100, Step=62/87, loss_xy=440.812256, loss_wh=363.482788, loss_obj=698.136902, loss_cls=18.806587, loss=1521.238525, lr=0.001000, time_each_step=1.33s, eta=2:46:5\n",
      "2022-04-13 12:45:15 [INFO]\t[TRAIN] Epoch=15/100, Step=72/87, loss_xy=336.617737, loss_wh=282.542114, loss_obj=646.528076, loss_cls=14.398177, loss=1280.086182, lr=0.001000, time_each_step=1.2s, eta=2:30:39\n",
      "2022-04-13 12:45:28 [INFO]\t[TRAIN] Epoch=15/100, Step=82/87, loss_xy=233.606033, loss_wh=55.771431, loss_obj=528.820496, loss_cls=10.390905, loss=828.588928, lr=0.001000, time_each_step=1.36s, eta=2:49:18\n",
      "2022-04-13 12:45:37 [INFO]\t[TRAIN] Epoch 15 finished, loss_xy=302.50943, loss_wh=174.36012, loss_obj=517.16626, loss_cls=12.927231, loss=1006.9631 .\n",
      "2022-04-13 12:45:37 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 12:45:38 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 12:45:44 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 12:45:44 [INFO]\t[EVAL] Finished, Epoch=15, bbox_map=0.000000 .\n",
      "2022-04-13 12:45:44 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=0.11307100859339667\n",
      "2022-04-13 12:45:45 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_15.\n",
      "2022-04-13 12:45:55 [INFO]\t[TRAIN] Epoch=16/100, Step=5/87, loss_xy=458.881683, loss_wh=199.350616, loss_obj=562.670288, loss_cls=19.400038, loss=1240.302612, lr=0.001000, time_each_step=1.81s, eta=3:44:53\n",
      "2022-04-13 12:46:11 [INFO]\t[TRAIN] Epoch=16/100, Step=15/87, loss_xy=369.366058, loss_wh=235.447189, loss_obj=529.912781, loss_cls=15.854489, loss=1150.580566, lr=0.001000, time_each_step=1.64s, eta=3:24:6\n",
      "2022-04-13 12:46:23 [INFO]\t[TRAIN] Epoch=16/100, Step=25/87, loss_xy=444.554169, loss_wh=212.303482, loss_obj=754.383179, loss_cls=18.805094, loss=1430.045898, lr=0.001000, time_each_step=1.19s, eta=2:28:24\n",
      "2022-04-13 12:46:35 [INFO]\t[TRAIN] Epoch=16/100, Step=35/87, loss_xy=180.222107, loss_wh=219.993774, loss_obj=275.156586, loss_cls=7.643199, loss=683.015625, lr=0.001000, time_each_step=1.13s, eta=2:21:9\n",
      "2022-04-13 12:46:50 [INFO]\t[TRAIN] Epoch=16/100, Step=45/87, loss_xy=292.119812, loss_wh=140.242950, loss_obj=519.161804, loss_cls=12.596365, loss=964.120911, lr=0.001000, time_each_step=1.5s, eta=3:6:2\n",
      "2022-04-13 12:47:04 [INFO]\t[TRAIN] Epoch=16/100, Step=55/87, loss_xy=150.483734, loss_wh=130.297974, loss_obj=257.674438, loss_cls=7.268818, loss=545.724976, lr=0.001000, time_each_step=1.43s, eta=2:57:2\n",
      "2022-04-13 12:47:21 [INFO]\t[TRAIN] Epoch=16/100, Step=65/87, loss_xy=286.253113, loss_wh=102.864212, loss_obj=454.608612, loss_cls=12.147822, loss=855.873779, lr=0.001000, time_each_step=1.71s, eta=3:30:32\n",
      "2022-04-13 12:47:37 [INFO]\t[TRAIN] Epoch=16/100, Step=75/87, loss_xy=272.801025, loss_wh=300.711395, loss_obj=172.652054, loss_cls=11.527220, loss=757.691711, lr=0.001000, time_each_step=1.57s, eta=3:14:0\n",
      "2022-04-13 12:47:52 [INFO]\t[TRAIN] Epoch=16/100, Step=85/87, loss_xy=236.442337, loss_wh=130.673126, loss_obj=404.504913, loss_cls=9.981082, loss=781.601440, lr=0.001000, time_each_step=1.52s, eta=3:7:39\n",
      "2022-04-13 12:47:55 [INFO]\t[TRAIN] Epoch 16 finished, loss_xy=288.94733, loss_wh=179.00317, loss_obj=462.15146, loss_cls=12.405342, loss=942.50745 .\n",
      "2022-04-13 12:48:08 [INFO]\t[TRAIN] Epoch=17/100, Step=8/87, loss_xy=379.366699, loss_wh=235.188950, loss_obj=730.239319, loss_cls=16.378962, loss=1361.173828, lr=0.001000, time_each_step=1.55s, eta=3:10:26\n",
      "2022-04-13 12:48:22 [INFO]\t[TRAIN] Epoch=17/100, Step=18/87, loss_xy=202.858582, loss_wh=114.058220, loss_obj=427.440979, loss_cls=8.586798, loss=752.944580, lr=0.001000, time_each_step=1.38s, eta=2:49:5\n",
      "2022-04-13 12:48:41 [INFO]\t[TRAIN] Epoch=17/100, Step=28/87, loss_xy=249.187714, loss_wh=99.852913, loss_obj=399.570160, loss_cls=10.534467, loss=759.145264, lr=0.001000, time_each_step=1.91s, eta=3:54:10\n",
      "2022-04-13 12:48:54 [INFO]\t[TRAIN] Epoch=17/100, Step=38/87, loss_xy=274.228668, loss_wh=148.106308, loss_obj=355.860962, loss_cls=11.611558, loss=789.807495, lr=0.001000, time_each_step=1.34s, eta=2:44:30\n",
      "2022-04-13 12:49:09 [INFO]\t[TRAIN] Epoch=17/100, Step=48/87, loss_xy=259.651154, loss_wh=164.745804, loss_obj=343.673035, loss_cls=10.995661, loss=779.065674, lr=0.001000, time_each_step=1.51s, eta=3:4:29\n",
      "2022-04-13 12:49:24 [INFO]\t[TRAIN] Epoch=17/100, Step=58/87, loss_xy=259.581268, loss_wh=113.804871, loss_obj=371.816986, loss_cls=10.993296, loss=756.196411, lr=0.001000, time_each_step=1.46s, eta=2:57:57\n",
      "2022-04-13 12:49:35 [INFO]\t[TRAIN] Epoch=17/100, Step=68/87, loss_xy=463.898773, loss_wh=452.074310, loss_obj=798.428833, loss_cls=19.659191, loss=1734.061035, lr=0.001000, time_each_step=1.14s, eta=2:20:4\n",
      "2022-04-13 12:49:49 [INFO]\t[TRAIN] Epoch=17/100, Step=78/87, loss_xy=306.433868, loss_wh=165.895004, loss_obj=552.789673, loss_cls=13.124526, loss=1038.243042, lr=0.001000, time_each_step=1.43s, eta=2:53:52\n",
      "2022-04-13 12:50:01 [INFO]\t[TRAIN] Epoch 17 finished, loss_xy=285.93976, loss_wh=150.95215, loss_obj=456.68347, loss_cls=12.2172575, loss=905.79254 .\n",
      "2022-04-13 12:50:05 [INFO]\t[TRAIN] Epoch=18/100, Step=1/87, loss_xy=289.129211, loss_wh=415.880341, loss_obj=413.668091, loss_cls=12.939667, loss=1131.617310, lr=0.001000, time_each_step=1.49s, eta=3:1:32\n",
      "2022-04-13 12:50:17 [INFO]\t[TRAIN] Epoch=18/100, Step=11/87, loss_xy=217.275269, loss_wh=247.250961, loss_obj=263.797668, loss_cls=9.371670, loss=737.695557, lr=0.001000, time_each_step=1.26s, eta=2:33:15\n",
      "2022-04-13 12:50:32 [INFO]\t[TRAIN] Epoch=18/100, Step=21/87, loss_xy=302.670441, loss_wh=58.691597, loss_obj=587.018005, loss_cls=13.000298, loss=961.380310, lr=0.001000, time_each_step=1.52s, eta=3:4:10\n",
      "2022-04-13 12:50:44 [INFO]\t[TRAIN] Epoch=18/100, Step=31/87, loss_xy=376.218414, loss_wh=199.794312, loss_obj=602.893188, loss_cls=15.960831, loss=1194.866699, lr=0.001000, time_each_step=1.21s, eta=2:27:12\n",
      "2022-04-13 12:51:01 [INFO]\t[TRAIN] Epoch=18/100, Step=41/87, loss_xy=373.829346, loss_wh=113.674622, loss_obj=652.019348, loss_cls=15.765572, loss=1155.288940, lr=0.001000, time_each_step=1.66s, eta=3:20:52\n",
      "2022-04-13 12:51:15 [INFO]\t[TRAIN] Epoch=18/100, Step=51/87, loss_xy=496.071167, loss_wh=139.236252, loss_obj=763.343323, loss_cls=20.999102, loss=1419.649902, lr=0.001000, time_each_step=1.36s, eta=2:44:7\n",
      "2022-04-13 12:51:30 [INFO]\t[TRAIN] Epoch=18/100, Step=61/87, loss_xy=168.669800, loss_wh=191.392181, loss_obj=134.728821, loss_cls=7.153004, loss=501.943817, lr=0.001000, time_each_step=1.5s, eta=3:1:24\n",
      "2022-04-13 12:51:44 [INFO]\t[TRAIN] Epoch=18/100, Step=71/87, loss_xy=245.543854, loss_wh=72.648773, loss_obj=364.256989, loss_cls=10.498019, loss=692.947632, lr=0.001000, time_each_step=1.43s, eta=2:52:10\n",
      "2022-04-13 12:52:00 [INFO]\t[TRAIN] Epoch=18/100, Step=81/87, loss_xy=309.908478, loss_wh=78.527428, loss_obj=539.725464, loss_cls=13.136847, loss=941.298218, lr=0.001000, time_each_step=1.6s, eta=3:11:54\n",
      "2022-04-13 12:52:11 [INFO]\t[TRAIN] Epoch 18 finished, loss_xy=294.09933, loss_wh=140.6766, loss_obj=448.7217, loss_cls=12.606166, loss=896.1038 .\n",
      "2022-04-13 12:52:17 [INFO]\t[TRAIN] Epoch=19/100, Step=4/87, loss_xy=119.094139, loss_wh=90.245804, loss_obj=143.827957, loss_cls=5.081290, loss=358.249207, lr=0.001000, time_each_step=1.74s, eta=3:28:18\n",
      "2022-04-13 12:52:37 [INFO]\t[TRAIN] Epoch=19/100, Step=14/87, loss_xy=308.680054, loss_wh=201.998840, loss_obj=458.706024, loss_cls=13.048273, loss=982.433167, lr=0.001000, time_each_step=1.92s, eta=3:49:44\n",
      "2022-04-13 12:52:50 [INFO]\t[TRAIN] Epoch=19/100, Step=24/87, loss_xy=273.641174, loss_wh=100.279427, loss_obj=540.238037, loss_cls=11.905976, loss=926.064636, lr=0.001000, time_each_step=1.35s, eta=2:42:7\n",
      "2022-04-13 12:53:05 [INFO]\t[TRAIN] Epoch=19/100, Step=34/87, loss_xy=454.840302, loss_wh=342.798584, loss_obj=740.666382, loss_cls=19.240234, loss=1557.545532, lr=0.001000, time_each_step=1.48s, eta=2:56:40\n",
      "2022-04-13 12:53:20 [INFO]\t[TRAIN] Epoch=19/100, Step=44/87, loss_xy=230.687531, loss_wh=253.987183, loss_obj=333.890259, loss_cls=9.747597, loss=828.312561, lr=0.001000, time_each_step=1.5s, eta=2:58:57\n",
      "2022-04-13 12:53:39 [INFO]\t[TRAIN] Epoch=19/100, Step=54/87, loss_xy=255.945908, loss_wh=111.490082, loss_obj=399.031494, loss_cls=10.910658, loss=777.378113, lr=0.001000, time_each_step=1.87s, eta=3:42:55\n",
      "2022-04-13 12:53:54 [INFO]\t[TRAIN] Epoch=19/100, Step=64/87, loss_xy=320.796204, loss_wh=258.351837, loss_obj=419.009491, loss_cls=13.554741, loss=1011.712341, lr=0.001000, time_each_step=1.5s, eta=2:58:37\n",
      "2022-04-13 12:54:06 [INFO]\t[TRAIN] Epoch=19/100, Step=74/87, loss_xy=315.852631, loss_wh=96.810715, loss_obj=687.366394, loss_cls=13.515512, loss=1113.545288, lr=0.001000, time_each_step=1.23s, eta=2:26:44\n",
      "2022-04-13 12:54:20 [INFO]\t[TRAIN] Epoch=19/100, Step=84/87, loss_xy=274.149048, loss_wh=61.098217, loss_obj=494.702576, loss_cls=11.801718, loss=841.751526, lr=0.001000, time_each_step=1.41s, eta=2:47:28\n",
      "2022-04-13 12:54:24 [INFO]\t[TRAIN] Epoch 19 finished, loss_xy=292.50156, loss_wh=178.4408, loss_obj=436.3347, loss_cls=12.480281, loss=919.75726 .\n",
      "2022-04-13 12:54:40 [INFO]\t[TRAIN] Epoch=20/100, Step=7/87, loss_xy=210.640747, loss_wh=102.499741, loss_obj=348.558350, loss_cls=9.011406, loss=670.710266, lr=0.001000, time_each_step=1.95s, eta=3:51:12\n",
      "2022-04-13 12:54:53 [INFO]\t[TRAIN] Epoch=20/100, Step=17/87, loss_xy=266.778015, loss_wh=92.063568, loss_obj=402.669495, loss_cls=11.307441, loss=772.818542, lr=0.001000, time_each_step=1.31s, eta=2:34:46\n",
      "2022-04-13 12:55:07 [INFO]\t[TRAIN] Epoch=20/100, Step=27/87, loss_xy=281.775604, loss_wh=141.154831, loss_obj=294.649841, loss_cls=12.004604, loss=729.584839, lr=0.001000, time_each_step=1.43s, eta=2:49:18\n",
      "2022-04-13 12:55:21 [INFO]\t[TRAIN] Epoch=20/100, Step=37/87, loss_xy=326.671936, loss_wh=191.513412, loss_obj=468.735168, loss_cls=13.820326, loss=1000.740845, lr=0.001000, time_each_step=1.41s, eta=2:47:6\n",
      "2022-04-13 12:55:37 [INFO]\t[TRAIN] Epoch=20/100, Step=47/87, loss_xy=200.081467, loss_wh=84.999832, loss_obj=218.006073, loss_cls=8.456661, loss=511.544037, lr=0.001000, time_each_step=1.53s, eta=3:0:46\n",
      "2022-04-13 12:55:52 [INFO]\t[TRAIN] Epoch=20/100, Step=57/87, loss_xy=224.181900, loss_wh=105.094337, loss_obj=385.089264, loss_cls=9.443846, loss=723.809326, lr=0.001000, time_each_step=1.56s, eta=3:3:15\n",
      "2022-04-13 12:56:04 [INFO]\t[TRAIN] Epoch=20/100, Step=67/87, loss_xy=274.514465, loss_wh=250.591141, loss_obj=431.171509, loss_cls=11.679331, loss=967.956421, lr=0.001000, time_each_step=1.21s, eta=2:22:50\n",
      "2022-04-13 12:56:18 [INFO]\t[TRAIN] Epoch=20/100, Step=77/87, loss_xy=166.495300, loss_wh=140.560974, loss_obj=230.708801, loss_cls=7.022581, loss=544.787659, lr=0.001000, time_each_step=1.35s, eta=2:38:51\n",
      "2022-04-13 12:56:33 [INFO]\t[TRAIN] Epoch=20/100, Step=87/87, loss_xy=258.684418, loss_wh=224.271713, loss_obj=329.998230, loss_cls=11.163818, loss=824.118164, lr=0.001000, time_each_step=1.54s, eta=3:0:7\n",
      "2022-04-13 12:56:33 [INFO]\t[TRAIN] Epoch 20 finished, loss_xy=298.28955, loss_wh=180.65466, loss_obj=458.06287, loss_cls=12.706128, loss=949.713 .\n",
      "2022-04-13 12:56:33 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 12:56:34 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 12:56:39 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 12:56:40 [INFO]\t[EVAL] Finished, Epoch=20, bbox_map=0.002029 .\n",
      "2022-04-13 12:56:40 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=0.11307100859339667\n",
      "2022-04-13 12:56:41 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_20.\n",
      "2022-04-13 12:56:58 [INFO]\t[TRAIN] Epoch=21/100, Step=10/87, loss_xy=300.608643, loss_wh=182.693787, loss_obj=513.113464, loss_cls=13.161905, loss=1009.577820, lr=0.001000, time_each_step=1.74s, eta=3:23:44\n",
      "2022-04-13 12:57:13 [INFO]\t[TRAIN] Epoch=21/100, Step=20/87, loss_xy=305.195709, loss_wh=158.878006, loss_obj=543.349121, loss_cls=12.935852, loss=1020.358704, lr=0.001000, time_each_step=1.47s, eta=2:51:32\n",
      "2022-04-13 12:57:29 [INFO]\t[TRAIN] Epoch=21/100, Step=30/87, loss_xy=249.802750, loss_wh=140.276031, loss_obj=395.667786, loss_cls=10.676538, loss=796.423096, lr=0.001000, time_each_step=1.59s, eta=3:5:39\n",
      "2022-04-13 12:57:44 [INFO]\t[TRAIN] Epoch=21/100, Step=40/87, loss_xy=345.957947, loss_wh=177.960052, loss_obj=628.360352, loss_cls=14.803003, loss=1167.081299, lr=0.001000, time_each_step=1.53s, eta=2:58:35\n",
      "2022-04-13 12:57:59 [INFO]\t[TRAIN] Epoch=21/100, Step=50/87, loss_xy=302.319702, loss_wh=130.609512, loss_obj=470.616608, loss_cls=12.768497, loss=916.314270, lr=0.001000, time_each_step=1.45s, eta=2:49:7\n",
      "2022-04-13 12:58:13 [INFO]\t[TRAIN] Epoch=21/100, Step=60/87, loss_xy=211.416870, loss_wh=48.354870, loss_obj=297.992706, loss_cls=8.945354, loss=566.709778, lr=0.001000, time_each_step=1.44s, eta=2:46:57\n",
      "2022-04-13 12:58:29 [INFO]\t[TRAIN] Epoch=21/100, Step=70/87, loss_xy=347.616577, loss_wh=143.946976, loss_obj=360.691498, loss_cls=14.633663, loss=866.888672, lr=0.001000, time_each_step=1.53s, eta=2:57:31\n",
      "2022-04-13 12:58:43 [INFO]\t[TRAIN] Epoch=21/100, Step=80/87, loss_xy=222.955322, loss_wh=144.094635, loss_obj=346.053833, loss_cls=9.686052, loss=722.789795, lr=0.001000, time_each_step=1.4s, eta=2:41:48\n",
      "2022-04-13 12:58:50 [INFO]\t[TRAIN] Epoch 21 finished, loss_xy=290.8111, loss_wh=146.9906, loss_obj=455.55222, loss_cls=12.421976, loss=905.7761 .\n",
      "2022-04-13 12:58:55 [INFO]\t[TRAIN] Epoch=22/100, Step=3/87, loss_xy=266.807617, loss_wh=172.659836, loss_obj=420.716949, loss_cls=11.265796, loss=871.450256, lr=0.001000, time_each_step=1.21s, eta=2:20:15\n",
      "2022-04-13 12:59:13 [INFO]\t[TRAIN] Epoch=22/100, Step=13/87, loss_xy=231.443420, loss_wh=134.409698, loss_obj=241.491974, loss_cls=9.779748, loss=617.124817, lr=0.001000, time_each_step=1.79s, eta=3:25:57\n",
      "2022-04-13 12:59:28 [INFO]\t[TRAIN] Epoch=22/100, Step=23/87, loss_xy=271.847443, loss_wh=130.112030, loss_obj=508.764404, loss_cls=11.706092, loss=922.429993, lr=0.001000, time_each_step=1.49s, eta=2:51:13\n",
      "2022-04-13 12:59:40 [INFO]\t[TRAIN] Epoch=22/100, Step=33/87, loss_xy=336.130157, loss_wh=110.818779, loss_obj=556.773804, loss_cls=14.208193, loss=1017.930969, lr=0.001000, time_each_step=1.26s, eta=2:25:2\n",
      "2022-04-13 12:59:54 [INFO]\t[TRAIN] Epoch=22/100, Step=43/87, loss_xy=202.936874, loss_wh=138.465851, loss_obj=306.628387, loss_cls=8.585763, loss=656.616882, lr=0.001000, time_each_step=1.41s, eta=2:41:53\n",
      "2022-04-13 13:00:08 [INFO]\t[TRAIN] Epoch=22/100, Step=53/87, loss_xy=256.186127, loss_wh=132.231445, loss_obj=381.628021, loss_cls=10.817565, loss=780.863159, lr=0.001000, time_each_step=1.38s, eta=2:38:53\n",
      "2022-04-13 13:00:20 [INFO]\t[TRAIN] Epoch=22/100, Step=63/87, loss_xy=191.314590, loss_wh=75.255211, loss_obj=253.551300, loss_cls=8.251429, loss=528.372498, lr=0.001000, time_each_step=1.21s, eta=2:18:45\n",
      "2022-04-13 13:00:36 [INFO]\t[TRAIN] Epoch=22/100, Step=73/87, loss_xy=365.886963, loss_wh=344.561249, loss_obj=449.541016, loss_cls=15.461086, loss=1175.450317, lr=0.001000, time_each_step=1.6s, eta=3:2:48\n",
      "2022-04-13 13:00:53 [INFO]\t[TRAIN] Epoch=22/100, Step=83/87, loss_xy=161.711151, loss_wh=206.292740, loss_obj=133.735474, loss_cls=6.849548, loss=508.588928, lr=0.001000, time_each_step=1.71s, eta=3:15:39\n",
      "2022-04-13 13:00:59 [INFO]\t[TRAIN] Epoch 22 finished, loss_xy=291.3011, loss_wh=189.98491, loss_obj=418.45523, loss_cls=12.442655, loss=912.18384 .\n",
      "2022-04-13 13:01:09 [INFO]\t[TRAIN] Epoch=23/100, Step=6/87, loss_xy=229.810242, loss_wh=150.282196, loss_obj=401.245972, loss_cls=9.769131, loss=791.107483, lr=0.001000, time_each_step=1.57s, eta=2:59:9\n",
      "2022-04-13 13:01:23 [INFO]\t[TRAIN] Epoch=23/100, Step=16/87, loss_xy=418.363861, loss_wh=150.498260, loss_obj=672.609741, loss_cls=17.719021, loss=1259.190918, lr=0.001000, time_each_step=1.39s, eta=2:38:37\n",
      "2022-04-13 13:01:40 [INFO]\t[TRAIN] Epoch=23/100, Step=26/87, loss_xy=380.746674, loss_wh=145.516479, loss_obj=763.138916, loss_cls=16.731899, loss=1306.134033, lr=0.001000, time_each_step=1.67s, eta=3:9:37\n",
      "2022-04-13 13:01:56 [INFO]\t[TRAIN] Epoch=23/100, Step=36/87, loss_xy=149.389893, loss_wh=72.206688, loss_obj=310.516876, loss_cls=6.494182, loss=538.607666, lr=0.001000, time_each_step=1.66s, eta=3:8:34\n",
      "2022-04-13 13:02:10 [INFO]\t[TRAIN] Epoch=23/100, Step=46/87, loss_xy=163.851349, loss_wh=89.145096, loss_obj=265.158569, loss_cls=7.513392, loss=525.668396, lr=0.001000, time_each_step=1.34s, eta=2:32:22\n",
      "2022-04-13 13:02:23 [INFO]\t[TRAIN] Epoch=23/100, Step=56/87, loss_xy=456.414062, loss_wh=225.585083, loss_obj=740.945251, loss_cls=19.337404, loss=1442.281738, lr=0.001000, time_each_step=1.29s, eta=2:25:49\n",
      "2022-04-13 13:02:38 [INFO]\t[TRAIN] Epoch=23/100, Step=66/87, loss_xy=293.438232, loss_wh=134.191849, loss_obj=396.001404, loss_cls=12.396982, loss=836.028442, lr=0.001000, time_each_step=1.54s, eta=2:54:33\n",
      "2022-04-13 13:02:54 [INFO]\t[TRAIN] Epoch=23/100, Step=76/87, loss_xy=188.873383, loss_wh=78.434357, loss_obj=364.692383, loss_cls=8.286889, loss=640.286987, lr=0.001000, time_each_step=1.6s, eta=3:0:4\n",
      "2022-04-13 13:03:08 [INFO]\t[TRAIN] Epoch=23/100, Step=86/87, loss_xy=220.663055, loss_wh=211.373199, loss_obj=249.899506, loss_cls=9.319994, loss=691.255798, lr=0.001000, time_each_step=1.42s, eta=2:40:5\n",
      "2022-04-13 13:03:09 [INFO]\t[TRAIN] Epoch 23 finished, loss_xy=282.69168, loss_wh=153.40616, loss_obj=417.65952, loss_cls=12.069746, loss=865.82697 .\n",
      "2022-04-13 13:03:26 [INFO]\t[TRAIN] Epoch=24/100, Step=9/87, loss_xy=124.023331, loss_wh=38.403561, loss_obj=240.864899, loss_cls=6.069284, loss=409.361084, lr=0.001000, time_each_step=1.75s, eta=3:16:49\n",
      "2022-04-13 13:03:39 [INFO]\t[TRAIN] Epoch=24/100, Step=19/87, loss_xy=407.190247, loss_wh=147.037415, loss_obj=547.079285, loss_cls=17.233812, loss=1118.540649, lr=0.001000, time_each_step=1.34s, eta=2:30:40\n",
      "2022-04-13 13:03:54 [INFO]\t[TRAIN] Epoch=24/100, Step=29/87, loss_xy=441.509674, loss_wh=316.325317, loss_obj=682.748657, loss_cls=18.763159, loss=1459.346802, lr=0.001000, time_each_step=1.46s, eta=2:44:22\n",
      "2022-04-13 13:04:07 [INFO]\t[TRAIN] Epoch=24/100, Step=39/87, loss_xy=277.868042, loss_wh=126.868317, loss_obj=454.255676, loss_cls=11.839582, loss=870.831665, lr=0.001000, time_each_step=1.28s, eta=2:23:32\n",
      "2022-04-13 13:04:20 [INFO]\t[TRAIN] Epoch=24/100, Step=49/87, loss_xy=276.562134, loss_wh=65.454201, loss_obj=450.819366, loss_cls=11.756769, loss=804.592468, lr=0.001000, time_each_step=1.37s, eta=2:33:47\n",
      "2022-04-13 13:04:33 [INFO]\t[TRAIN] Epoch=24/100, Step=59/87, loss_xy=404.319275, loss_wh=146.413620, loss_obj=662.225037, loss_cls=17.105381, loss=1230.063354, lr=0.001000, time_each_step=1.27s, eta=2:21:52\n",
      "2022-04-13 13:04:47 [INFO]\t[TRAIN] Epoch=24/100, Step=69/87, loss_xy=278.759705, loss_wh=212.771896, loss_obj=229.222656, loss_cls=11.775246, loss=732.529541, lr=0.001000, time_each_step=1.38s, eta=2:34:34\n",
      "2022-04-13 13:05:01 [INFO]\t[TRAIN] Epoch=24/100, Step=79/87, loss_xy=392.380035, loss_wh=169.355118, loss_obj=576.751953, loss_cls=16.628189, loss=1155.115234, lr=0.001000, time_each_step=1.46s, eta=2:42:37\n",
      "2022-04-13 13:05:12 [INFO]\t[TRAIN] Epoch 24 finished, loss_xy=311.22684, loss_wh=134.97456, loss_obj=460.00305, loss_cls=13.277279, loss=919.4817 .\n",
      "2022-04-13 13:05:16 [INFO]\t[TRAIN] Epoch=25/100, Step=2/87, loss_xy=257.818726, loss_wh=91.018555, loss_obj=429.871002, loss_cls=11.151361, loss=789.859619, lr=0.001000, time_each_step=1.41s, eta=2:36:36\n",
      "2022-04-13 13:05:30 [INFO]\t[TRAIN] Epoch=25/100, Step=12/87, loss_xy=219.806915, loss_wh=69.540703, loss_obj=240.870331, loss_cls=9.616058, loss=539.833984, lr=0.001000, time_each_step=1.44s, eta=2:39:26\n",
      "2022-04-13 13:05:44 [INFO]\t[TRAIN] Epoch=25/100, Step=22/87, loss_xy=309.890778, loss_wh=69.104233, loss_obj=508.514587, loss_cls=13.249519, loss=900.759094, lr=0.001000, time_each_step=1.43s, eta=2:38:54\n",
      "2022-04-13 13:06:00 [INFO]\t[TRAIN] Epoch=25/100, Step=32/87, loss_xy=335.867615, loss_wh=75.136948, loss_obj=492.596680, loss_cls=14.307265, loss=917.908508, lr=0.001000, time_each_step=1.55s, eta=2:51:16\n",
      "2022-04-13 13:06:12 [INFO]\t[TRAIN] Epoch=25/100, Step=42/87, loss_xy=194.232056, loss_wh=72.966003, loss_obj=249.017227, loss_cls=8.199060, loss=524.414307, lr=0.001000, time_each_step=1.26s, eta=2:19:3\n",
      "2022-04-13 13:06:25 [INFO]\t[TRAIN] Epoch=25/100, Step=52/87, loss_xy=146.643616, loss_wh=61.970657, loss_obj=145.243805, loss_cls=6.195920, loss=360.054016, lr=0.001000, time_each_step=1.29s, eta=2:22:34\n",
      "2022-04-13 13:06:43 [INFO]\t[TRAIN] Epoch=25/100, Step=62/87, loss_xy=196.290588, loss_wh=78.447556, loss_obj=432.158417, loss_cls=8.390594, loss=715.287231, lr=0.001000, time_each_step=1.74s, eta=3:11:3\n",
      "2022-04-13 13:06:58 [INFO]\t[TRAIN] Epoch=25/100, Step=72/87, loss_xy=411.674622, loss_wh=192.855988, loss_obj=626.436096, loss_cls=17.483871, loss=1248.450684, lr=0.001000, time_each_step=1.52s, eta=2:47:29\n",
      "2022-04-13 13:07:10 [INFO]\t[TRAIN] Epoch=25/100, Step=82/87, loss_xy=321.348938, loss_wh=116.617081, loss_obj=526.226074, loss_cls=13.585533, loss=977.777588, lr=0.001000, time_each_step=1.2s, eta=2:12:9\n",
      "2022-04-13 13:07:17 [INFO]\t[TRAIN] Epoch 25 finished, loss_xy=294.85632, loss_wh=126.70639, loss_obj=426.042, loss_cls=12.568118, loss=860.1728 .\n",
      "2022-04-13 13:07:17 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 13:07:17 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 13:07:24 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 13:07:24 [INFO]\t[EVAL] Finished, Epoch=25, bbox_map=12.852461 .\n",
      "2022-04-13 13:07:29 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 13:07:29 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_25, bbox_map=12.852461238547594\n",
      "2022-04-13 13:07:30 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_25.\n",
      "2022-04-13 13:07:40 [INFO]\t[TRAIN] Epoch=26/100, Step=5/87, loss_xy=306.457184, loss_wh=81.793945, loss_obj=341.515198, loss_cls=12.980584, loss=742.746948, lr=0.001000, time_each_step=1.68s, eta=3:5:54\n",
      "2022-04-13 13:07:55 [INFO]\t[TRAIN] Epoch=26/100, Step=15/87, loss_xy=323.389709, loss_wh=99.397675, loss_obj=424.900543, loss_cls=13.727010, loss=861.414917, lr=0.001000, time_each_step=1.52s, eta=2:47:24\n",
      "2022-04-13 13:08:11 [INFO]\t[TRAIN] Epoch=26/100, Step=25/87, loss_xy=366.280579, loss_wh=208.880783, loss_obj=539.632751, loss_cls=15.605491, loss=1130.399658, lr=0.001000, time_each_step=1.56s, eta=2:51:56\n",
      "2022-04-13 13:08:25 [INFO]\t[TRAIN] Epoch=26/100, Step=35/87, loss_xy=332.595398, loss_wh=214.089767, loss_obj=390.815704, loss_cls=14.104684, loss=951.605530, lr=0.001000, time_each_step=1.42s, eta=2:36:23\n",
      "2022-04-13 13:08:42 [INFO]\t[TRAIN] Epoch=26/100, Step=45/87, loss_xy=184.233337, loss_wh=63.243660, loss_obj=105.266853, loss_cls=7.775825, loss=360.519653, lr=0.001000, time_each_step=1.67s, eta=3:3:29\n",
      "2022-04-13 13:08:54 [INFO]\t[TRAIN] Epoch=26/100, Step=55/87, loss_xy=323.103424, loss_wh=88.707954, loss_obj=518.420471, loss_cls=13.770711, loss=944.002502, lr=0.001000, time_each_step=1.22s, eta=2:14:17\n",
      "2022-04-13 13:09:10 [INFO]\t[TRAIN] Epoch=26/100, Step=65/87, loss_xy=149.865311, loss_wh=86.361450, loss_obj=170.845657, loss_cls=6.305560, loss=413.377991, lr=0.001000, time_each_step=1.63s, eta=2:58:32\n",
      "2022-04-13 13:09:22 [INFO]\t[TRAIN] Epoch=26/100, Step=75/87, loss_xy=238.639481, loss_wh=97.375984, loss_obj=334.380096, loss_cls=10.089625, loss=680.485168, lr=0.001000, time_each_step=1.23s, eta=2:15:2\n",
      "2022-04-13 13:09:35 [INFO]\t[TRAIN] Epoch=26/100, Step=85/87, loss_xy=281.289673, loss_wh=76.430916, loss_obj=463.487427, loss_cls=12.192137, loss=833.400146, lr=0.001000, time_each_step=1.29s, eta=2:21:29\n",
      "2022-04-13 13:09:38 [INFO]\t[TRAIN] Epoch 26 finished, loss_xy=288.89328, loss_wh=155.22722, loss_obj=400.55154, loss_cls=12.356404, loss=857.0284 .\n",
      "2022-04-13 13:09:47 [INFO]\t[TRAIN] Epoch=27/100, Step=8/87, loss_xy=183.929962, loss_wh=52.440952, loss_obj=323.632263, loss_cls=8.411161, loss=568.414307, lr=0.001000, time_each_step=1.17s, eta=2:8:13\n",
      "2022-04-13 13:10:01 [INFO]\t[TRAIN] Epoch=27/100, Step=18/87, loss_xy=206.814117, loss_wh=68.086349, loss_obj=378.374695, loss_cls=8.911343, loss=662.186462, lr=0.001000, time_each_step=1.38s, eta=2:30:19\n",
      "2022-04-13 13:10:12 [INFO]\t[TRAIN] Epoch=27/100, Step=28/87, loss_xy=542.082520, loss_wh=140.529419, loss_obj=711.544983, loss_cls=23.080780, loss=1417.237793, lr=0.001000, time_each_step=1.14s, eta=2:5:11\n",
      "2022-04-13 13:10:29 [INFO]\t[TRAIN] Epoch=27/100, Step=38/87, loss_xy=481.819183, loss_wh=1087.571289, loss_obj=862.259521, loss_cls=20.774633, loss=2452.424561, lr=0.001000, time_each_step=1.7s, eta=3:4:13\n",
      "2022-04-13 13:10:44 [INFO]\t[TRAIN] Epoch=27/100, Step=48/87, loss_xy=247.118591, loss_wh=164.662369, loss_obj=401.463623, loss_cls=10.768209, loss=824.012756, lr=0.001000, time_each_step=1.41s, eta=2:32:40\n",
      "2022-04-13 13:11:00 [INFO]\t[TRAIN] Epoch=27/100, Step=58/87, loss_xy=206.325790, loss_wh=150.550644, loss_obj=294.529449, loss_cls=8.784782, loss=660.190674, lr=0.001000, time_each_step=1.69s, eta=3:3:9\n",
      "2022-04-13 13:11:14 [INFO]\t[TRAIN] Epoch=27/100, Step=68/87, loss_xy=373.953186, loss_wh=147.825272, loss_obj=510.683502, loss_cls=16.000967, loss=1048.462891, lr=0.001000, time_each_step=1.36s, eta=2:27:49\n",
      "2022-04-13 13:11:28 [INFO]\t[TRAIN] Epoch=27/100, Step=78/87, loss_xy=194.917175, loss_wh=103.275208, loss_obj=291.319641, loss_cls=8.480495, loss=597.992493, lr=0.001000, time_each_step=1.37s, eta=2:27:44\n",
      "2022-04-13 13:11:42 [INFO]\t[TRAIN] Epoch 27 finished, loss_xy=283.21606, loss_wh=171.74786, loss_obj=396.75812, loss_cls=12.162762, loss=863.88477 .\n",
      "2022-04-13 13:11:45 [INFO]\t[TRAIN] Epoch=28/100, Step=1/87, loss_xy=285.909851, loss_wh=92.828140, loss_obj=461.896118, loss_cls=12.831384, loss=853.465454, lr=0.001000, time_each_step=1.68s, eta=3:0:32\n",
      "2022-04-13 13:11:59 [INFO]\t[TRAIN] Epoch=28/100, Step=11/87, loss_xy=372.766174, loss_wh=389.459961, loss_obj=280.828522, loss_cls=15.728966, loss=1058.783691, lr=0.001000, time_each_step=1.44s, eta=2:34:36\n",
      "2022-04-13 13:12:13 [INFO]\t[TRAIN] Epoch=28/100, Step=21/87, loss_xy=353.566040, loss_wh=197.969543, loss_obj=380.057281, loss_cls=15.219027, loss=946.811951, lr=0.001000, time_each_step=1.36s, eta=2:26:0\n",
      "2022-04-13 13:12:24 [INFO]\t[TRAIN] Epoch=28/100, Step=31/87, loss_xy=219.518417, loss_wh=520.894470, loss_obj=187.841904, loss_cls=9.273395, loss=937.528198, lr=0.001000, time_each_step=1.16s, eta=2:5:11\n",
      "2022-04-13 13:12:39 [INFO]\t[TRAIN] Epoch=28/100, Step=41/87, loss_xy=222.906616, loss_wh=155.107208, loss_obj=340.122437, loss_cls=9.589190, loss=727.725403, lr=0.001000, time_each_step=1.46s, eta=2:36:17\n",
      "2022-04-13 13:12:58 [INFO]\t[TRAIN] Epoch=28/100, Step=51/87, loss_xy=253.038574, loss_wh=279.840393, loss_obj=350.479584, loss_cls=10.758710, loss=894.117249, lr=0.001000, time_each_step=1.88s, eta=3:20:30\n",
      "2022-04-13 13:13:13 [INFO]\t[TRAIN] Epoch=28/100, Step=61/87, loss_xy=337.819122, loss_wh=83.545959, loss_obj=540.051514, loss_cls=14.858033, loss=976.274658, lr=0.001000, time_each_step=1.54s, eta=2:44:24\n",
      "2022-04-13 13:13:27 [INFO]\t[TRAIN] Epoch=28/100, Step=71/87, loss_xy=351.288849, loss_wh=280.342255, loss_obj=383.902740, loss_cls=14.938104, loss=1030.471924, lr=0.001000, time_each_step=1.36s, eta=2:24:55\n",
      "2022-04-13 13:13:39 [INFO]\t[TRAIN] Epoch=28/100, Step=81/87, loss_xy=323.994904, loss_wh=188.207199, loss_obj=460.855774, loss_cls=13.815256, loss=986.873108, lr=0.001000, time_each_step=1.24s, eta=2:12:30\n",
      "2022-04-13 13:13:47 [INFO]\t[TRAIN] Epoch 28 finished, loss_xy=295.67752, loss_wh=198.16489, loss_obj=409.6771, loss_cls=12.729258, loss=916.2487 .\n",
      "2022-04-13 13:13:53 [INFO]\t[TRAIN] Epoch=29/100, Step=4/87, loss_xy=321.439026, loss_wh=216.846054, loss_obj=524.024292, loss_cls=13.545785, loss=1075.855103, lr=0.001000, time_each_step=1.39s, eta=2:27:33\n",
      "2022-04-13 13:14:08 [INFO]\t[TRAIN] Epoch=29/100, Step=14/87, loss_xy=364.562317, loss_wh=235.948151, loss_obj=534.122681, loss_cls=15.694616, loss=1150.327759, lr=0.001000, time_each_step=1.49s, eta=2:37:54\n",
      "2022-04-13 13:14:24 [INFO]\t[TRAIN] Epoch=29/100, Step=24/87, loss_xy=243.499100, loss_wh=99.733337, loss_obj=384.986847, loss_cls=10.435455, loss=738.654663, lr=0.001000, time_each_step=1.57s, eta=2:46:8\n",
      "2022-04-13 13:14:39 [INFO]\t[TRAIN] Epoch=29/100, Step=34/87, loss_xy=254.823853, loss_wh=131.352753, loss_obj=319.448242, loss_cls=10.865677, loss=716.490540, lr=0.001000, time_each_step=1.56s, eta=2:44:31\n",
      "2022-04-13 13:14:57 [INFO]\t[TRAIN] Epoch=29/100, Step=44/87, loss_xy=352.228210, loss_wh=168.515747, loss_obj=357.410034, loss_cls=14.935806, loss=893.089783, lr=0.001000, time_each_step=1.76s, eta=3:5:49\n",
      "2022-04-13 13:15:12 [INFO]\t[TRAIN] Epoch=29/100, Step=54/87, loss_xy=190.662689, loss_wh=129.921753, loss_obj=271.171265, loss_cls=8.163334, loss=599.919067, lr=0.001000, time_each_step=1.49s, eta=2:37:17\n",
      "2022-04-13 13:15:28 [INFO]\t[TRAIN] Epoch=29/100, Step=64/87, loss_xy=333.157776, loss_wh=137.244049, loss_obj=372.281250, loss_cls=14.058737, loss=856.741821, lr=0.001000, time_each_step=1.64s, eta=2:52:40\n",
      "2022-04-13 13:15:42 [INFO]\t[TRAIN] Epoch=29/100, Step=74/87, loss_xy=240.067169, loss_wh=194.285004, loss_obj=536.672668, loss_cls=10.297362, loss=981.322205, lr=0.001000, time_each_step=1.43s, eta=2:30:14\n",
      "2022-04-13 13:15:58 [INFO]\t[TRAIN] Epoch=29/100, Step=84/87, loss_xy=330.158813, loss_wh=302.734283, loss_obj=524.737732, loss_cls=14.165087, loss=1171.795898, lr=0.001000, time_each_step=1.59s, eta=2:46:17\n",
      "2022-04-13 13:16:00 [INFO]\t[TRAIN] Epoch 29 finished, loss_xy=284.4687, loss_wh=185.51064, loss_obj=403.30963, loss_cls=12.201484, loss=885.4905 .\n",
      "2022-04-13 13:16:11 [INFO]\t[TRAIN] Epoch=30/100, Step=7/87, loss_xy=447.196838, loss_wh=249.724442, loss_obj=753.398438, loss_cls=19.221729, loss=1469.541382, lr=0.001000, time_each_step=1.26s, eta=2:11:51\n",
      "2022-04-13 13:16:26 [INFO]\t[TRAIN] Epoch=30/100, Step=17/87, loss_xy=287.940582, loss_wh=115.529007, loss_obj=425.572510, loss_cls=12.322585, loss=841.364685, lr=0.001000, time_each_step=1.53s, eta=2:39:27\n",
      "2022-04-13 13:16:42 [INFO]\t[TRAIN] Epoch=30/100, Step=27/87, loss_xy=374.891998, loss_wh=261.033997, loss_obj=442.973663, loss_cls=16.341394, loss=1095.241089, lr=0.001000, time_each_step=1.54s, eta=2:40:20\n",
      "2022-04-13 13:16:57 [INFO]\t[TRAIN] Epoch=30/100, Step=37/87, loss_xy=412.325073, loss_wh=326.026764, loss_obj=653.162720, loss_cls=17.885239, loss=1409.399780, lr=0.001000, time_each_step=1.52s, eta=2:38:3\n",
      "2022-04-13 13:17:11 [INFO]\t[TRAIN] Epoch=30/100, Step=47/87, loss_xy=400.508911, loss_wh=147.726517, loss_obj=355.287476, loss_cls=16.878445, loss=920.401306, lr=0.001000, time_each_step=1.37s, eta=2:23:4\n",
      "2022-04-13 13:17:29 [INFO]\t[TRAIN] Epoch=30/100, Step=57/87, loss_xy=432.665009, loss_wh=407.100037, loss_obj=458.830017, loss_cls=18.515663, loss=1317.110596, lr=0.001000, time_each_step=1.82s, eta=3:8:23\n",
      "2022-04-13 13:17:47 [INFO]\t[TRAIN] Epoch=30/100, Step=67/87, loss_xy=254.962616, loss_wh=111.763870, loss_obj=423.471100, loss_cls=11.288126, loss=801.485779, lr=0.001000, time_each_step=1.84s, eta=3:10:15\n",
      "2022-04-13 13:18:00 [INFO]\t[TRAIN] Epoch=30/100, Step=77/87, loss_xy=281.622131, loss_wh=131.483002, loss_obj=440.229675, loss_cls=12.406018, loss=865.740845, lr=0.001000, time_each_step=1.32s, eta=2:17:20\n",
      "2022-04-13 13:18:16 [INFO]\t[TRAIN] Epoch=30/100, Step=87/87, loss_xy=201.587311, loss_wh=157.298828, loss_obj=302.498474, loss_cls=8.555887, loss=669.940552, lr=0.001000, time_each_step=1.56s, eta=2:41:22\n",
      "2022-04-13 13:18:16 [INFO]\t[TRAIN] Epoch 30 finished, loss_xy=286.35968, loss_wh=171.1398, loss_obj=401.98492, loss_cls=12.361213, loss=871.8455 .\n",
      "2022-04-13 13:18:16 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 13:18:17 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 13:18:22 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 13:18:22 [INFO]\t[EVAL] Finished, Epoch=30, bbox_map=14.442951 .\n",
      "2022-04-13 13:18:27 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 13:18:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_30, bbox_map=14.44295076457738\n",
      "2022-04-13 13:18:29 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_30.\n",
      "2022-04-13 13:18:42 [INFO]\t[TRAIN] Epoch=31/100, Step=10/87, loss_xy=441.745819, loss_wh=281.209717, loss_obj=531.024414, loss_cls=19.358089, loss=1273.338013, lr=0.001000, time_each_step=1.34s, eta=2:18:13\n",
      "2022-04-13 13:18:56 [INFO]\t[TRAIN] Epoch=31/100, Step=20/87, loss_xy=351.625916, loss_wh=233.046738, loss_obj=343.953796, loss_cls=15.613002, loss=944.239441, lr=0.001000, time_each_step=1.34s, eta=2:18:13\n",
      "2022-04-13 13:19:07 [INFO]\t[TRAIN] Epoch=31/100, Step=30/87, loss_xy=241.050156, loss_wh=124.014320, loss_obj=375.733582, loss_cls=10.272088, loss=751.070190, lr=0.001000, time_each_step=1.14s, eta=1:57:48\n",
      "2022-04-13 13:19:20 [INFO]\t[TRAIN] Epoch=31/100, Step=40/87, loss_xy=210.384689, loss_wh=42.390610, loss_obj=281.327209, loss_cls=9.091248, loss=543.193787, lr=0.001000, time_each_step=1.33s, eta=2:17:10\n",
      "2022-04-13 13:19:35 [INFO]\t[TRAIN] Epoch=31/100, Step=50/87, loss_xy=265.701874, loss_wh=162.790039, loss_obj=426.969940, loss_cls=11.680566, loss=867.142395, lr=0.001000, time_each_step=1.44s, eta=2:27:22\n",
      "2022-04-13 13:19:48 [INFO]\t[TRAIN] Epoch=31/100, Step=60/87, loss_xy=308.618134, loss_wh=115.960976, loss_obj=486.892883, loss_cls=13.719297, loss=925.191284, lr=0.001000, time_each_step=1.32s, eta=2:15:33\n",
      "2022-04-13 13:20:03 [INFO]\t[TRAIN] Epoch=31/100, Step=70/87, loss_xy=335.990448, loss_wh=124.130455, loss_obj=469.564362, loss_cls=14.911352, loss=944.596680, lr=0.001000, time_each_step=1.51s, eta=2:33:50\n",
      "2022-04-13 13:20:19 [INFO]\t[TRAIN] Epoch=31/100, Step=80/87, loss_xy=229.567703, loss_wh=73.420731, loss_obj=322.174957, loss_cls=9.767016, loss=634.930420, lr=0.001000, time_each_step=1.62s, eta=2:44:34\n",
      "2022-04-13 13:20:27 [INFO]\t[TRAIN] Epoch 31 finished, loss_xy=287.499, loss_wh=141.4661, loss_obj=402.225, loss_cls=12.516995, loss=843.7071 .\n",
      "2022-04-13 13:20:32 [INFO]\t[TRAIN] Epoch=32/100, Step=3/87, loss_xy=308.169342, loss_wh=70.076897, loss_obj=436.610077, loss_cls=13.246146, loss=828.102478, lr=0.001000, time_each_step=1.28s, eta=2:10:19\n",
      "2022-04-13 13:20:45 [INFO]\t[TRAIN] Epoch=32/100, Step=13/87, loss_xy=302.866058, loss_wh=72.509613, loss_obj=375.951538, loss_cls=13.319514, loss=764.646729, lr=0.001000, time_each_step=1.28s, eta=2:10:41\n",
      "2022-04-13 13:21:01 [INFO]\t[TRAIN] Epoch=32/100, Step=23/87, loss_xy=330.578247, loss_wh=414.623108, loss_obj=204.736420, loss_cls=13.987468, loss=963.925232, lr=0.001000, time_each_step=1.61s, eta=2:43:1\n",
      "2022-04-13 13:21:12 [INFO]\t[TRAIN] Epoch=32/100, Step=33/87, loss_xy=262.095093, loss_wh=183.312088, loss_obj=359.191376, loss_cls=11.612028, loss=816.210510, lr=0.001000, time_each_step=1.1s, eta=1:51:38\n",
      "2022-04-13 13:21:26 [INFO]\t[TRAIN] Epoch=32/100, Step=43/87, loss_xy=402.837860, loss_wh=664.127930, loss_obj=327.242981, loss_cls=17.182964, loss=1411.391724, lr=0.001000, time_each_step=1.41s, eta=2:22:51\n",
      "2022-04-13 13:21:40 [INFO]\t[TRAIN] Epoch=32/100, Step=53/87, loss_xy=329.134155, loss_wh=194.325378, loss_obj=471.778778, loss_cls=14.501180, loss=1009.739441, lr=0.001000, time_each_step=1.4s, eta=2:21:9\n",
      "2022-04-13 13:21:55 [INFO]\t[TRAIN] Epoch=32/100, Step=63/87, loss_xy=252.361557, loss_wh=112.251549, loss_obj=360.419342, loss_cls=10.991499, loss=736.023987, lr=0.001000, time_each_step=1.47s, eta=2:28:12\n",
      "2022-04-13 13:22:07 [INFO]\t[TRAIN] Epoch=32/100, Step=73/87, loss_xy=514.221558, loss_wh=129.017883, loss_obj=556.464661, loss_cls=21.768070, loss=1221.472168, lr=0.001000, time_each_step=1.22s, eta=2:3:18\n",
      "2022-04-13 13:22:24 [INFO]\t[TRAIN] Epoch=32/100, Step=83/87, loss_xy=255.180023, loss_wh=54.417175, loss_obj=482.397308, loss_cls=11.080847, loss=803.075378, lr=0.001000, time_each_step=1.68s, eta=2:48:20\n",
      "2022-04-13 13:22:28 [INFO]\t[TRAIN] Epoch 32 finished, loss_xy=293.42313, loss_wh=168.06163, loss_obj=399.43005, loss_cls=12.8018675, loss=873.7168 .\n",
      "2022-04-13 13:22:39 [INFO]\t[TRAIN] Epoch=33/100, Step=6/87, loss_xy=176.928558, loss_wh=78.348579, loss_obj=250.936218, loss_cls=7.613967, loss=513.827332, lr=0.001000, time_each_step=1.53s, eta=2:33:43\n",
      "2022-04-13 13:22:55 [INFO]\t[TRAIN] Epoch=33/100, Step=16/87, loss_xy=277.842651, loss_wh=139.134415, loss_obj=260.729950, loss_cls=12.013436, loss=689.720459, lr=0.001000, time_each_step=1.52s, eta=2:32:29\n",
      "2022-04-13 13:23:12 [INFO]\t[TRAIN] Epoch=33/100, Step=26/87, loss_xy=388.847717, loss_wh=253.004730, loss_obj=323.085785, loss_cls=16.632648, loss=981.570862, lr=0.001000, time_each_step=1.73s, eta=2:52:36\n",
      "2022-04-13 13:23:23 [INFO]\t[TRAIN] Epoch=33/100, Step=36/87, loss_xy=325.193787, loss_wh=133.378448, loss_obj=529.293884, loss_cls=14.307188, loss=1002.173279, lr=0.001000, time_each_step=1.16s, eta=1:56:16\n",
      "2022-04-13 13:23:35 [INFO]\t[TRAIN] Epoch=33/100, Step=46/87, loss_xy=441.569702, loss_wh=155.994888, loss_obj=623.838196, loss_cls=18.561350, loss=1239.964233, lr=0.001000, time_each_step=1.19s, eta=1:58:52\n",
      "2022-04-13 13:23:51 [INFO]\t[TRAIN] Epoch=33/100, Step=56/87, loss_xy=260.365387, loss_wh=73.649277, loss_obj=388.726868, loss_cls=12.077622, loss=734.819153, lr=0.001000, time_each_step=1.52s, eta=2:30:44\n",
      "2022-04-13 13:24:05 [INFO]\t[TRAIN] Epoch=33/100, Step=66/87, loss_xy=219.396057, loss_wh=108.946838, loss_obj=182.171799, loss_cls=9.241501, loss=519.756226, lr=0.001000, time_each_step=1.44s, eta=2:22:57\n",
      "2022-04-13 13:24:20 [INFO]\t[TRAIN] Epoch=33/100, Step=76/87, loss_xy=292.080475, loss_wh=69.680313, loss_obj=418.151123, loss_cls=12.907217, loss=792.819153, lr=0.001000, time_each_step=1.47s, eta=2:25:22\n",
      "2022-04-13 13:24:31 [INFO]\t[TRAIN] Epoch=33/100, Step=86/87, loss_xy=303.504822, loss_wh=134.327423, loss_obj=409.523285, loss_cls=13.713582, loss=861.069092, lr=0.001000, time_each_step=1.15s, eta=1:54:35\n",
      "2022-04-13 13:24:34 [INFO]\t[TRAIN] Epoch 33 finished, loss_xy=266.4016, loss_wh=129.26093, loss_obj=350.0369, loss_cls=11.661402, loss=757.3609 .\n",
      "2022-04-13 13:24:48 [INFO]\t[TRAIN] Epoch=34/100, Step=9/87, loss_xy=181.958267, loss_wh=176.745071, loss_obj=335.255341, loss_cls=7.744745, loss=701.703430, lr=0.001000, time_each_step=1.63s, eta=2:40:59\n",
      "2022-04-13 13:25:06 [INFO]\t[TRAIN] Epoch=34/100, Step=19/87, loss_xy=268.875702, loss_wh=361.012939, loss_obj=354.302856, loss_cls=11.775126, loss=995.966675, lr=0.001000, time_each_step=1.79s, eta=2:56:13\n",
      "2022-04-13 13:25:20 [INFO]\t[TRAIN] Epoch=34/100, Step=29/87, loss_xy=237.906677, loss_wh=101.958374, loss_obj=323.265381, loss_cls=10.197406, loss=673.327820, lr=0.001000, time_each_step=1.49s, eta=2:27:4\n",
      "2022-04-13 13:25:35 [INFO]\t[TRAIN] Epoch=34/100, Step=39/87, loss_xy=189.807327, loss_wh=166.779922, loss_obj=243.078964, loss_cls=8.243189, loss=607.909363, lr=0.001000, time_each_step=1.42s, eta=2:19:50\n",
      "2022-04-13 13:25:45 [INFO]\t[TRAIN] Epoch=34/100, Step=49/87, loss_xy=361.652985, loss_wh=162.465225, loss_obj=621.106262, loss_cls=15.465351, loss=1160.689819, lr=0.001000, time_each_step=1.05s, eta=1:43:44\n",
      "2022-04-13 13:25:59 [INFO]\t[TRAIN] Epoch=34/100, Step=59/87, loss_xy=244.204987, loss_wh=132.586288, loss_obj=370.487976, loss_cls=10.623715, loss=757.902954, lr=0.001000, time_each_step=1.37s, eta=2:14:34\n",
      "2022-04-13 13:26:12 [INFO]\t[TRAIN] Epoch=34/100, Step=69/87, loss_xy=236.153229, loss_wh=82.014999, loss_obj=323.150391, loss_cls=10.480107, loss=651.798706, lr=0.001000, time_each_step=1.34s, eta=2:11:17\n",
      "2022-04-13 13:26:30 [INFO]\t[TRAIN] Epoch=34/100, Step=79/87, loss_xy=241.252441, loss_wh=144.327652, loss_obj=333.858612, loss_cls=10.546335, loss=729.985046, lr=0.001000, time_each_step=1.75s, eta=2:50:28\n",
      "2022-04-13 13:26:40 [INFO]\t[TRAIN] Epoch 34 finished, loss_xy=297.9085, loss_wh=199.72823, loss_obj=394.3709, loss_cls=12.966544, loss=904.9741 .\n",
      "2022-04-13 13:26:45 [INFO]\t[TRAIN] Epoch=35/100, Step=2/87, loss_xy=347.170593, loss_wh=195.591110, loss_obj=510.912994, loss_cls=14.925121, loss=1068.599854, lr=0.001000, time_each_step=1.53s, eta=2:29:1\n",
      "2022-04-13 13:26:57 [INFO]\t[TRAIN] Epoch=35/100, Step=12/87, loss_xy=221.756042, loss_wh=64.969200, loss_obj=364.487183, loss_cls=9.901464, loss=661.113892, lr=0.001000, time_each_step=1.2s, eta=1:56:43\n",
      "2022-04-13 13:27:12 [INFO]\t[TRAIN] Epoch=35/100, Step=22/87, loss_xy=146.143478, loss_wh=57.752220, loss_obj=275.114532, loss_cls=6.336460, loss=485.346680, lr=0.001000, time_each_step=1.5s, eta=2:25:31\n",
      "2022-04-13 13:27:27 [INFO]\t[TRAIN] Epoch=35/100, Step=32/87, loss_xy=250.537659, loss_wh=138.253448, loss_obj=367.336151, loss_cls=11.772779, loss=767.900024, lr=0.001000, time_each_step=1.44s, eta=2:19:23\n",
      "2022-04-13 13:27:42 [INFO]\t[TRAIN] Epoch=35/100, Step=42/87, loss_xy=433.431702, loss_wh=261.388641, loss_obj=644.713074, loss_cls=18.681635, loss=1358.215088, lr=0.001000, time_each_step=1.56s, eta=2:30:31\n",
      "2022-04-13 13:27:55 [INFO]\t[TRAIN] Epoch=35/100, Step=52/87, loss_xy=412.355438, loss_wh=207.754333, loss_obj=625.987122, loss_cls=17.679081, loss=1263.776001, lr=0.001000, time_each_step=1.3s, eta=2:6:7\n",
      "2022-04-13 13:28:07 [INFO]\t[TRAIN] Epoch=35/100, Step=62/87, loss_xy=186.411819, loss_wh=51.076481, loss_obj=292.043640, loss_cls=8.047578, loss=537.579529, lr=0.001000, time_each_step=1.21s, eta=1:57:0\n",
      "2022-04-13 13:28:21 [INFO]\t[TRAIN] Epoch=35/100, Step=72/87, loss_xy=257.675415, loss_wh=58.206188, loss_obj=271.136810, loss_cls=11.113894, loss=598.132324, lr=0.001000, time_each_step=1.36s, eta=2:11:23\n",
      "2022-04-13 13:28:31 [INFO]\t[TRAIN] Epoch=35/100, Step=82/87, loss_xy=363.203003, loss_wh=111.362206, loss_obj=536.309998, loss_cls=15.904747, loss=1026.780029, lr=0.001000, time_each_step=1.02s, eta=1:38:47\n",
      "2022-04-13 13:28:40 [INFO]\t[TRAIN] Epoch 35 finished, loss_xy=275.67914, loss_wh=119.881355, loss_obj=380.61996, loss_cls=12.095399, loss=788.27594 .\n",
      "2022-04-13 13:28:40 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 13:28:41 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 13:28:48 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 13:28:48 [INFO]\t[EVAL] Finished, Epoch=35, bbox_map=22.667333 .\n",
      "2022-04-13 13:28:53 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 13:28:53 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_35, bbox_map=22.66733286293076\n",
      "2022-04-13 13:28:54 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_35.\n",
      "2022-04-13 13:29:03 [INFO]\t[TRAIN] Epoch=36/100, Step=5/87, loss_xy=287.405609, loss_wh=137.960632, loss_obj=284.966309, loss_cls=12.728150, loss=723.060669, lr=0.001000, time_each_step=1.73s, eta=2:45:24\n",
      "2022-04-13 13:29:17 [INFO]\t[TRAIN] Epoch=36/100, Step=15/87, loss_xy=436.113037, loss_wh=145.175247, loss_obj=607.940552, loss_cls=19.223049, loss=1208.451782, lr=0.001000, time_each_step=1.42s, eta=2:16:39\n",
      "2022-04-13 13:29:32 [INFO]\t[TRAIN] Epoch=36/100, Step=25/87, loss_xy=204.314270, loss_wh=78.759361, loss_obj=192.651443, loss_cls=8.575928, loss=484.301025, lr=0.001000, time_each_step=1.51s, eta=2:24:0\n",
      "2022-04-13 13:29:44 [INFO]\t[TRAIN] Epoch=36/100, Step=35/87, loss_xy=173.439941, loss_wh=37.776859, loss_obj=362.080292, loss_cls=7.601544, loss=580.898682, lr=0.001000, time_each_step=1.14s, eta=1:49:35\n",
      "2022-04-13 13:29:58 [INFO]\t[TRAIN] Epoch=36/100, Step=45/87, loss_xy=475.417511, loss_wh=369.278870, loss_obj=688.313660, loss_cls=21.048132, loss=1554.058105, lr=0.001000, time_each_step=1.4s, eta=2:14:8\n",
      "2022-04-13 13:30:12 [INFO]\t[TRAIN] Epoch=36/100, Step=55/87, loss_xy=245.943298, loss_wh=96.696983, loss_obj=472.549286, loss_cls=11.106520, loss=826.296082, lr=0.001000, time_each_step=1.4s, eta=2:13:49\n",
      "2022-04-13 13:30:24 [INFO]\t[TRAIN] Epoch=36/100, Step=65/87, loss_xy=231.471298, loss_wh=73.300514, loss_obj=275.085419, loss_cls=10.637116, loss=590.494385, lr=0.001000, time_each_step=1.27s, eta=2:1:7\n",
      "2022-04-13 13:30:36 [INFO]\t[TRAIN] Epoch=36/100, Step=75/87, loss_xy=228.421341, loss_wh=92.545280, loss_obj=207.150345, loss_cls=10.653811, loss=538.770752, lr=0.001000, time_each_step=1.19s, eta=1:53:4\n",
      "2022-04-13 13:30:49 [INFO]\t[TRAIN] Epoch=36/100, Step=85/87, loss_xy=160.857086, loss_wh=40.139915, loss_obj=362.625641, loss_cls=7.541543, loss=571.164246, lr=0.001000, time_each_step=1.29s, eta=2:2:47\n",
      "2022-04-13 13:30:51 [INFO]\t[TRAIN] Epoch 36 finished, loss_xy=290.65125, loss_wh=129.0567, loss_obj=386.91617, loss_cls=12.823841, loss=819.4478 .\n",
      "2022-04-13 13:31:03 [INFO]\t[TRAIN] Epoch=37/100, Step=8/87, loss_xy=269.417969, loss_wh=129.193115, loss_obj=311.094269, loss_cls=11.770308, loss=721.475647, lr=0.001000, time_each_step=1.36s, eta=2:8:21\n",
      "2022-04-13 13:31:21 [INFO]\t[TRAIN] Epoch=37/100, Step=18/87, loss_xy=187.125275, loss_wh=57.060188, loss_obj=218.772369, loss_cls=8.168292, loss=471.126129, lr=0.001000, time_each_step=1.81s, eta=2:50:10\n",
      "2022-04-13 13:31:34 [INFO]\t[TRAIN] Epoch=37/100, Step=28/87, loss_xy=456.011139, loss_wh=125.267601, loss_obj=363.824310, loss_cls=19.370537, loss=964.473572, lr=0.001000, time_each_step=1.32s, eta=2:4:54\n",
      "2022-04-13 13:31:47 [INFO]\t[TRAIN] Epoch=37/100, Step=38/87, loss_xy=111.063377, loss_wh=38.382710, loss_obj=132.123047, loss_cls=5.095303, loss=286.664459, lr=0.001000, time_each_step=1.29s, eta=2:1:45\n",
      "2022-04-13 13:32:02 [INFO]\t[TRAIN] Epoch=37/100, Step=48/87, loss_xy=240.514435, loss_wh=124.693176, loss_obj=154.583771, loss_cls=10.185176, loss=529.976562, lr=0.001000, time_each_step=1.45s, eta=2:15:54\n",
      "2022-04-13 13:32:16 [INFO]\t[TRAIN] Epoch=37/100, Step=58/87, loss_xy=442.165161, loss_wh=165.334946, loss_obj=667.184326, loss_cls=18.751228, loss=1293.435669, lr=0.001000, time_each_step=1.45s, eta=2:15:50\n",
      "2022-04-13 13:32:32 [INFO]\t[TRAIN] Epoch=37/100, Step=68/87, loss_xy=213.196396, loss_wh=84.034447, loss_obj=353.349243, loss_cls=9.495647, loss=660.075745, lr=0.001000, time_each_step=1.63s, eta=2:32:29\n",
      "2022-04-13 13:32:48 [INFO]\t[TRAIN] Epoch=37/100, Step=78/87, loss_xy=345.407990, loss_wh=194.108536, loss_obj=406.632477, loss_cls=15.276878, loss=961.425903, lr=0.001000, time_each_step=1.51s, eta=2:20:46\n",
      "2022-04-13 13:32:58 [INFO]\t[TRAIN] Epoch 37 finished, loss_xy=280.3517, loss_wh=120.93061, loss_obj=348.63828, loss_cls=12.324773, loss=762.2453 .\n",
      "2022-04-13 13:33:02 [INFO]\t[TRAIN] Epoch=38/100, Step=1/87, loss_xy=191.887497, loss_wh=99.013306, loss_obj=180.849457, loss_cls=8.145882, loss=479.896149, lr=0.001000, time_each_step=1.48s, eta=2:17:45\n",
      "2022-04-13 13:33:18 [INFO]\t[TRAIN] Epoch=38/100, Step=11/87, loss_xy=219.351868, loss_wh=109.794800, loss_obj=134.158020, loss_cls=9.252532, loss=472.557220, lr=0.001000, time_each_step=1.57s, eta=2:25:50\n",
      "2022-04-13 13:33:34 [INFO]\t[TRAIN] Epoch=38/100, Step=21/87, loss_xy=251.308807, loss_wh=92.517754, loss_obj=301.987793, loss_cls=11.253056, loss=657.067383, lr=0.001000, time_each_step=1.6s, eta=2:28:3\n",
      "2022-04-13 13:33:49 [INFO]\t[TRAIN] Epoch=38/100, Step=31/87, loss_xy=256.769745, loss_wh=52.502228, loss_obj=531.561768, loss_cls=11.262482, loss=852.096191, lr=0.001000, time_each_step=1.51s, eta=2:19:43\n",
      "2022-04-13 13:34:07 [INFO]\t[TRAIN] Epoch=38/100, Step=41/87, loss_xy=245.621521, loss_wh=196.758392, loss_obj=235.708588, loss_cls=10.429873, loss=688.518372, lr=0.001000, time_each_step=1.78s, eta=2:44:9\n",
      "2022-04-13 13:34:21 [INFO]\t[TRAIN] Epoch=38/100, Step=51/87, loss_xy=126.905830, loss_wh=70.168961, loss_obj=138.990967, loss_cls=5.777003, loss=341.842773, lr=0.001000, time_each_step=1.42s, eta=2:11:1\n",
      "2022-04-13 13:34:34 [INFO]\t[TRAIN] Epoch=38/100, Step=61/87, loss_xy=516.546753, loss_wh=359.374084, loss_obj=624.427368, loss_cls=22.342300, loss=1522.690430, lr=0.001000, time_each_step=1.25s, eta=1:55:48\n",
      "2022-04-13 13:34:47 [INFO]\t[TRAIN] Epoch=38/100, Step=71/87, loss_xy=247.330460, loss_wh=130.361282, loss_obj=345.717926, loss_cls=11.897875, loss=735.307556, lr=0.001000, time_each_step=1.32s, eta=2:1:42\n",
      "2022-04-13 13:35:04 [INFO]\t[TRAIN] Epoch=38/100, Step=81/87, loss_xy=157.004593, loss_wh=45.345520, loss_obj=86.750816, loss_cls=6.630679, loss=295.731598, lr=0.001000, time_each_step=1.67s, eta=2:33:22\n",
      "2022-04-13 13:35:10 [INFO]\t[TRAIN] Epoch 38 finished, loss_xy=279.6479, loss_wh=143.27257, loss_obj=336.30896, loss_cls=12.325002, loss=771.55444 .\n",
      "2022-04-13 13:35:17 [INFO]\t[TRAIN] Epoch=39/100, Step=4/87, loss_xy=348.826172, loss_wh=213.346619, loss_obj=525.054321, loss_cls=15.204987, loss=1102.432007, lr=0.001000, time_each_step=1.34s, eta=2:2:50\n",
      "2022-04-13 13:35:31 [INFO]\t[TRAIN] Epoch=39/100, Step=14/87, loss_xy=310.584564, loss_wh=95.912460, loss_obj=420.942352, loss_cls=13.332798, loss=840.772156, lr=0.001000, time_each_step=1.43s, eta=2:11:25\n",
      "2022-04-13 13:35:45 [INFO]\t[TRAIN] Epoch=39/100, Step=24/87, loss_xy=353.915894, loss_wh=103.030045, loss_obj=488.305634, loss_cls=16.031927, loss=961.283508, lr=0.001000, time_each_step=1.4s, eta=2:8:5\n",
      "2022-04-13 13:35:59 [INFO]\t[TRAIN] Epoch=39/100, Step=34/87, loss_xy=279.594757, loss_wh=105.648819, loss_obj=221.481018, loss_cls=12.011605, loss=618.736206, lr=0.001000, time_each_step=1.38s, eta=2:6:10\n",
      "2022-04-13 13:36:15 [INFO]\t[TRAIN] Epoch=39/100, Step=44/87, loss_xy=302.143982, loss_wh=104.618767, loss_obj=451.436005, loss_cls=13.057896, loss=871.256653, lr=0.001000, time_each_step=1.55s, eta=2:21:0\n",
      "2022-04-13 13:36:28 [INFO]\t[TRAIN] Epoch=39/100, Step=54/87, loss_xy=332.757935, loss_wh=335.248718, loss_obj=405.218903, loss_cls=14.462177, loss=1087.687744, lr=0.001000, time_each_step=1.35s, eta=2:2:48\n",
      "2022-04-13 13:36:42 [INFO]\t[TRAIN] Epoch=39/100, Step=64/87, loss_xy=157.318405, loss_wh=33.441193, loss_obj=243.788483, loss_cls=6.714073, loss=441.262177, lr=0.001000, time_each_step=1.37s, eta=2:4:29\n",
      "2022-04-13 13:36:54 [INFO]\t[TRAIN] Epoch=39/100, Step=74/87, loss_xy=214.571808, loss_wh=119.032150, loss_obj=139.775146, loss_cls=9.055054, loss=482.434143, lr=0.001000, time_each_step=1.26s, eta=1:54:4\n",
      "2022-04-13 13:37:09 [INFO]\t[TRAIN] Epoch=39/100, Step=84/87, loss_xy=413.164032, loss_wh=137.898285, loss_obj=519.721924, loss_cls=17.758951, loss=1088.543091, lr=0.001000, time_each_step=1.41s, eta=2:7:12\n",
      "2022-04-13 13:37:15 [INFO]\t[TRAIN] Epoch 39 finished, loss_xy=289.66113, loss_wh=126.046875, loss_obj=396.69604, loss_cls=12.723678, loss=825.12787 .\n",
      "2022-04-13 13:37:27 [INFO]\t[TRAIN] Epoch=40/100, Step=7/87, loss_xy=209.088074, loss_wh=90.422379, loss_obj=161.545334, loss_cls=8.827520, loss=469.883301, lr=0.001000, time_each_step=1.8s, eta=2:41:14\n",
      "2022-04-13 13:37:39 [INFO]\t[TRAIN] Epoch=40/100, Step=17/87, loss_xy=265.459442, loss_wh=58.935966, loss_obj=385.938416, loss_cls=12.119979, loss=722.453857, lr=0.001000, time_each_step=1.19s, eta=1:47:10\n",
      "2022-04-13 13:37:54 [INFO]\t[TRAIN] Epoch=40/100, Step=27/87, loss_xy=300.392578, loss_wh=120.462738, loss_obj=363.375427, loss_cls=13.126349, loss=797.357056, lr=0.001000, time_each_step=1.49s, eta=2:13:31\n",
      "2022-04-13 13:38:10 [INFO]\t[TRAIN] Epoch=40/100, Step=37/87, loss_xy=186.586914, loss_wh=50.165131, loss_obj=178.816711, loss_cls=8.018776, loss=423.587524, lr=0.001000, time_each_step=1.69s, eta=2:30:37\n",
      "2022-04-13 13:38:25 [INFO]\t[TRAIN] Epoch=40/100, Step=47/87, loss_xy=225.733490, loss_wh=110.837448, loss_obj=142.279648, loss_cls=9.498106, loss=488.348694, lr=0.001000, time_each_step=1.49s, eta=2:12:48\n",
      "2022-04-13 13:38:42 [INFO]\t[TRAIN] Epoch=40/100, Step=57/87, loss_xy=351.229797, loss_wh=184.280960, loss_obj=535.473633, loss_cls=15.447711, loss=1086.432129, lr=0.001000, time_each_step=1.69s, eta=2:30:40\n",
      "2022-04-13 13:38:55 [INFO]\t[TRAIN] Epoch=40/100, Step=67/87, loss_xy=370.101440, loss_wh=131.430267, loss_obj=545.422241, loss_cls=17.063095, loss=1064.017090, lr=0.001000, time_each_step=1.27s, eta=1:53:4\n",
      "2022-04-13 13:39:08 [INFO]\t[TRAIN] Epoch=40/100, Step=77/87, loss_xy=204.760895, loss_wh=62.005333, loss_obj=332.198059, loss_cls=8.948120, loss=607.912415, lr=0.001000, time_each_step=1.32s, eta=1:57:45\n",
      "2022-04-13 13:39:20 [INFO]\t[TRAIN] Epoch=40/100, Step=87/87, loss_xy=345.707153, loss_wh=265.846985, loss_obj=374.556885, loss_cls=14.800025, loss=1000.911072, lr=0.001000, time_each_step=1.21s, eta=1:47:32\n",
      "2022-04-13 13:39:20 [INFO]\t[TRAIN] Epoch 40 finished, loss_xy=268.25418, loss_wh=131.40001, loss_obj=349.22366, loss_cls=11.871246, loss=760.7492 .\n",
      "2022-04-13 13:39:20 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 13:39:21 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 13:39:27 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 13:39:27 [INFO]\t[EVAL] Finished, Epoch=40, bbox_map=15.581350 .\n",
      "2022-04-13 13:39:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_35, bbox_map=22.66733286293076\n",
      "2022-04-13 13:39:29 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_40.\n",
      "2022-04-13 13:39:46 [INFO]\t[TRAIN] Epoch=41/100, Step=10/87, loss_xy=210.696442, loss_wh=100.760925, loss_obj=292.531128, loss_cls=9.226757, loss=613.215271, lr=0.001000, time_each_step=1.77s, eta=2:35:19\n",
      "2022-04-13 13:40:01 [INFO]\t[TRAIN] Epoch=41/100, Step=20/87, loss_xy=322.848633, loss_wh=137.749878, loss_obj=415.148834, loss_cls=13.962435, loss=889.709778, lr=0.001000, time_each_step=1.47s, eta=2:9:6\n",
      "2022-04-13 13:40:14 [INFO]\t[TRAIN] Epoch=41/100, Step=30/87, loss_xy=185.733307, loss_wh=88.694466, loss_obj=283.384583, loss_cls=8.313170, loss=566.125549, lr=0.001000, time_each_step=1.28s, eta=1:52:24\n",
      "2022-04-13 13:40:26 [INFO]\t[TRAIN] Epoch=41/100, Step=40/87, loss_xy=95.544449, loss_wh=57.557465, loss_obj=306.751038, loss_cls=4.678096, loss=464.531067, lr=0.001000, time_each_step=1.24s, eta=1:48:25\n",
      "2022-04-13 13:40:38 [INFO]\t[TRAIN] Epoch=41/100, Step=50/87, loss_xy=383.565491, loss_wh=112.784027, loss_obj=430.545013, loss_cls=17.214911, loss=944.109436, lr=0.001000, time_each_step=1.14s, eta=1:39:36\n",
      "2022-04-13 13:40:55 [INFO]\t[TRAIN] Epoch=41/100, Step=60/87, loss_xy=293.722382, loss_wh=101.218262, loss_obj=492.940735, loss_cls=12.849271, loss=900.730591, lr=0.001000, time_each_step=1.76s, eta=2:33:9\n",
      "2022-04-13 13:41:10 [INFO]\t[TRAIN] Epoch=41/100, Step=70/87, loss_xy=255.585480, loss_wh=84.371109, loss_obj=380.853577, loss_cls=11.334604, loss=732.144775, lr=0.001000, time_each_step=1.41s, eta=2:2:4\n",
      "2022-04-13 13:41:23 [INFO]\t[TRAIN] Epoch=41/100, Step=80/87, loss_xy=279.436462, loss_wh=66.623474, loss_obj=465.729553, loss_cls=12.510389, loss=824.299866, lr=0.001000, time_each_step=1.36s, eta=1:57:55\n",
      "2022-04-13 13:41:32 [INFO]\t[TRAIN] Epoch 41 finished, loss_xy=279.87314, loss_wh=152.81982, loss_obj=374.24432, loss_cls=12.378073, loss=819.3153 .\n",
      "2022-04-13 13:41:38 [INFO]\t[TRAIN] Epoch=42/100, Step=3/87, loss_xy=367.280365, loss_wh=169.392426, loss_obj=543.302612, loss_cls=16.391392, loss=1096.366699, lr=0.001000, time_each_step=1.47s, eta=2:7:21\n",
      "2022-04-13 13:41:53 [INFO]\t[TRAIN] Epoch=42/100, Step=13/87, loss_xy=475.200470, loss_wh=263.906311, loss_obj=568.914612, loss_cls=20.068056, loss=1328.089600, lr=0.001000, time_each_step=1.53s, eta=2:11:39\n",
      "2022-04-13 13:42:09 [INFO]\t[TRAIN] Epoch=42/100, Step=23/87, loss_xy=328.928711, loss_wh=139.293594, loss_obj=171.966202, loss_cls=13.891433, loss=654.079895, lr=0.001000, time_each_step=1.59s, eta=2:16:54\n",
      "2022-04-13 13:42:25 [INFO]\t[TRAIN] Epoch=42/100, Step=33/87, loss_xy=296.388397, loss_wh=117.812943, loss_obj=302.106079, loss_cls=13.638091, loss=729.945496, lr=0.001000, time_each_step=1.61s, eta=2:18:16\n",
      "2022-04-13 13:42:38 [INFO]\t[TRAIN] Epoch=42/100, Step=43/87, loss_xy=249.109131, loss_wh=220.906265, loss_obj=197.578278, loss_cls=10.527830, loss=678.121460, lr=0.001000, time_each_step=1.26s, eta=1:48:7\n",
      "2022-04-13 13:42:50 [INFO]\t[TRAIN] Epoch=42/100, Step=53/87, loss_xy=226.322388, loss_wh=133.718430, loss_obj=253.000351, loss_cls=10.103554, loss=623.144775, lr=0.001000, time_each_step=1.25s, eta=1:47:37\n",
      "2022-04-13 13:43:05 [INFO]\t[TRAIN] Epoch=42/100, Step=63/87, loss_xy=249.839767, loss_wh=164.759323, loss_obj=323.166901, loss_cls=11.567263, loss=749.333252, lr=0.001000, time_each_step=1.44s, eta=2:2:55\n",
      "2022-04-13 13:43:20 [INFO]\t[TRAIN] Epoch=42/100, Step=73/87, loss_xy=203.105652, loss_wh=194.997131, loss_obj=107.197258, loss_cls=8.587540, loss=513.887573, lr=0.001000, time_each_step=1.5s, eta=2:7:30\n",
      "2022-04-13 13:43:36 [INFO]\t[TRAIN] Epoch=42/100, Step=83/87, loss_xy=413.993835, loss_wh=96.003929, loss_obj=545.548279, loss_cls=17.909891, loss=1073.455933, lr=0.001000, time_each_step=1.62s, eta=2:17:51\n",
      "2022-04-13 13:43:40 [INFO]\t[TRAIN] Epoch 42 finished, loss_xy=278.6377, loss_wh=140.20862, loss_obj=350.83667, loss_cls=12.306278, loss=781.9893 .\n",
      "2022-04-13 13:43:48 [INFO]\t[TRAIN] Epoch=43/100, Step=6/87, loss_xy=381.879944, loss_wh=295.664764, loss_obj=766.798096, loss_cls=17.585068, loss=1461.927856, lr=0.001000, time_each_step=1.22s, eta=1:43:42\n",
      "2022-04-13 13:44:02 [INFO]\t[TRAIN] Epoch=43/100, Step=16/87, loss_xy=329.053131, loss_wh=153.020447, loss_obj=407.397522, loss_cls=14.070864, loss=903.541931, lr=0.001000, time_each_step=1.4s, eta=1:58:28\n",
      "2022-04-13 13:44:16 [INFO]\t[TRAIN] Epoch=43/100, Step=26/87, loss_xy=343.023315, loss_wh=249.501419, loss_obj=423.748901, loss_cls=15.254321, loss=1031.527954, lr=0.001000, time_each_step=1.41s, eta=1:59:43\n",
      "2022-04-13 13:44:30 [INFO]\t[TRAIN] Epoch=43/100, Step=36/87, loss_xy=130.637970, loss_wh=62.745384, loss_obj=190.482864, loss_cls=5.876648, loss=389.742859, lr=0.001000, time_each_step=1.32s, eta=1:51:15\n",
      "2022-04-13 13:44:43 [INFO]\t[TRAIN] Epoch=43/100, Step=46/87, loss_xy=235.107513, loss_wh=74.794533, loss_obj=401.863281, loss_cls=10.411106, loss=722.176453, lr=0.001000, time_each_step=1.37s, eta=1:55:38\n",
      "2022-04-13 13:44:56 [INFO]\t[TRAIN] Epoch=43/100, Step=56/87, loss_xy=258.988800, loss_wh=87.185509, loss_obj=254.484253, loss_cls=11.953444, loss=612.612000, lr=0.001000, time_each_step=1.28s, eta=1:47:52\n",
      "2022-04-13 13:45:10 [INFO]\t[TRAIN] Epoch=43/100, Step=66/87, loss_xy=408.144348, loss_wh=205.547089, loss_obj=568.504089, loss_cls=18.410461, loss=1200.605957, lr=0.001000, time_each_step=1.35s, eta=1:53:28\n",
      "2022-04-13 13:45:24 [INFO]\t[TRAIN] Epoch=43/100, Step=76/87, loss_xy=382.701141, loss_wh=92.074852, loss_obj=523.860107, loss_cls=17.368952, loss=1016.005066, lr=0.001000, time_each_step=1.47s, eta=2:3:19\n",
      "2022-04-13 13:45:37 [INFO]\t[TRAIN] Epoch=43/100, Step=86/87, loss_xy=325.173340, loss_wh=178.673096, loss_obj=351.356964, loss_cls=14.195429, loss=869.398804, lr=0.001000, time_each_step=1.26s, eta=1:45:32\n",
      "2022-04-13 13:45:39 [INFO]\t[TRAIN] Epoch 43 finished, loss_xy=281.16504, loss_wh=127.2601, loss_obj=364.27457, loss_cls=12.534528, loss=785.2342 .\n",
      "2022-04-13 13:45:54 [INFO]\t[TRAIN] Epoch=44/100, Step=9/87, loss_xy=361.216217, loss_wh=234.552734, loss_obj=449.935699, loss_cls=15.905016, loss=1061.609619, lr=0.001000, time_each_step=1.73s, eta=2:24:8\n",
      "2022-04-13 13:46:09 [INFO]\t[TRAIN] Epoch=44/100, Step=19/87, loss_xy=458.203339, loss_wh=173.459015, loss_obj=454.544220, loss_cls=19.545738, loss=1105.752319, lr=0.001000, time_each_step=1.41s, eta=1:57:47\n",
      "2022-04-13 13:46:20 [INFO]\t[TRAIN] Epoch=44/100, Step=29/87, loss_xy=246.774994, loss_wh=124.156441, loss_obj=321.598297, loss_cls=11.764706, loss=704.294434, lr=0.001000, time_each_step=1.13s, eta=1:34:12\n",
      "2022-04-13 13:46:33 [INFO]\t[TRAIN] Epoch=44/100, Step=39/87, loss_xy=215.027679, loss_wh=97.475082, loss_obj=325.817810, loss_cls=9.340734, loss=647.661316, lr=0.001000, time_each_step=1.34s, eta=1:51:3\n",
      "2022-04-13 13:46:48 [INFO]\t[TRAIN] Epoch=44/100, Step=49/87, loss_xy=298.762054, loss_wh=179.602173, loss_obj=161.695374, loss_cls=12.581316, loss=652.640869, lr=0.001000, time_each_step=1.5s, eta=2:4:1\n",
      "2022-04-13 13:47:03 [INFO]\t[TRAIN] Epoch=44/100, Step=59/87, loss_xy=364.196442, loss_wh=116.232224, loss_obj=296.916504, loss_cls=15.504219, loss=792.849365, lr=0.001000, time_each_step=1.49s, eta=2:3:16\n",
      "2022-04-13 13:47:18 [INFO]\t[TRAIN] Epoch=44/100, Step=69/87, loss_xy=273.038055, loss_wh=82.198654, loss_obj=276.166290, loss_cls=12.746189, loss=644.149170, lr=0.001000, time_each_step=1.5s, eta=2:3:49\n",
      "2022-04-13 13:47:34 [INFO]\t[TRAIN] Epoch=44/100, Step=79/87, loss_xy=301.135223, loss_wh=296.009460, loss_obj=429.921478, loss_cls=13.278934, loss=1040.345093, lr=0.001000, time_each_step=1.58s, eta=2:9:53\n",
      "2022-04-13 13:47:45 [INFO]\t[TRAIN] Epoch 44 finished, loss_xy=279.4128, loss_wh=159.93599, loss_obj=346.55685, loss_cls=12.327676, loss=798.2333 .\n",
      "2022-04-13 13:47:48 [INFO]\t[TRAIN] Epoch=45/100, Step=2/87, loss_xy=432.053528, loss_wh=156.346313, loss_obj=615.901733, loss_cls=20.242937, loss=1224.544434, lr=0.001000, time_each_step=1.39s, eta=1:54:28\n",
      "2022-04-13 13:48:01 [INFO]\t[TRAIN] Epoch=45/100, Step=12/87, loss_xy=208.093048, loss_wh=112.983322, loss_obj=273.486328, loss_cls=9.141913, loss=603.704590, lr=0.001000, time_each_step=1.27s, eta=1:43:50\n",
      "2022-04-13 13:48:15 [INFO]\t[TRAIN] Epoch=45/100, Step=22/87, loss_xy=338.890167, loss_wh=120.458008, loss_obj=448.521332, loss_cls=15.616995, loss=923.486511, lr=0.001000, time_each_step=1.45s, eta=1:58:31\n",
      "2022-04-13 13:48:31 [INFO]\t[TRAIN] Epoch=45/100, Step=32/87, loss_xy=457.984985, loss_wh=261.280273, loss_obj=538.197510, loss_cls=19.511332, loss=1276.974121, lr=0.001000, time_each_step=1.54s, eta=2:5:37\n",
      "2022-04-13 13:48:42 [INFO]\t[TRAIN] Epoch=45/100, Step=42/87, loss_xy=221.072235, loss_wh=79.296036, loss_obj=332.753448, loss_cls=10.025461, loss=643.147156, lr=0.001000, time_each_step=1.14s, eta=1:32:59\n",
      "2022-04-13 13:48:57 [INFO]\t[TRAIN] Epoch=45/100, Step=52/87, loss_xy=86.243431, loss_wh=94.446182, loss_obj=261.924286, loss_cls=4.103150, loss=446.717041, lr=0.001000, time_each_step=1.53s, eta=2:3:50\n",
      "2022-04-13 13:49:08 [INFO]\t[TRAIN] Epoch=45/100, Step=62/87, loss_xy=354.945923, loss_wh=213.095428, loss_obj=477.058441, loss_cls=15.812493, loss=1060.912354, lr=0.001000, time_each_step=1.03s, eta=1:24:11\n",
      "2022-04-13 13:49:22 [INFO]\t[TRAIN] Epoch=45/100, Step=72/87, loss_xy=304.396973, loss_wh=133.880264, loss_obj=372.586548, loss_cls=14.077209, loss=824.940979, lr=0.001000, time_each_step=1.45s, eta=1:57:8\n",
      "2022-04-13 13:49:38 [INFO]\t[TRAIN] Epoch=45/100, Step=82/87, loss_xy=468.195404, loss_wh=222.830734, loss_obj=580.464355, loss_cls=20.802982, loss=1292.293457, lr=0.001000, time_each_step=1.63s, eta=2:11:15\n",
      "2022-04-13 13:49:44 [INFO]\t[TRAIN] Epoch 45 finished, loss_xy=278.6157, loss_wh=147.20743, loss_obj=363.71255, loss_cls=12.292145, loss=801.8279 .\n",
      "2022-04-13 13:49:44 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 13:49:45 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 13:49:51 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 13:49:51 [INFO]\t[EVAL] Finished, Epoch=45, bbox_map=17.612947 .\n",
      "2022-04-13 13:49:51 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_35, bbox_map=22.66733286293076\n",
      "2022-04-13 13:49:52 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_45.\n",
      "2022-04-13 13:50:03 [INFO]\t[TRAIN] Epoch=46/100, Step=5/87, loss_xy=308.971863, loss_wh=101.877533, loss_obj=290.261047, loss_cls=13.343195, loss=714.453674, lr=0.001000, time_each_step=1.57s, eta=2:6:5\n",
      "2022-04-13 13:50:17 [INFO]\t[TRAIN] Epoch=46/100, Step=15/87, loss_xy=237.019562, loss_wh=119.568970, loss_obj=172.873138, loss_cls=9.995810, loss=539.457458, lr=0.001000, time_each_step=1.41s, eta=1:53:8\n",
      "2022-04-13 13:50:30 [INFO]\t[TRAIN] Epoch=46/100, Step=25/87, loss_xy=335.009979, loss_wh=346.383606, loss_obj=437.280823, loss_cls=14.953819, loss=1133.628174, lr=0.001000, time_each_step=1.34s, eta=1:47:34\n",
      "2022-04-13 13:50:45 [INFO]\t[TRAIN] Epoch=46/100, Step=35/87, loss_xy=295.560913, loss_wh=81.171532, loss_obj=468.854126, loss_cls=12.873492, loss=858.460022, lr=0.001000, time_each_step=1.46s, eta=1:56:58\n",
      "2022-04-13 13:50:59 [INFO]\t[TRAIN] Epoch=46/100, Step=45/87, loss_xy=297.759216, loss_wh=106.682480, loss_obj=329.476379, loss_cls=13.879215, loss=747.797302, lr=0.001000, time_each_step=1.43s, eta=1:54:20\n",
      "2022-04-13 13:51:11 [INFO]\t[TRAIN] Epoch=46/100, Step=55/87, loss_xy=395.413635, loss_wh=455.214355, loss_obj=409.418793, loss_cls=16.668165, loss=1276.714966, lr=0.001000, time_each_step=1.25s, eta=1:39:36\n",
      "2022-04-13 13:51:27 [INFO]\t[TRAIN] Epoch=46/100, Step=65/87, loss_xy=232.448868, loss_wh=152.272964, loss_obj=247.262146, loss_cls=10.430880, loss=642.414917, lr=0.001000, time_each_step=1.58s, eta=2:5:31\n",
      "2022-04-13 13:51:42 [INFO]\t[TRAIN] Epoch=46/100, Step=75/87, loss_xy=451.396118, loss_wh=164.455048, loss_obj=445.257324, loss_cls=20.036736, loss=1081.145264, lr=0.001000, time_each_step=1.46s, eta=1:55:43\n",
      "2022-04-13 13:51:57 [INFO]\t[TRAIN] Epoch=46/100, Step=85/87, loss_xy=338.150940, loss_wh=87.373871, loss_obj=578.112732, loss_cls=14.770082, loss=1018.407654, lr=0.001000, time_each_step=1.49s, eta=1:58:3\n",
      "2022-04-13 13:51:58 [INFO]\t[TRAIN] Epoch 46 finished, loss_xy=267.84592, loss_wh=130.25931, loss_obj=334.08768, loss_cls=11.8828335, loss=744.07574 .\n",
      "2022-04-13 13:52:11 [INFO]\t[TRAIN] Epoch=47/100, Step=8/87, loss_xy=258.790283, loss_wh=102.144608, loss_obj=520.419983, loss_cls=11.692616, loss=893.047485, lr=0.001000, time_each_step=1.4s, eta=1:50:50\n",
      "2022-04-13 13:52:28 [INFO]\t[TRAIN] Epoch=47/100, Step=18/87, loss_xy=309.859650, loss_wh=134.994156, loss_obj=347.603668, loss_cls=13.386219, loss=805.843750, lr=0.001000, time_each_step=1.71s, eta=2:14:15\n",
      "2022-04-13 13:52:44 [INFO]\t[TRAIN] Epoch=47/100, Step=28/87, loss_xy=361.282898, loss_wh=131.488007, loss_obj=424.187378, loss_cls=15.815790, loss=932.774048, lr=0.001000, time_each_step=1.63s, eta=2:8:12\n",
      "2022-04-13 13:52:56 [INFO]\t[TRAIN] Epoch=47/100, Step=38/87, loss_xy=274.749054, loss_wh=86.402580, loss_obj=422.006104, loss_cls=12.915615, loss=796.073303, lr=0.001000, time_each_step=1.12s, eta=1:28:5\n",
      "2022-04-13 13:53:09 [INFO]\t[TRAIN] Epoch=47/100, Step=48/87, loss_xy=158.030914, loss_wh=42.316856, loss_obj=285.461487, loss_cls=7.168187, loss=492.977448, lr=0.001000, time_each_step=1.33s, eta=1:44:2\n",
      "2022-04-13 13:53:25 [INFO]\t[TRAIN] Epoch=47/100, Step=58/87, loss_xy=362.719147, loss_wh=169.059250, loss_obj=350.510803, loss_cls=16.495081, loss=898.784241, lr=0.001000, time_each_step=1.61s, eta=2:5:35\n",
      "2022-04-13 13:53:39 [INFO]\t[TRAIN] Epoch=47/100, Step=68/87, loss_xy=275.500916, loss_wh=73.186798, loss_obj=406.823761, loss_cls=12.447229, loss=767.958679, lr=0.001000, time_each_step=1.37s, eta=1:46:49\n",
      "2022-04-13 13:53:54 [INFO]\t[TRAIN] Epoch=47/100, Step=78/87, loss_xy=254.684494, loss_wh=82.297142, loss_obj=259.040436, loss_cls=11.891359, loss=607.913452, lr=0.001000, time_each_step=1.58s, eta=2:2:53\n",
      "2022-04-13 13:54:09 [INFO]\t[TRAIN] Epoch 47 finished, loss_xy=277.1339, loss_wh=121.18696, loss_obj=327.76743, loss_cls=12.322012, loss=738.4102 .\n",
      "2022-04-13 13:54:12 [INFO]\t[TRAIN] Epoch=48/100, Step=1/87, loss_xy=166.989288, loss_wh=83.579430, loss_obj=251.554794, loss_cls=7.065800, loss=509.189331, lr=0.001000, time_each_step=1.71s, eta=2:12:35\n",
      "2022-04-13 13:54:25 [INFO]\t[TRAIN] Epoch=48/100, Step=11/87, loss_xy=309.398315, loss_wh=206.797485, loss_obj=460.078064, loss_cls=14.325572, loss=990.599426, lr=0.001000, time_each_step=1.3s, eta=1:40:34\n",
      "2022-04-13 13:54:41 [INFO]\t[TRAIN] Epoch=48/100, Step=21/87, loss_xy=273.541168, loss_wh=170.673843, loss_obj=357.013672, loss_cls=13.167645, loss=814.396362, lr=0.001000, time_each_step=1.68s, eta=2:9:38\n",
      "2022-04-13 13:54:57 [INFO]\t[TRAIN] Epoch=48/100, Step=31/87, loss_xy=194.034271, loss_wh=66.287766, loss_obj=322.619995, loss_cls=8.507276, loss=591.449280, lr=0.001000, time_each_step=1.58s, eta=2:1:45\n",
      "2022-04-13 13:55:10 [INFO]\t[TRAIN] Epoch=48/100, Step=41/87, loss_xy=212.328156, loss_wh=92.901489, loss_obj=230.498444, loss_cls=9.342155, loss=545.070251, lr=0.001000, time_each_step=1.27s, eta=1:37:46\n",
      "2022-04-13 13:55:22 [INFO]\t[TRAIN] Epoch=48/100, Step=51/87, loss_xy=248.674194, loss_wh=103.738327, loss_obj=207.026367, loss_cls=10.608113, loss=570.046997, lr=0.001000, time_each_step=1.19s, eta=1:31:20\n",
      "2022-04-13 13:55:33 [INFO]\t[TRAIN] Epoch=48/100, Step=61/87, loss_xy=285.570984, loss_wh=103.897858, loss_obj=330.574127, loss_cls=13.765516, loss=733.808472, lr=0.001000, time_each_step=1.16s, eta=1:28:58\n",
      "2022-04-13 13:55:49 [INFO]\t[TRAIN] Epoch=48/100, Step=71/87, loss_xy=204.741882, loss_wh=101.304207, loss_obj=227.343994, loss_cls=9.362842, loss=542.752930, lr=0.001000, time_each_step=1.6s, eta=2:2:15\n",
      "2022-04-13 13:56:03 [INFO]\t[TRAIN] Epoch=48/100, Step=81/87, loss_xy=282.080505, loss_wh=123.015381, loss_obj=381.197449, loss_cls=12.794917, loss=799.088257, lr=0.001000, time_each_step=1.35s, eta=1:43:7\n",
      "2022-04-13 13:56:10 [INFO]\t[TRAIN] Epoch 48 finished, loss_xy=275.41275, loss_wh=135.41676, loss_obj=344.4564, loss_cls=12.212727, loss=767.49854 .\n",
      "2022-04-13 13:56:15 [INFO]\t[TRAIN] Epoch=49/100, Step=4/87, loss_xy=176.141449, loss_wh=87.701965, loss_obj=292.182556, loss_cls=8.344251, loss=564.370239, lr=0.001000, time_each_step=1.24s, eta=1:34:33\n",
      "2022-04-13 13:56:28 [INFO]\t[TRAIN] Epoch=49/100, Step=14/87, loss_xy=336.069427, loss_wh=371.124359, loss_obj=371.817719, loss_cls=14.605023, loss=1093.616455, lr=0.001000, time_each_step=1.32s, eta=1:40:16\n",
      "2022-04-13 13:56:41 [INFO]\t[TRAIN] Epoch=49/100, Step=24/87, loss_xy=266.037659, loss_wh=122.037384, loss_obj=244.595703, loss_cls=11.721759, loss=644.392517, lr=0.001000, time_each_step=1.22s, eta=1:32:45\n",
      "2022-04-13 13:56:56 [INFO]\t[TRAIN] Epoch=49/100, Step=34/87, loss_xy=234.661285, loss_wh=124.762619, loss_obj=228.016113, loss_cls=10.801661, loss=598.241638, lr=0.001000, time_each_step=1.53s, eta=1:55:46\n",
      "2022-04-13 13:57:11 [INFO]\t[TRAIN] Epoch=49/100, Step=44/87, loss_xy=313.055664, loss_wh=307.749451, loss_obj=394.262115, loss_cls=14.014689, loss=1029.081909, lr=0.001000, time_each_step=1.51s, eta=1:53:53\n",
      "2022-04-13 13:57:24 [INFO]\t[TRAIN] Epoch=49/100, Step=54/87, loss_xy=200.384766, loss_wh=137.145264, loss_obj=130.700714, loss_cls=8.436036, loss=476.666779, lr=0.001000, time_each_step=1.27s, eta=1:35:30\n",
      "2022-04-13 13:57:38 [INFO]\t[TRAIN] Epoch=49/100, Step=64/87, loss_xy=260.286713, loss_wh=148.406204, loss_obj=457.402740, loss_cls=12.145657, loss=878.241333, lr=0.001000, time_each_step=1.43s, eta=1:47:52\n",
      "2022-04-13 13:57:49 [INFO]\t[TRAIN] Epoch=49/100, Step=74/87, loss_xy=433.781067, loss_wh=128.398026, loss_obj=592.505737, loss_cls=19.184843, loss=1173.869629, lr=0.001000, time_each_step=1.08s, eta=1:21:1\n",
      "2022-04-13 13:58:01 [INFO]\t[TRAIN] Epoch=49/100, Step=84/87, loss_xy=256.390564, loss_wh=131.114151, loss_obj=264.658356, loss_cls=11.236606, loss=663.399719, lr=0.001000, time_each_step=1.2s, eta=1:29:51\n",
      "2022-04-13 13:58:05 [INFO]\t[TRAIN] Epoch 49 finished, loss_xy=285.21292, loss_wh=138.96538, loss_obj=352.19238, loss_cls=12.679428, loss=789.0501 .\n",
      "2022-04-13 13:58:19 [INFO]\t[TRAIN] Epoch=50/100, Step=7/87, loss_xy=322.813049, loss_wh=154.474380, loss_obj=347.811707, loss_cls=14.964358, loss=840.063477, lr=0.001000, time_each_step=1.81s, eta=2:14:42\n",
      "2022-04-13 13:58:31 [INFO]\t[TRAIN] Epoch=50/100, Step=17/87, loss_xy=259.430511, loss_wh=68.124275, loss_obj=388.515076, loss_cls=11.551778, loss=727.621582, lr=0.001000, time_each_step=1.16s, eta=1:26:42\n",
      "2022-04-13 13:58:45 [INFO]\t[TRAIN] Epoch=50/100, Step=27/87, loss_xy=438.629425, loss_wh=206.766190, loss_obj=521.437866, loss_cls=19.300293, loss=1186.133789, lr=0.001000, time_each_step=1.41s, eta=1:44:30\n",
      "2022-04-13 13:59:02 [INFO]\t[TRAIN] Epoch=50/100, Step=37/87, loss_xy=217.331650, loss_wh=73.673599, loss_obj=369.364685, loss_cls=9.296385, loss=669.666321, lr=0.001000, time_each_step=1.72s, eta=2:7:1\n",
      "2022-04-13 13:59:20 [INFO]\t[TRAIN] Epoch=50/100, Step=47/87, loss_xy=260.257263, loss_wh=62.386169, loss_obj=258.593933, loss_cls=10.988605, loss=592.225952, lr=0.001000, time_each_step=1.78s, eta=2:11:38\n",
      "2022-04-13 13:59:34 [INFO]\t[TRAIN] Epoch=50/100, Step=57/87, loss_xy=421.500366, loss_wh=255.504562, loss_obj=511.500122, loss_cls=18.388081, loss=1206.893188, lr=0.001000, time_each_step=1.46s, eta=1:47:21\n",
      "2022-04-13 13:59:48 [INFO]\t[TRAIN] Epoch=50/100, Step=67/87, loss_xy=164.356247, loss_wh=104.463074, loss_obj=164.648453, loss_cls=6.987315, loss=440.455078, lr=0.001000, time_each_step=1.39s, eta=1:42:43\n",
      "2022-04-13 14:00:02 [INFO]\t[TRAIN] Epoch=50/100, Step=77/87, loss_xy=361.144562, loss_wh=92.965027, loss_obj=350.595673, loss_cls=15.542682, loss=820.247925, lr=0.001000, time_each_step=1.38s, eta=1:41:29\n",
      "2022-04-13 14:00:14 [INFO]\t[TRAIN] Epoch=50/100, Step=87/87, loss_xy=161.470978, loss_wh=198.352371, loss_obj=206.958740, loss_cls=6.972067, loss=573.754150, lr=0.001000, time_each_step=1.17s, eta=1:25:53\n",
      "2022-04-13 14:00:14 [INFO]\t[TRAIN] Epoch 50 finished, loss_xy=281.0488, loss_wh=156.28777, loss_obj=333.3723, loss_cls=12.419314, loss=783.12823 .\n",
      "2022-04-13 14:00:14 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 14:00:14 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 14:00:21 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 14:00:21 [INFO]\t[EVAL] Finished, Epoch=50, bbox_map=1.124968 .\n",
      "2022-04-13 14:00:21 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_35, bbox_map=22.66733286293076\n",
      "2022-04-13 14:00:22 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_50.\n",
      "2022-04-13 14:00:39 [INFO]\t[TRAIN] Epoch=51/100, Step=10/87, loss_xy=312.412445, loss_wh=174.169647, loss_obj=502.797363, loss_cls=13.375830, loss=1002.755310, lr=0.001000, time_each_step=1.67s, eta=2:1:54\n",
      "2022-04-13 14:00:55 [INFO]\t[TRAIN] Epoch=51/100, Step=20/87, loss_xy=274.183105, loss_wh=207.368835, loss_obj=400.757568, loss_cls=11.824767, loss=894.134277, lr=0.001000, time_each_step=1.61s, eta=1:57:19\n",
      "2022-04-13 14:01:09 [INFO]\t[TRAIN] Epoch=51/100, Step=30/87, loss_xy=286.864655, loss_wh=99.109604, loss_obj=401.976196, loss_cls=13.040127, loss=800.990540, lr=0.001000, time_each_step=1.44s, eta=1:44:52\n",
      "2022-04-13 14:01:22 [INFO]\t[TRAIN] Epoch=51/100, Step=40/87, loss_xy=381.114685, loss_wh=174.298218, loss_obj=463.328552, loss_cls=17.915771, loss=1036.657227, lr=0.001000, time_each_step=1.24s, eta=1:30:0\n",
      "2022-04-13 14:01:37 [INFO]\t[TRAIN] Epoch=51/100, Step=50/87, loss_xy=223.357819, loss_wh=264.300354, loss_obj=155.303070, loss_cls=9.450541, loss=652.411804, lr=0.001000, time_each_step=1.54s, eta=1:51:50\n",
      "2022-04-13 14:01:52 [INFO]\t[TRAIN] Epoch=51/100, Step=60/87, loss_xy=271.708038, loss_wh=52.197124, loss_obj=360.581665, loss_cls=12.368345, loss=696.855164, lr=0.001000, time_each_step=1.47s, eta=1:45:57\n",
      "2022-04-13 14:02:07 [INFO]\t[TRAIN] Epoch=51/100, Step=70/87, loss_xy=208.284653, loss_wh=117.698143, loss_obj=190.472122, loss_cls=9.093562, loss=525.548462, lr=0.001000, time_each_step=1.5s, eta=1:47:51\n",
      "2022-04-13 14:02:20 [INFO]\t[TRAIN] Epoch=51/100, Step=80/87, loss_xy=206.854431, loss_wh=119.306763, loss_obj=200.090744, loss_cls=8.971746, loss=535.223694, lr=0.001000, time_each_step=1.36s, eta=1:37:52\n",
      "2022-04-13 14:02:29 [INFO]\t[TRAIN] Epoch 51 finished, loss_xy=265.14706, loss_wh=158.40231, loss_obj=302.6573, loss_cls=11.778141, loss=737.98474 .\n",
      "2022-04-13 14:02:35 [INFO]\t[TRAIN] Epoch=52/100, Step=3/87, loss_xy=228.555359, loss_wh=67.185631, loss_obj=300.327942, loss_cls=10.363651, loss=606.432617, lr=0.001000, time_each_step=1.48s, eta=1:45:56\n",
      "2022-04-13 14:02:51 [INFO]\t[TRAIN] Epoch=52/100, Step=13/87, loss_xy=191.004272, loss_wh=115.130913, loss_obj=238.577957, loss_cls=8.218432, loss=552.931580, lr=0.001000, time_each_step=1.56s, eta=1:51:55\n",
      "2022-04-13 14:03:04 [INFO]\t[TRAIN] Epoch=52/100, Step=23/87, loss_xy=240.015701, loss_wh=181.116943, loss_obj=334.868774, loss_cls=11.378494, loss=767.379883, lr=0.001000, time_each_step=1.31s, eta=1:33:43\n",
      "2022-04-13 14:03:20 [INFO]\t[TRAIN] Epoch=52/100, Step=33/87, loss_xy=213.549484, loss_wh=67.731812, loss_obj=340.311035, loss_cls=9.277708, loss=630.870056, lr=0.001000, time_each_step=1.54s, eta=1:49:57\n",
      "2022-04-13 14:03:32 [INFO]\t[TRAIN] Epoch=52/100, Step=43/87, loss_xy=414.225098, loss_wh=130.461258, loss_obj=519.950073, loss_cls=18.894377, loss=1083.530884, lr=0.001000, time_each_step=1.28s, eta=1:30:56\n",
      "2022-04-13 14:03:47 [INFO]\t[TRAIN] Epoch=52/100, Step=53/87, loss_xy=236.125092, loss_wh=74.948700, loss_obj=147.120941, loss_cls=9.949585, loss=468.144318, lr=0.001000, time_each_step=1.49s, eta=1:45:43\n",
      "2022-04-13 14:03:59 [INFO]\t[TRAIN] Epoch=52/100, Step=63/87, loss_xy=326.432159, loss_wh=106.935410, loss_obj=331.641266, loss_cls=14.683367, loss=779.692139, lr=0.001000, time_each_step=1.16s, eta=1:22:38\n",
      "2022-04-13 14:04:12 [INFO]\t[TRAIN] Epoch=52/100, Step=73/87, loss_xy=312.948975, loss_wh=82.713715, loss_obj=450.559052, loss_cls=13.981102, loss=860.202820, lr=0.001000, time_each_step=1.34s, eta=1:34:37\n",
      "2022-04-13 14:04:27 [INFO]\t[TRAIN] Epoch=52/100, Step=83/87, loss_xy=263.112946, loss_wh=131.575531, loss_obj=328.246613, loss_cls=11.243624, loss=734.178711, lr=0.001000, time_each_step=1.49s, eta=1:44:43\n",
      "2022-04-13 14:04:32 [INFO]\t[TRAIN] Epoch 52 finished, loss_xy=272.25372, loss_wh=137.21622, loss_obj=314.6545, loss_cls=12.106993, loss=736.2314 .\n",
      "2022-04-13 14:04:41 [INFO]\t[TRAIN] Epoch=53/100, Step=6/87, loss_xy=215.010071, loss_wh=110.529716, loss_obj=311.876801, loss_cls=9.301482, loss=646.718079, lr=0.001000, time_each_step=1.4s, eta=1:38:42\n",
      "2022-04-13 14:04:54 [INFO]\t[TRAIN] Epoch=53/100, Step=16/87, loss_xy=224.336334, loss_wh=114.326271, loss_obj=256.753021, loss_cls=9.952719, loss=605.368347, lr=0.001000, time_each_step=1.3s, eta=1:31:16\n",
      "2022-04-13 14:05:09 [INFO]\t[TRAIN] Epoch=53/100, Step=26/87, loss_xy=355.811646, loss_wh=293.839478, loss_obj=381.364807, loss_cls=16.508348, loss=1047.524170, lr=0.001000, time_each_step=1.42s, eta=1:39:23\n",
      "2022-04-13 14:05:21 [INFO]\t[TRAIN] Epoch=53/100, Step=36/87, loss_xy=185.730637, loss_wh=84.832397, loss_obj=231.658752, loss_cls=8.167950, loss=510.389740, lr=0.001000, time_each_step=1.28s, eta=1:29:32\n",
      "2022-04-13 14:05:39 [INFO]\t[TRAIN] Epoch=53/100, Step=46/87, loss_xy=216.462280, loss_wh=63.388809, loss_obj=267.940247, loss_cls=9.422771, loss=557.214111, lr=0.001000, time_each_step=1.75s, eta=2:1:56\n",
      "2022-04-13 14:05:51 [INFO]\t[TRAIN] Epoch=53/100, Step=56/87, loss_xy=292.042480, loss_wh=208.207565, loss_obj=303.329285, loss_cls=13.263790, loss=816.843140, lr=0.001000, time_each_step=1.2s, eta=1:23:21\n",
      "2022-04-13 14:06:06 [INFO]\t[TRAIN] Epoch=53/100, Step=66/87, loss_xy=195.779602, loss_wh=62.705090, loss_obj=300.785187, loss_cls=8.988514, loss=568.258423, lr=0.001000, time_each_step=1.5s, eta=1:43:40\n",
      "2022-04-13 14:06:21 [INFO]\t[TRAIN] Epoch=53/100, Step=76/87, loss_xy=187.589691, loss_wh=50.048782, loss_obj=322.445679, loss_cls=8.385067, loss=568.469238, lr=0.001000, time_each_step=1.56s, eta=1:47:59\n",
      "2022-04-13 14:06:35 [INFO]\t[TRAIN] Epoch=53/100, Step=86/87, loss_xy=183.269913, loss_wh=160.166992, loss_obj=107.094902, loss_cls=7.747452, loss=458.279236, lr=0.001000, time_each_step=1.35s, eta=1:33:3\n",
      "2022-04-13 14:06:36 [INFO]\t[TRAIN] Epoch 53 finished, loss_xy=271.31696, loss_wh=135.43115, loss_obj=309.53772, loss_cls=12.109891, loss=728.39575 .\n",
      "2022-04-13 14:06:49 [INFO]\t[TRAIN] Epoch=54/100, Step=9/87, loss_xy=367.728729, loss_wh=192.765396, loss_obj=394.451355, loss_cls=16.250654, loss=971.196167, lr=0.001000, time_each_step=1.43s, eta=1:38:6\n",
      "2022-04-13 14:07:04 [INFO]\t[TRAIN] Epoch=54/100, Step=19/87, loss_xy=195.843521, loss_wh=47.414742, loss_obj=282.951263, loss_cls=9.178635, loss=535.388184, lr=0.001000, time_each_step=1.47s, eta=1:40:38\n",
      "2022-04-13 14:07:17 [INFO]\t[TRAIN] Epoch=54/100, Step=29/87, loss_xy=258.762207, loss_wh=188.024872, loss_obj=115.190598, loss_cls=10.870016, loss=572.847656, lr=0.001000, time_each_step=1.34s, eta=1:31:50\n",
      "2022-04-13 14:07:31 [INFO]\t[TRAIN] Epoch=54/100, Step=39/87, loss_xy=270.902557, loss_wh=82.184235, loss_obj=386.593628, loss_cls=12.383079, loss=752.063477, lr=0.001000, time_each_step=1.32s, eta=1:30:14\n",
      "2022-04-13 14:07:48 [INFO]\t[TRAIN] Epoch=54/100, Step=49/87, loss_xy=295.261200, loss_wh=171.111450, loss_obj=422.218842, loss_cls=13.068634, loss=901.660156, lr=0.001000, time_each_step=1.72s, eta=1:57:12\n",
      "2022-04-13 14:08:06 [INFO]\t[TRAIN] Epoch=54/100, Step=59/87, loss_xy=308.105957, loss_wh=183.953461, loss_obj=350.113037, loss_cls=13.600050, loss=855.772522, lr=0.001000, time_each_step=1.82s, eta=2:3:11\n",
      "2022-04-13 14:08:21 [INFO]\t[TRAIN] Epoch=54/100, Step=69/87, loss_xy=435.719299, loss_wh=269.624268, loss_obj=590.876648, loss_cls=19.400177, loss=1315.620361, lr=0.001000, time_each_step=1.48s, eta=1:40:20\n",
      "2022-04-13 14:08:35 [INFO]\t[TRAIN] Epoch=54/100, Step=79/87, loss_xy=255.457245, loss_wh=86.255119, loss_obj=351.820312, loss_cls=11.762327, loss=705.295044, lr=0.001000, time_each_step=1.37s, eta=1:32:48\n",
      "2022-04-13 14:08:47 [INFO]\t[TRAIN] Epoch 54 finished, loss_xy=267.8474, loss_wh=143.17015, loss_obj=310.0074, loss_cls=11.957016, loss=732.98193 .\n",
      "2022-04-13 14:08:50 [INFO]\t[TRAIN] Epoch=55/100, Step=2/87, loss_xy=366.996704, loss_wh=111.851540, loss_obj=392.547089, loss_cls=16.100048, loss=887.495361, lr=0.001000, time_each_step=1.55s, eta=1:44:26\n",
      "2022-04-13 14:09:06 [INFO]\t[TRAIN] Epoch=55/100, Step=12/87, loss_xy=254.736237, loss_wh=104.347519, loss_obj=210.515854, loss_cls=11.217844, loss=580.817444, lr=0.001000, time_each_step=1.61s, eta=1:48:16\n",
      "2022-04-13 14:09:20 [INFO]\t[TRAIN] Epoch=55/100, Step=22/87, loss_xy=257.245850, loss_wh=128.605026, loss_obj=242.441971, loss_cls=11.571599, loss=639.864441, lr=0.001000, time_each_step=1.4s, eta=1:34:1\n",
      "2022-04-13 14:09:35 [INFO]\t[TRAIN] Epoch=55/100, Step=32/87, loss_xy=612.111755, loss_wh=195.663330, loss_obj=787.950745, loss_cls=27.414429, loss=1623.140259, lr=0.001000, time_each_step=1.43s, eta=1:35:30\n",
      "2022-04-13 14:09:48 [INFO]\t[TRAIN] Epoch=55/100, Step=42/87, loss_xy=282.695770, loss_wh=99.875587, loss_obj=319.788971, loss_cls=12.922151, loss=715.282532, lr=0.001000, time_each_step=1.37s, eta=1:31:37\n",
      "2022-04-13 14:10:04 [INFO]\t[TRAIN] Epoch=55/100, Step=52/87, loss_xy=385.382050, loss_wh=243.679184, loss_obj=431.445496, loss_cls=16.731579, loss=1077.238281, lr=0.001000, time_each_step=1.52s, eta=1:41:1\n",
      "2022-04-13 14:10:17 [INFO]\t[TRAIN] Epoch=55/100, Step=62/87, loss_xy=232.264542, loss_wh=119.680679, loss_obj=211.859543, loss_cls=9.935516, loss=573.740234, lr=0.001000, time_each_step=1.38s, eta=1:31:36\n",
      "2022-04-13 14:10:33 [INFO]\t[TRAIN] Epoch=55/100, Step=72/87, loss_xy=231.817764, loss_wh=65.578522, loss_obj=249.740341, loss_cls=10.491477, loss=557.628113, lr=0.001000, time_each_step=1.52s, eta=1:40:46\n",
      "2022-04-13 14:10:48 [INFO]\t[TRAIN] Epoch=55/100, Step=82/87, loss_xy=255.459808, loss_wh=124.785339, loss_obj=267.123291, loss_cls=11.596255, loss=658.964661, lr=0.001000, time_each_step=1.5s, eta=1:39:17\n",
      "2022-04-13 14:10:54 [INFO]\t[TRAIN] Epoch 55 finished, loss_xy=279.08276, loss_wh=120.16971, loss_obj=304.89005, loss_cls=12.456409, loss=716.599 .\n",
      "2022-04-13 14:10:54 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 14:10:55 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 14:11:01 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 14:11:01 [INFO]\t[EVAL] Finished, Epoch=55, bbox_map=43.850042 .\n",
      "2022-04-13 14:11:05 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 14:11:05 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_55, bbox_map=43.85004191825223\n",
      "2022-04-13 14:11:07 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_55.\n",
      "2022-04-13 14:11:18 [INFO]\t[TRAIN] Epoch=56/100, Step=5/87, loss_xy=383.908997, loss_wh=184.024673, loss_obj=226.023758, loss_cls=16.234514, loss=810.191895, lr=0.001000, time_each_step=1.76s, eta=1:56:29\n",
      "2022-04-13 14:11:33 [INFO]\t[TRAIN] Epoch=56/100, Step=15/87, loss_xy=129.660706, loss_wh=40.955002, loss_obj=244.270599, loss_cls=5.939294, loss=420.825592, lr=0.001000, time_each_step=1.49s, eta=1:38:24\n",
      "2022-04-13 14:11:48 [INFO]\t[TRAIN] Epoch=56/100, Step=25/87, loss_xy=209.340378, loss_wh=244.233246, loss_obj=334.533203, loss_cls=9.228128, loss=797.334961, lr=0.001000, time_each_step=1.51s, eta=1:39:37\n",
      "2022-04-13 14:12:02 [INFO]\t[TRAIN] Epoch=56/100, Step=35/87, loss_xy=345.585297, loss_wh=117.305069, loss_obj=433.609497, loss_cls=14.682913, loss=911.182800, lr=0.001000, time_each_step=1.36s, eta=1:29:56\n",
      "2022-04-13 14:12:17 [INFO]\t[TRAIN] Epoch=56/100, Step=45/87, loss_xy=492.204407, loss_wh=336.995422, loss_obj=220.027588, loss_cls=20.784676, loss=1070.012085, lr=0.001000, time_each_step=1.52s, eta=1:39:35\n",
      "2022-04-13 14:12:31 [INFO]\t[TRAIN] Epoch=56/100, Step=55/87, loss_xy=352.101959, loss_wh=278.560059, loss_obj=465.805908, loss_cls=15.736790, loss=1112.204712, lr=0.001000, time_each_step=1.38s, eta=1:30:34\n",
      "2022-04-13 14:12:45 [INFO]\t[TRAIN] Epoch=56/100, Step=65/87, loss_xy=242.523163, loss_wh=191.815338, loss_obj=283.281372, loss_cls=10.446985, loss=728.066833, lr=0.001000, time_each_step=1.44s, eta=1:33:55\n",
      "2022-04-13 14:13:01 [INFO]\t[TRAIN] Epoch=56/100, Step=75/87, loss_xy=320.495331, loss_wh=199.190796, loss_obj=395.654694, loss_cls=14.693262, loss=930.034058, lr=0.001000, time_each_step=1.63s, eta=1:46:8\n",
      "2022-04-13 14:13:13 [INFO]\t[TRAIN] Epoch=56/100, Step=85/87, loss_xy=213.440140, loss_wh=131.315002, loss_obj=289.589630, loss_cls=9.624012, loss=643.968750, lr=0.001000, time_each_step=1.12s, eta=1:13:4\n",
      "2022-04-13 14:13:15 [INFO]\t[TRAIN] Epoch 56 finished, loss_xy=283.60178, loss_wh=238.69998, loss_obj=309.27106, loss_cls=12.507011, loss=844.07983 .\n",
      "2022-04-13 14:13:26 [INFO]\t[TRAIN] Epoch=57/100, Step=8/87, loss_xy=159.748978, loss_wh=30.304529, loss_obj=315.658325, loss_cls=7.380529, loss=513.092407, lr=0.001000, time_each_step=1.28s, eta=1:23:21\n",
      "2022-04-13 14:13:40 [INFO]\t[TRAIN] Epoch=57/100, Step=18/87, loss_xy=166.934464, loss_wh=79.636948, loss_obj=234.601196, loss_cls=7.495875, loss=488.668488, lr=0.001000, time_each_step=1.44s, eta=1:33:13\n",
      "2022-04-13 14:13:52 [INFO]\t[TRAIN] Epoch=57/100, Step=28/87, loss_xy=116.805382, loss_wh=46.962807, loss_obj=215.430344, loss_cls=5.897981, loss=385.096527, lr=0.001000, time_each_step=1.21s, eta=1:18:38\n",
      "2022-04-13 14:14:10 [INFO]\t[TRAIN] Epoch=57/100, Step=38/87, loss_xy=339.865143, loss_wh=265.386597, loss_obj=373.109314, loss_cls=14.890030, loss=993.251038, lr=0.001000, time_each_step=1.75s, eta=1:51:59\n",
      "2022-04-13 14:14:25 [INFO]\t[TRAIN] Epoch=57/100, Step=48/87, loss_xy=413.555420, loss_wh=101.315407, loss_obj=388.782135, loss_cls=19.336138, loss=922.989075, lr=0.001000, time_each_step=1.5s, eta=1:35:52\n",
      "2022-04-13 14:14:41 [INFO]\t[TRAIN] Epoch=57/100, Step=58/87, loss_xy=265.263550, loss_wh=156.033127, loss_obj=261.272034, loss_cls=11.505402, loss=694.074097, lr=0.001000, time_each_step=1.67s, eta=1:46:37\n",
      "2022-04-13 14:14:56 [INFO]\t[TRAIN] Epoch=57/100, Step=68/87, loss_xy=245.743484, loss_wh=373.824860, loss_obj=320.085571, loss_cls=10.971837, loss=950.625793, lr=0.001000, time_each_step=1.48s, eta=1:34:25\n",
      "2022-04-13 14:15:10 [INFO]\t[TRAIN] Epoch=57/100, Step=78/87, loss_xy=266.045746, loss_wh=645.128113, loss_obj=418.216858, loss_cls=12.311174, loss=1341.701782, lr=0.001000, time_each_step=1.42s, eta=1:30:35\n",
      "2022-04-13 14:15:23 [INFO]\t[TRAIN] Epoch 57 finished, loss_xy=281.79547, loss_wh=195.06522, loss_obj=313.40826, loss_cls=12.551175, loss=802.82025 .\n",
      "2022-04-13 14:15:25 [INFO]\t[TRAIN] Epoch=58/100, Step=1/87, loss_xy=345.433167, loss_wh=182.113785, loss_obj=406.756409, loss_cls=15.506813, loss=949.810181, lr=0.001000, time_each_step=1.5s, eta=1:35:17\n",
      "2022-04-13 14:15:39 [INFO]\t[TRAIN] Epoch=58/100, Step=11/87, loss_xy=251.356659, loss_wh=161.849579, loss_obj=241.005966, loss_cls=10.743958, loss=664.956177, lr=0.001000, time_each_step=1.38s, eta=1:27:10\n",
      "2022-04-13 14:15:52 [INFO]\t[TRAIN] Epoch=58/100, Step=21/87, loss_xy=204.517548, loss_wh=75.117119, loss_obj=315.894348, loss_cls=9.185038, loss=604.714111, lr=0.001000, time_each_step=1.25s, eta=1:18:55\n",
      "2022-04-13 14:16:07 [INFO]\t[TRAIN] Epoch=58/100, Step=31/87, loss_xy=296.115814, loss_wh=63.361721, loss_obj=380.016632, loss_cls=13.473904, loss=752.968018, lr=0.001000, time_each_step=1.57s, eta=1:38:33\n",
      "2022-04-13 14:16:22 [INFO]\t[TRAIN] Epoch=58/100, Step=41/87, loss_xy=443.300842, loss_wh=204.830490, loss_obj=469.772369, loss_cls=19.512699, loss=1137.416382, lr=0.001000, time_each_step=1.46s, eta=1:31:44\n",
      "2022-04-13 14:16:38 [INFO]\t[TRAIN] Epoch=58/100, Step=51/87, loss_xy=241.959686, loss_wh=112.131813, loss_obj=332.752502, loss_cls=11.025215, loss=697.869202, lr=0.001000, time_each_step=1.59s, eta=1:39:32\n",
      "2022-04-13 14:16:51 [INFO]\t[TRAIN] Epoch=58/100, Step=61/87, loss_xy=255.960007, loss_wh=142.347046, loss_obj=114.195427, loss_cls=10.806553, loss=523.309082, lr=0.001000, time_each_step=1.31s, eta=1:21:50\n",
      "2022-04-13 14:17:09 [INFO]\t[TRAIN] Epoch=58/100, Step=71/87, loss_xy=321.678345, loss_wh=101.356277, loss_obj=415.020782, loss_cls=13.579681, loss=851.635132, lr=0.001000, time_each_step=1.85s, eta=1:54:52\n",
      "2022-04-13 14:17:26 [INFO]\t[TRAIN] Epoch=58/100, Step=81/87, loss_xy=477.966248, loss_wh=258.497528, loss_obj=722.364868, loss_cls=21.173004, loss=1480.001587, lr=0.001000, time_each_step=1.61s, eta=1:40:8\n",
      "2022-04-13 14:17:34 [INFO]\t[TRAIN] Epoch 58 finished, loss_xy=273.34634, loss_wh=161.0855, loss_obj=309.35593, loss_cls=12.147854, loss=755.9357 .\n",
      "2022-04-13 14:17:42 [INFO]\t[TRAIN] Epoch=59/100, Step=4/87, loss_xy=323.085449, loss_wh=169.986389, loss_obj=438.831696, loss_cls=14.309340, loss=946.212891, lr=0.001000, time_each_step=1.66s, eta=1:42:39\n",
      "2022-04-13 14:17:58 [INFO]\t[TRAIN] Epoch=59/100, Step=14/87, loss_xy=153.010223, loss_wh=101.732483, loss_obj=154.629517, loss_cls=6.700260, loss=416.072479, lr=0.001000, time_each_step=1.57s, eta=1:36:58\n",
      "2022-04-13 14:18:12 [INFO]\t[TRAIN] Epoch=59/100, Step=24/87, loss_xy=386.358826, loss_wh=152.719635, loss_obj=350.653229, loss_cls=16.395193, loss=906.126892, lr=0.001000, time_each_step=1.35s, eta=1:23:27\n",
      "2022-04-13 14:18:28 [INFO]\t[TRAIN] Epoch=59/100, Step=34/87, loss_xy=357.798157, loss_wh=125.347450, loss_obj=164.944839, loss_cls=15.054428, loss=663.144897, lr=0.001000, time_each_step=1.62s, eta=1:39:11\n",
      "2022-04-13 14:18:39 [INFO]\t[TRAIN] Epoch=59/100, Step=44/87, loss_xy=344.444031, loss_wh=118.844421, loss_obj=480.922882, loss_cls=15.350619, loss=959.561951, lr=0.001000, time_each_step=1.17s, eta=1:11:56\n",
      "2022-04-13 14:18:52 [INFO]\t[TRAIN] Epoch=59/100, Step=54/87, loss_xy=280.873840, loss_wh=168.395370, loss_obj=305.329407, loss_cls=12.492279, loss=767.090942, lr=0.001000, time_each_step=1.26s, eta=1:17:19\n",
      "2022-04-13 14:19:09 [INFO]\t[TRAIN] Epoch=59/100, Step=64/87, loss_xy=211.703018, loss_wh=153.217117, loss_obj=161.174957, loss_cls=9.714935, loss=535.810059, lr=0.001000, time_each_step=1.68s, eta=1:42:15\n",
      "2022-04-13 14:19:21 [INFO]\t[TRAIN] Epoch=59/100, Step=74/87, loss_xy=239.734253, loss_wh=232.776047, loss_obj=218.157349, loss_cls=11.523263, loss=702.190918, lr=0.001000, time_each_step=1.26s, eta=1:17:5\n",
      "2022-04-13 14:19:35 [INFO]\t[TRAIN] Epoch=59/100, Step=84/87, loss_xy=309.265411, loss_wh=209.782822, loss_obj=403.675537, loss_cls=14.603197, loss=937.326965, lr=0.001000, time_each_step=1.35s, eta=1:21:50\n",
      "2022-04-13 14:19:40 [INFO]\t[TRAIN] Epoch 59 finished, loss_xy=257.01187, loss_wh=128.63855, loss_obj=296.09726, loss_cls=11.610731, loss=693.3584 .\n",
      "2022-04-13 14:19:51 [INFO]\t[TRAIN] Epoch=60/100, Step=7/87, loss_xy=176.040710, loss_wh=105.931931, loss_obj=179.571182, loss_cls=7.724619, loss=469.268433, lr=0.001000, time_each_step=1.61s, eta=1:36:56\n",
      "2022-04-13 14:20:05 [INFO]\t[TRAIN] Epoch=60/100, Step=17/87, loss_xy=252.781067, loss_wh=105.410583, loss_obj=320.699829, loss_cls=11.746283, loss=690.637756, lr=0.001000, time_each_step=1.34s, eta=1:20:29\n",
      "2022-04-13 14:20:22 [INFO]\t[TRAIN] Epoch=60/100, Step=27/87, loss_xy=140.247391, loss_wh=53.567047, loss_obj=193.402893, loss_cls=6.718838, loss=393.936188, lr=0.001000, time_each_step=1.72s, eta=1:43:10\n",
      "2022-04-13 14:20:36 [INFO]\t[TRAIN] Epoch=60/100, Step=37/87, loss_xy=257.558197, loss_wh=87.919548, loss_obj=275.916321, loss_cls=11.825447, loss=633.219482, lr=0.001000, time_each_step=1.44s, eta=1:26:1\n",
      "2022-04-13 14:20:49 [INFO]\t[TRAIN] Epoch=60/100, Step=47/87, loss_xy=247.480759, loss_wh=66.512253, loss_obj=306.242188, loss_cls=11.022668, loss=631.257874, lr=0.001000, time_each_step=1.3s, eta=1:18:0\n",
      "2022-04-13 14:21:04 [INFO]\t[TRAIN] Epoch=60/100, Step=57/87, loss_xy=285.205139, loss_wh=59.794296, loss_obj=451.282227, loss_cls=12.797307, loss=809.078979, lr=0.001000, time_each_step=1.5s, eta=1:29:23\n",
      "2022-04-13 14:21:16 [INFO]\t[TRAIN] Epoch=60/100, Step=67/87, loss_xy=262.381104, loss_wh=81.437965, loss_obj=337.668610, loss_cls=12.132710, loss=693.620361, lr=0.001000, time_each_step=1.18s, eta=1:10:15\n",
      "2022-04-13 14:21:33 [INFO]\t[TRAIN] Epoch=60/100, Step=77/87, loss_xy=137.790344, loss_wh=66.400986, loss_obj=138.420258, loss_cls=5.948479, loss=348.560059, lr=0.001000, time_each_step=1.72s, eta=1:41:34\n",
      "2022-04-13 14:21:45 [INFO]\t[TRAIN] Epoch=60/100, Step=87/87, loss_xy=270.546783, loss_wh=233.467514, loss_obj=217.117249, loss_cls=11.757636, loss=732.889160, lr=0.001000, time_each_step=1.22s, eta=1:12:6\n",
      "2022-04-13 14:21:46 [INFO]\t[TRAIN] Epoch 60 finished, loss_xy=281.7249, loss_wh=128.83824, loss_obj=318.34338, loss_cls=12.69302, loss=741.59955 .\n",
      "2022-04-13 14:21:46 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 14:21:46 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 14:21:52 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 14:21:52 [INFO]\t[EVAL] Finished, Epoch=60, bbox_map=25.685226 .\n",
      "2022-04-13 14:21:52 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_55, bbox_map=43.85004191825223\n",
      "2022-04-13 14:21:53 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_60.\n",
      "2022-04-13 14:22:08 [INFO]\t[TRAIN] Epoch=61/100, Step=10/87, loss_xy=201.320831, loss_wh=59.192532, loss_obj=308.320251, loss_cls=9.638571, loss=578.472168, lr=0.001000, time_each_step=1.44s, eta=1:23:54\n",
      "2022-04-13 14:22:21 [INFO]\t[TRAIN] Epoch=61/100, Step=20/87, loss_xy=219.583115, loss_wh=46.802017, loss_obj=234.107269, loss_cls=9.735455, loss=510.227844, lr=0.001000, time_each_step=1.28s, eta=1:14:35\n",
      "2022-04-13 14:22:38 [INFO]\t[TRAIN] Epoch=61/100, Step=30/87, loss_xy=179.104553, loss_wh=117.531509, loss_obj=220.349030, loss_cls=7.996453, loss=524.981567, lr=0.001000, time_each_step=1.72s, eta=1:39:58\n",
      "2022-04-13 14:22:53 [INFO]\t[TRAIN] Epoch=61/100, Step=40/87, loss_xy=233.150284, loss_wh=99.595543, loss_obj=239.034409, loss_cls=10.401834, loss=582.182068, lr=0.001000, time_each_step=1.49s, eta=1:26:3\n",
      "2022-04-13 14:23:04 [INFO]\t[TRAIN] Epoch=61/100, Step=50/87, loss_xy=186.108566, loss_wh=83.963722, loss_obj=255.518845, loss_cls=8.810061, loss=534.401184, lr=0.001000, time_each_step=1.18s, eta=1:8:18\n",
      "2022-04-13 14:23:17 [INFO]\t[TRAIN] Epoch=61/100, Step=60/87, loss_xy=295.866455, loss_wh=127.690727, loss_obj=288.378265, loss_cls=12.875374, loss=724.810791, lr=0.001000, time_each_step=1.27s, eta=1:12:59\n",
      "2022-04-13 14:23:32 [INFO]\t[TRAIN] Epoch=61/100, Step=70/87, loss_xy=303.093262, loss_wh=268.520477, loss_obj=398.453491, loss_cls=14.327703, loss=984.394958, lr=0.001000, time_each_step=1.49s, eta=1:25:17\n",
      "2022-04-13 14:23:45 [INFO]\t[TRAIN] Epoch=61/100, Step=80/87, loss_xy=254.943268, loss_wh=110.439316, loss_obj=274.377472, loss_cls=12.042458, loss=651.802490, lr=0.001000, time_each_step=1.35s, eta=1:17:17\n",
      "2022-04-13 14:23:57 [INFO]\t[TRAIN] Epoch 61 finished, loss_xy=262.9857, loss_wh=140.7501, loss_obj=290.45547, loss_cls=11.898548, loss=706.08984 .\n",
      "2022-04-13 14:24:01 [INFO]\t[TRAIN] Epoch=62/100, Step=3/87, loss_xy=234.211761, loss_wh=90.327797, loss_obj=407.709290, loss_cls=11.096306, loss=743.345154, lr=0.001000, time_each_step=1.54s, eta=1:28:0\n",
      "2022-04-13 14:24:15 [INFO]\t[TRAIN] Epoch=62/100, Step=13/87, loss_xy=245.522629, loss_wh=99.432777, loss_obj=304.323486, loss_cls=10.855554, loss=660.134460, lr=0.001000, time_each_step=1.38s, eta=1:18:43\n",
      "2022-04-13 14:24:31 [INFO]\t[TRAIN] Epoch=62/100, Step=23/87, loss_xy=267.009796, loss_wh=128.612488, loss_obj=306.633057, loss_cls=12.022647, loss=714.278015, lr=0.001000, time_each_step=1.61s, eta=1:31:8\n",
      "2022-04-13 14:24:44 [INFO]\t[TRAIN] Epoch=62/100, Step=33/87, loss_xy=260.214386, loss_wh=65.737312, loss_obj=263.941681, loss_cls=13.030520, loss=602.923889, lr=0.001000, time_each_step=1.31s, eta=1:14:14\n",
      "2022-04-13 14:24:58 [INFO]\t[TRAIN] Epoch=62/100, Step=43/87, loss_xy=302.595734, loss_wh=91.916725, loss_obj=459.869080, loss_cls=13.902196, loss=868.283752, lr=0.001000, time_each_step=1.44s, eta=1:21:9\n",
      "2022-04-13 14:25:13 [INFO]\t[TRAIN] Epoch=62/100, Step=53/87, loss_xy=291.870392, loss_wh=67.052505, loss_obj=397.851715, loss_cls=13.311696, loss=770.086365, lr=0.001000, time_each_step=1.49s, eta=1:23:49\n",
      "2022-04-13 14:25:27 [INFO]\t[TRAIN] Epoch=62/100, Step=63/87, loss_xy=356.085266, loss_wh=82.750778, loss_obj=367.110931, loss_cls=15.768002, loss=821.715027, lr=0.001000, time_each_step=1.41s, eta=1:19:8\n",
      "2022-04-13 14:25:39 [INFO]\t[TRAIN] Epoch=62/100, Step=73/87, loss_xy=215.286133, loss_wh=28.996445, loss_obj=308.426514, loss_cls=9.683737, loss=562.392822, lr=0.001000, time_each_step=1.17s, eta=1:5:29\n",
      "2022-04-13 14:25:53 [INFO]\t[TRAIN] Epoch=62/100, Step=83/87, loss_xy=291.953613, loss_wh=148.115189, loss_obj=283.693298, loss_cls=12.895663, loss=736.657776, lr=0.001000, time_each_step=1.42s, eta=1:19:20\n",
      "2022-04-13 14:25:58 [INFO]\t[TRAIN] Epoch 62 finished, loss_xy=270.73416, loss_wh=115.07967, loss_obj=301.3556, loss_cls=12.245588, loss=699.41486 .\n",
      "2022-04-13 14:26:08 [INFO]\t[TRAIN] Epoch=63/100, Step=6/87, loss_xy=323.739319, loss_wh=149.518478, loss_obj=441.147583, loss_cls=14.541544, loss=928.946960, lr=0.001000, time_each_step=1.46s, eta=1:21:9\n",
      "2022-04-13 14:26:25 [INFO]\t[TRAIN] Epoch=63/100, Step=16/87, loss_xy=240.413345, loss_wh=113.315834, loss_obj=272.918091, loss_cls=10.733753, loss=637.381042, lr=0.001000, time_each_step=1.7s, eta=1:34:12\n",
      "2022-04-13 14:26:39 [INFO]\t[TRAIN] Epoch=63/100, Step=26/87, loss_xy=184.455109, loss_wh=73.420631, loss_obj=130.352417, loss_cls=8.125347, loss=396.353485, lr=0.001000, time_each_step=1.4s, eta=1:17:12\n",
      "2022-04-13 14:26:55 [INFO]\t[TRAIN] Epoch=63/100, Step=36/87, loss_xy=127.765961, loss_wh=100.444511, loss_obj=61.395950, loss_cls=5.426865, loss=295.033325, lr=0.001000, time_each_step=1.56s, eta=1:25:58\n",
      "2022-04-13 14:27:11 [INFO]\t[TRAIN] Epoch=63/100, Step=46/87, loss_xy=181.368317, loss_wh=60.320377, loss_obj=66.915489, loss_cls=7.657887, loss=316.262085, lr=0.001000, time_each_step=1.67s, eta=1:31:48\n",
      "2022-04-13 14:27:24 [INFO]\t[TRAIN] Epoch=63/100, Step=56/87, loss_xy=361.513702, loss_wh=126.912666, loss_obj=291.646698, loss_cls=15.502240, loss=795.575317, lr=0.001000, time_each_step=1.28s, eta=1:9:55\n",
      "2022-04-13 14:27:41 [INFO]\t[TRAIN] Epoch=63/100, Step=66/87, loss_xy=187.593658, loss_wh=82.625595, loss_obj=153.278259, loss_cls=8.143082, loss=431.640564, lr=0.001000, time_each_step=1.65s, eta=1:29:41\n",
      "2022-04-13 14:27:58 [INFO]\t[TRAIN] Epoch=63/100, Step=76/87, loss_xy=245.725388, loss_wh=97.583633, loss_obj=234.316391, loss_cls=10.945689, loss=588.571106, lr=0.001000, time_each_step=1.69s, eta=1:31:50\n",
      "2022-04-13 14:28:11 [INFO]\t[TRAIN] Epoch=63/100, Step=86/87, loss_xy=251.392975, loss_wh=98.196785, loss_obj=278.807678, loss_cls=11.268851, loss=639.666321, lr=0.001000, time_each_step=1.35s, eta=1:13:10\n",
      "2022-04-13 14:28:11 [INFO]\t[TRAIN] Epoch 63 finished, loss_xy=271.17947, loss_wh=151.26427, loss_obj=301.1606, loss_cls=12.184208, loss=735.7885 .\n",
      "2022-04-13 14:28:26 [INFO]\t[TRAIN] Epoch=64/100, Step=9/87, loss_xy=395.798584, loss_wh=324.584869, loss_obj=456.367462, loss_cls=19.213875, loss=1195.964722, lr=0.001000, time_each_step=1.49s, eta=1:20:46\n",
      "2022-04-13 14:28:40 [INFO]\t[TRAIN] Epoch=64/100, Step=19/87, loss_xy=473.372223, loss_wh=224.266144, loss_obj=455.272278, loss_cls=22.182707, loss=1175.093384, lr=0.001000, time_each_step=1.37s, eta=1:13:59\n",
      "2022-04-13 14:28:58 [INFO]\t[TRAIN] Epoch=64/100, Step=29/87, loss_xy=171.512238, loss_wh=82.952774, loss_obj=168.630630, loss_cls=7.495948, loss=430.591583, lr=0.001000, time_each_step=1.77s, eta=1:34:59\n",
      "2022-04-13 14:29:13 [INFO]\t[TRAIN] Epoch=64/100, Step=39/87, loss_xy=201.484528, loss_wh=81.237518, loss_obj=200.867279, loss_cls=9.058416, loss=492.647736, lr=0.001000, time_each_step=1.55s, eta=1:22:45\n",
      "2022-04-13 14:29:27 [INFO]\t[TRAIN] Epoch=64/100, Step=49/87, loss_xy=285.658539, loss_wh=80.344337, loss_obj=253.789322, loss_cls=12.545941, loss=632.338135, lr=0.001000, time_each_step=1.41s, eta=1:15:24\n",
      "2022-04-13 14:29:40 [INFO]\t[TRAIN] Epoch=64/100, Step=59/87, loss_xy=154.531189, loss_wh=52.963245, loss_obj=173.140488, loss_cls=6.864779, loss=387.499695, lr=0.001000, time_each_step=1.24s, eta=1:6:3\n",
      "2022-04-13 14:29:51 [INFO]\t[TRAIN] Epoch=64/100, Step=69/87, loss_xy=356.066345, loss_wh=70.843826, loss_obj=483.959808, loss_cls=16.209156, loss=927.079163, lr=0.001000, time_each_step=1.13s, eta=1:0:9\n",
      "2022-04-13 14:30:08 [INFO]\t[TRAIN] Epoch=64/100, Step=79/87, loss_xy=187.081726, loss_wh=253.266968, loss_obj=167.678223, loss_cls=8.119574, loss=616.146484, lr=0.001000, time_each_step=1.73s, eta=1:31:30\n",
      "2022-04-13 14:30:19 [INFO]\t[TRAIN] Epoch 64 finished, loss_xy=270.42813, loss_wh=131.3352, loss_obj=286.72067, loss_cls=12.219361, loss=700.70337 .\n",
      "2022-04-13 14:30:24 [INFO]\t[TRAIN] Epoch=65/100, Step=2/87, loss_xy=167.618683, loss_wh=156.829926, loss_obj=79.172684, loss_cls=7.062816, loss=410.684082, lr=0.001000, time_each_step=1.54s, eta=1:20:54\n",
      "2022-04-13 14:30:36 [INFO]\t[TRAIN] Epoch=65/100, Step=12/87, loss_xy=244.968170, loss_wh=121.419357, loss_obj=241.624390, loss_cls=10.709874, loss=618.721802, lr=0.001000, time_each_step=1.22s, eta=1:3:56\n",
      "2022-04-13 14:30:50 [INFO]\t[TRAIN] Epoch=65/100, Step=22/87, loss_xy=268.624451, loss_wh=159.859329, loss_obj=148.457184, loss_cls=11.241487, loss=588.182434, lr=0.001000, time_each_step=1.42s, eta=1:14:10\n",
      "2022-04-13 14:31:05 [INFO]\t[TRAIN] Epoch=65/100, Step=32/87, loss_xy=434.016846, loss_wh=108.924599, loss_obj=370.764587, loss_cls=18.282658, loss=931.988708, lr=0.001000, time_each_step=1.45s, eta=1:15:45\n",
      "2022-04-13 14:31:23 [INFO]\t[TRAIN] Epoch=65/100, Step=42/87, loss_xy=295.523132, loss_wh=103.421844, loss_obj=438.406372, loss_cls=13.396604, loss=850.747925, lr=0.001000, time_each_step=1.8s, eta=1:33:34\n",
      "2022-04-13 14:31:34 [INFO]\t[TRAIN] Epoch=65/100, Step=52/87, loss_xy=208.456696, loss_wh=95.904640, loss_obj=262.067932, loss_cls=9.285521, loss=575.714783, lr=0.001000, time_each_step=1.17s, eta=1:0:44\n",
      "2022-04-13 14:31:49 [INFO]\t[TRAIN] Epoch=65/100, Step=62/87, loss_xy=178.610550, loss_wh=105.272224, loss_obj=131.403488, loss_cls=7.775885, loss=423.062134, lr=0.001000, time_each_step=1.49s, eta=1:17:1\n",
      "2022-04-13 14:32:06 [INFO]\t[TRAIN] Epoch=65/100, Step=72/87, loss_xy=259.529480, loss_wh=116.516022, loss_obj=220.268906, loss_cls=11.702636, loss=608.017029, lr=0.001000, time_each_step=1.67s, eta=1:25:53\n",
      "2022-04-13 14:32:21 [INFO]\t[TRAIN] Epoch=65/100, Step=82/87, loss_xy=212.780106, loss_wh=40.893147, loss_obj=185.780075, loss_cls=9.506723, loss=448.960022, lr=0.001000, time_each_step=1.48s, eta=1:16:5\n",
      "2022-04-13 14:32:26 [INFO]\t[TRAIN] Epoch 65 finished, loss_xy=271.22183, loss_wh=126.83267, loss_obj=284.6613, loss_cls=12.205438, loss=694.92126 .\n",
      "2022-04-13 14:32:26 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 14:32:26 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 14:32:34 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 14:32:34 [INFO]\t[EVAL] Finished, Epoch=65, bbox_map=44.748181 .\n",
      "2022-04-13 14:32:38 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 14:32:38 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_65, bbox_map=44.74818137437224\n",
      "2022-04-13 14:32:40 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_65.\n",
      "2022-04-13 14:32:47 [INFO]\t[TRAIN] Epoch=66/100, Step=5/87, loss_xy=236.732559, loss_wh=130.350983, loss_obj=311.499817, loss_cls=11.165387, loss=689.748779, lr=0.001000, time_each_step=1.24s, eta=1:4:11\n",
      "2022-04-13 14:33:02 [INFO]\t[TRAIN] Epoch=66/100, Step=15/87, loss_xy=128.227386, loss_wh=104.929588, loss_obj=259.903961, loss_cls=6.035922, loss=499.096863, lr=0.001000, time_each_step=1.45s, eta=1:14:39\n",
      "2022-04-13 14:33:18 [INFO]\t[TRAIN] Epoch=66/100, Step=25/87, loss_xy=148.137543, loss_wh=29.545135, loss_obj=197.105057, loss_cls=6.885016, loss=381.672729, lr=0.001000, time_each_step=1.59s, eta=1:21:40\n",
      "2022-04-13 14:33:30 [INFO]\t[TRAIN] Epoch=66/100, Step=35/87, loss_xy=200.349854, loss_wh=116.070938, loss_obj=184.605148, loss_cls=8.547084, loss=509.573029, lr=0.001000, time_each_step=1.19s, eta=1:1:13\n",
      "2022-04-13 14:33:47 [INFO]\t[TRAIN] Epoch=66/100, Step=45/87, loss_xy=207.821365, loss_wh=136.458221, loss_obj=242.876221, loss_cls=9.676390, loss=596.832214, lr=0.001000, time_each_step=1.74s, eta=1:28:26\n",
      "2022-04-13 14:34:03 [INFO]\t[TRAIN] Epoch=66/100, Step=55/87, loss_xy=223.439240, loss_wh=298.333954, loss_obj=103.450478, loss_cls=9.451425, loss=634.675110, lr=0.001000, time_each_step=1.54s, eta=1:18:8\n",
      "2022-04-13 14:34:17 [INFO]\t[TRAIN] Epoch=66/100, Step=65/87, loss_xy=326.708405, loss_wh=319.514801, loss_obj=322.777130, loss_cls=14.621755, loss=983.622131, lr=0.001000, time_each_step=1.47s, eta=1:14:38\n",
      "2022-04-13 14:34:33 [INFO]\t[TRAIN] Epoch=66/100, Step=75/87, loss_xy=297.803833, loss_wh=66.173332, loss_obj=353.404388, loss_cls=14.124255, loss=731.505859, lr=0.001000, time_each_step=1.53s, eta=1:17:3\n",
      "2022-04-13 14:34:49 [INFO]\t[TRAIN] Epoch=66/100, Step=85/87, loss_xy=264.277344, loss_wh=107.917442, loss_obj=362.737762, loss_cls=11.720948, loss=746.653503, lr=0.001000, time_each_step=1.68s, eta=1:24:8\n",
      "2022-04-13 14:34:53 [INFO]\t[TRAIN] Epoch 66 finished, loss_xy=254.71767, loss_wh=142.00185, loss_obj=256.0533, loss_cls=11.420908, loss=664.19366 .\n",
      "2022-04-13 14:35:08 [INFO]\t[TRAIN] Epoch=67/100, Step=8/87, loss_xy=242.824860, loss_wh=193.868668, loss_obj=195.054428, loss_cls=11.058510, loss=642.806519, lr=0.001000, time_each_step=1.82s, eta=1:31:2\n",
      "2022-04-13 14:35:24 [INFO]\t[TRAIN] Epoch=67/100, Step=18/87, loss_xy=129.485184, loss_wh=42.287663, loss_obj=144.571838, loss_cls=6.051635, loss=322.396301, lr=0.001000, time_each_step=1.61s, eta=1:20:32\n",
      "2022-04-13 14:35:37 [INFO]\t[TRAIN] Epoch=67/100, Step=28/87, loss_xy=258.386932, loss_wh=232.689972, loss_obj=212.020386, loss_cls=12.017145, loss=715.114441, lr=0.001000, time_each_step=1.37s, eta=1:8:15\n",
      "2022-04-13 14:35:53 [INFO]\t[TRAIN] Epoch=67/100, Step=38/87, loss_xy=240.543030, loss_wh=112.839050, loss_obj=229.983414, loss_cls=10.853592, loss=594.219055, lr=0.001000, time_each_step=1.57s, eta=1:18:0\n",
      "2022-04-13 14:36:06 [INFO]\t[TRAIN] Epoch=67/100, Step=48/87, loss_xy=403.479218, loss_wh=139.550522, loss_obj=531.332153, loss_cls=18.306517, loss=1092.668335, lr=0.001000, time_each_step=1.26s, eta=1:2:32\n",
      "2022-04-13 14:36:23 [INFO]\t[TRAIN] Epoch=67/100, Step=58/87, loss_xy=242.746506, loss_wh=83.749664, loss_obj=315.767487, loss_cls=11.502166, loss=653.765808, lr=0.001000, time_each_step=1.73s, eta=1:25:2\n",
      "2022-04-13 14:36:37 [INFO]\t[TRAIN] Epoch=67/100, Step=68/87, loss_xy=201.120483, loss_wh=124.170944, loss_obj=214.570618, loss_cls=9.339025, loss=549.201111, lr=0.001000, time_each_step=1.35s, eta=1:6:42\n",
      "2022-04-13 14:36:50 [INFO]\t[TRAIN] Epoch=67/100, Step=78/87, loss_xy=210.925598, loss_wh=272.140839, loss_obj=113.040855, loss_cls=8.816707, loss=604.924011, lr=0.001000, time_each_step=1.37s, eta=1:7:6\n",
      "2022-04-13 14:37:05 [INFO]\t[TRAIN] Epoch 67 finished, loss_xy=252.82126, loss_wh=123.12181, loss_obj=256.06158, loss_cls=11.368194, loss=643.37286 .\n",
      "2022-04-13 14:37:08 [INFO]\t[TRAIN] Epoch=68/100, Step=1/87, loss_xy=173.731583, loss_wh=93.207085, loss_obj=187.905640, loss_cls=8.349857, loss=463.194153, lr=0.001000, time_each_step=1.77s, eta=1:26:17\n",
      "2022-04-13 14:37:21 [INFO]\t[TRAIN] Epoch=68/100, Step=11/87, loss_xy=350.992065, loss_wh=335.662048, loss_obj=318.632538, loss_cls=16.981789, loss=1022.268433, lr=0.001000, time_each_step=1.31s, eta=1:3:51\n",
      "2022-04-13 14:37:35 [INFO]\t[TRAIN] Epoch=68/100, Step=21/87, loss_xy=262.902527, loss_wh=167.592743, loss_obj=288.124817, loss_cls=11.584356, loss=730.204468, lr=0.001000, time_each_step=1.42s, eta=1:9:8\n",
      "2022-04-13 14:37:49 [INFO]\t[TRAIN] Epoch=68/100, Step=31/87, loss_xy=192.881470, loss_wh=61.755955, loss_obj=245.357529, loss_cls=9.526073, loss=509.520996, lr=0.001000, time_each_step=1.38s, eta=1:6:46\n",
      "2022-04-13 14:38:04 [INFO]\t[TRAIN] Epoch=68/100, Step=41/87, loss_xy=158.173004, loss_wh=61.314453, loss_obj=72.522636, loss_cls=6.755257, loss=298.765350, lr=0.001000, time_each_step=1.44s, eta=1:9:15\n",
      "2022-04-13 14:38:19 [INFO]\t[TRAIN] Epoch=68/100, Step=51/87, loss_xy=406.628754, loss_wh=164.930954, loss_obj=530.749512, loss_cls=17.448004, loss=1119.757202, lr=0.001000, time_each_step=1.54s, eta=1:14:1\n",
      "2022-04-13 14:38:35 [INFO]\t[TRAIN] Epoch=68/100, Step=61/87, loss_xy=251.404785, loss_wh=68.100388, loss_obj=255.672318, loss_cls=11.241800, loss=586.419312, lr=0.001000, time_each_step=1.58s, eta=1:15:35\n",
      "2022-04-13 14:38:51 [INFO]\t[TRAIN] Epoch=68/100, Step=71/87, loss_xy=323.839508, loss_wh=236.361282, loss_obj=340.747620, loss_cls=14.894264, loss=915.842712, lr=0.001000, time_each_step=1.63s, eta=1:17:46\n",
      "2022-04-13 14:39:06 [INFO]\t[TRAIN] Epoch=68/100, Step=81/87, loss_xy=242.391113, loss_wh=115.390327, loss_obj=310.621185, loss_cls=10.746556, loss=679.149170, lr=0.001000, time_each_step=1.48s, eta=1:10:23\n",
      "2022-04-13 14:39:13 [INFO]\t[TRAIN] Epoch 68 finished, loss_xy=262.45316, loss_wh=123.31805, loss_obj=294.28867, loss_cls=11.918094, loss=691.97797 .\n",
      "2022-04-13 14:39:21 [INFO]\t[TRAIN] Epoch=69/100, Step=4/87, loss_xy=229.871613, loss_wh=192.969559, loss_obj=336.864105, loss_cls=9.922991, loss=769.628296, lr=0.001000, time_each_step=1.46s, eta=1:9:21\n",
      "2022-04-13 14:39:33 [INFO]\t[TRAIN] Epoch=69/100, Step=14/87, loss_xy=246.201843, loss_wh=71.032677, loss_obj=324.636017, loss_cls=11.570144, loss=653.440674, lr=0.001000, time_each_step=1.25s, eta=0:58:59\n",
      "2022-04-13 14:39:50 [INFO]\t[TRAIN] Epoch=69/100, Step=24/87, loss_xy=318.619659, loss_wh=169.198669, loss_obj=400.595978, loss_cls=15.285480, loss=903.699768, lr=0.001000, time_each_step=1.68s, eta=1:18:45\n",
      "2022-04-13 14:40:06 [INFO]\t[TRAIN] Epoch=69/100, Step=34/87, loss_xy=232.984909, loss_wh=75.622223, loss_obj=267.547577, loss_cls=11.457911, loss=587.612549, lr=0.001000, time_each_step=1.61s, eta=1:15:6\n",
      "2022-04-13 14:40:22 [INFO]\t[TRAIN] Epoch=69/100, Step=44/87, loss_xy=208.009430, loss_wh=101.166458, loss_obj=279.385590, loss_cls=9.110613, loss=597.672119, lr=0.001000, time_each_step=1.56s, eta=1:12:51\n",
      "2022-04-13 14:40:38 [INFO]\t[TRAIN] Epoch=69/100, Step=54/87, loss_xy=269.281830, loss_wh=134.441879, loss_obj=332.794159, loss_cls=12.281659, loss=748.799500, lr=0.001000, time_each_step=1.62s, eta=1:15:14\n",
      "2022-04-13 14:40:52 [INFO]\t[TRAIN] Epoch=69/100, Step=64/87, loss_xy=393.975922, loss_wh=167.528091, loss_obj=299.301239, loss_cls=17.128981, loss=877.934265, lr=0.001000, time_each_step=1.39s, eta=1:4:20\n",
      "2022-04-13 14:41:09 [INFO]\t[TRAIN] Epoch=69/100, Step=74/87, loss_xy=319.012238, loss_wh=231.020355, loss_obj=274.256348, loss_cls=14.322799, loss=838.611755, lr=0.001000, time_each_step=1.72s, eta=1:19:9\n",
      "2022-04-13 14:41:21 [INFO]\t[TRAIN] Epoch=69/100, Step=84/87, loss_xy=208.451721, loss_wh=96.774574, loss_obj=312.349976, loss_cls=9.563947, loss=627.140259, lr=0.001000, time_each_step=1.16s, eta=0:53:42\n",
      "2022-04-13 14:41:26 [INFO]\t[TRAIN] Epoch 69 finished, loss_xy=260.59448, loss_wh=133.51918, loss_obj=278.05634, loss_cls=11.746227, loss=683.9162 .\n",
      "2022-04-13 14:41:39 [INFO]\t[TRAIN] Epoch=70/100, Step=7/87, loss_xy=278.475830, loss_wh=162.957886, loss_obj=235.101028, loss_cls=12.837152, loss=689.371887, lr=0.001000, time_each_step=1.82s, eta=1:23:3\n",
      "2022-04-13 14:41:53 [INFO]\t[TRAIN] Epoch=70/100, Step=17/87, loss_xy=440.220612, loss_wh=179.706665, loss_obj=536.796204, loss_cls=20.075228, loss=1176.798584, lr=0.001000, time_each_step=1.38s, eta=1:3:7\n",
      "2022-04-13 14:42:04 [INFO]\t[TRAIN] Epoch=70/100, Step=27/87, loss_xy=226.924774, loss_wh=110.797501, loss_obj=270.216522, loss_cls=9.935853, loss=617.874695, lr=0.001000, time_each_step=1.08s, eta=0:49:23\n",
      "2022-04-13 14:42:21 [INFO]\t[TRAIN] Epoch=70/100, Step=37/87, loss_xy=367.213989, loss_wh=336.513184, loss_obj=471.264771, loss_cls=16.445671, loss=1191.437622, lr=0.001000, time_each_step=1.75s, eta=1:18:56\n",
      "2022-04-13 14:42:32 [INFO]\t[TRAIN] Epoch=70/100, Step=47/87, loss_xy=376.689636, loss_wh=234.678741, loss_obj=474.620667, loss_cls=16.497595, loss=1102.486572, lr=0.001000, time_each_step=1.11s, eta=0:50:20\n",
      "2022-04-13 14:42:45 [INFO]\t[TRAIN] Epoch=70/100, Step=57/87, loss_xy=300.246613, loss_wh=208.589218, loss_obj=309.429474, loss_cls=14.112343, loss=832.377625, lr=0.001000, time_each_step=1.27s, eta=0:57:18\n",
      "2022-04-13 14:42:59 [INFO]\t[TRAIN] Epoch=70/100, Step=67/87, loss_xy=242.145279, loss_wh=65.208054, loss_obj=216.000259, loss_cls=10.824423, loss=534.177979, lr=0.001000, time_each_step=1.41s, eta=1:3:9\n",
      "2022-04-13 14:43:13 [INFO]\t[TRAIN] Epoch=70/100, Step=77/87, loss_xy=271.955536, loss_wh=94.331978, loss_obj=290.626770, loss_cls=13.181889, loss=670.096191, lr=0.001000, time_each_step=1.38s, eta=1:1:29\n",
      "2022-04-13 14:43:23 [INFO]\t[TRAIN] Epoch=70/100, Step=87/87, loss_xy=355.306122, loss_wh=372.754700, loss_obj=323.170013, loss_cls=16.882536, loss=1068.113403, lr=0.001000, time_each_step=1.0s, eta=0:44:47\n",
      "2022-04-13 14:43:23 [INFO]\t[TRAIN] Epoch 70 finished, loss_xy=282.57065, loss_wh=161.03285, loss_obj=319.89636, loss_cls=12.824756, loss=776.32465 .\n",
      "2022-04-13 14:43:23 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 14:43:23 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 14:43:30 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 14:43:30 [INFO]\t[EVAL] Finished, Epoch=70, bbox_map=11.097360 .\n",
      "2022-04-13 14:43:30 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_65, bbox_map=44.74818137437224\n",
      "2022-04-13 14:43:32 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_70.\n",
      "2022-04-13 14:43:45 [INFO]\t[TRAIN] Epoch=71/100, Step=10/87, loss_xy=136.385437, loss_wh=83.058273, loss_obj=300.073334, loss_cls=6.362772, loss=525.879822, lr=0.001000, time_each_step=1.26s, eta=0:55:25\n",
      "2022-04-13 14:44:01 [INFO]\t[TRAIN] Epoch=71/100, Step=20/87, loss_xy=195.515594, loss_wh=71.010529, loss_obj=233.168304, loss_cls=9.579227, loss=509.273651, lr=0.001000, time_each_step=1.59s, eta=1:9:23\n",
      "2022-04-13 14:44:14 [INFO]\t[TRAIN] Epoch=71/100, Step=30/87, loss_xy=268.088165, loss_wh=89.131851, loss_obj=165.521530, loss_cls=11.786123, loss=534.527710, lr=0.001000, time_each_step=1.34s, eta=0:58:10\n",
      "2022-04-13 14:44:29 [INFO]\t[TRAIN] Epoch=71/100, Step=40/87, loss_xy=243.615448, loss_wh=210.820984, loss_obj=217.938019, loss_cls=10.546812, loss=682.921265, lr=0.001000, time_each_step=1.46s, eta=1:3:29\n",
      "2022-04-13 14:44:44 [INFO]\t[TRAIN] Epoch=71/100, Step=50/87, loss_xy=405.926697, loss_wh=161.816498, loss_obj=504.752258, loss_cls=17.489296, loss=1089.984619, lr=0.001000, time_each_step=1.53s, eta=1:5:57\n",
      "2022-04-13 14:44:58 [INFO]\t[TRAIN] Epoch=71/100, Step=60/87, loss_xy=253.429657, loss_wh=105.827423, loss_obj=162.294525, loss_cls=10.637333, loss=532.188965, lr=0.001000, time_each_step=1.43s, eta=1:1:39\n",
      "2022-04-13 14:45:09 [INFO]\t[TRAIN] Epoch=71/100, Step=70/87, loss_xy=236.544571, loss_wh=77.519028, loss_obj=234.772644, loss_cls=10.468037, loss=559.304260, lr=0.001000, time_each_step=1.12s, eta=0:48:13\n",
      "2022-04-13 14:45:23 [INFO]\t[TRAIN] Epoch=71/100, Step=80/87, loss_xy=287.575409, loss_wh=154.112534, loss_obj=258.660889, loss_cls=12.784317, loss=713.133118, lr=0.001000, time_each_step=1.4s, eta=0:59:33\n",
      "2022-04-13 14:45:34 [INFO]\t[TRAIN] Epoch 71 finished, loss_xy=267.8511, loss_wh=146.45578, loss_obj=284.1237, loss_cls=12.003825, loss=710.43445 .\n",
      "2022-04-13 14:45:40 [INFO]\t[TRAIN] Epoch=72/100, Step=3/87, loss_xy=160.896545, loss_wh=65.870316, loss_obj=257.412354, loss_cls=7.349826, loss=491.529022, lr=0.001000, time_each_step=1.65s, eta=1:9:50\n",
      "2022-04-13 14:45:54 [INFO]\t[TRAIN] Epoch=72/100, Step=13/87, loss_xy=297.951355, loss_wh=104.736153, loss_obj=337.295837, loss_cls=13.939709, loss=753.923035, lr=0.001000, time_each_step=1.41s, eta=0:59:44\n",
      "2022-04-13 14:46:07 [INFO]\t[TRAIN] Epoch=72/100, Step=23/87, loss_xy=250.454666, loss_wh=129.607330, loss_obj=299.188446, loss_cls=11.257257, loss=690.507751, lr=0.001000, time_each_step=1.32s, eta=0:55:51\n",
      "2022-04-13 14:46:25 [INFO]\t[TRAIN] Epoch=72/100, Step=33/87, loss_xy=250.525665, loss_wh=97.921844, loss_obj=193.527115, loss_cls=11.161259, loss=553.135864, lr=0.001000, time_each_step=1.73s, eta=1:12:27\n",
      "2022-04-13 14:46:36 [INFO]\t[TRAIN] Epoch=72/100, Step=43/87, loss_xy=198.555771, loss_wh=103.494812, loss_obj=241.944244, loss_cls=8.921384, loss=552.916260, lr=0.001000, time_each_step=1.17s, eta=0:49:4\n",
      "2022-04-13 14:46:50 [INFO]\t[TRAIN] Epoch=72/100, Step=53/87, loss_xy=182.479477, loss_wh=88.679047, loss_obj=332.866150, loss_cls=8.322869, loss=612.347534, lr=0.001000, time_each_step=1.37s, eta=0:57:9\n",
      "2022-04-13 14:47:05 [INFO]\t[TRAIN] Epoch=72/100, Step=63/87, loss_xy=261.085144, loss_wh=269.211609, loss_obj=333.325989, loss_cls=12.253819, loss=875.876587, lr=0.001000, time_each_step=1.52s, eta=1:3:9\n",
      "2022-04-13 14:47:21 [INFO]\t[TRAIN] Epoch=72/100, Step=73/87, loss_xy=347.837769, loss_wh=276.959412, loss_obj=161.131805, loss_cls=15.036846, loss=800.965820, lr=0.001000, time_each_step=1.61s, eta=1:6:32\n",
      "2022-04-13 14:47:34 [INFO]\t[TRAIN] Epoch=72/100, Step=83/87, loss_xy=419.761780, loss_wh=431.734161, loss_obj=449.880310, loss_cls=18.169079, loss=1319.545288, lr=0.001000, time_each_step=1.23s, eta=0:50:36\n",
      "2022-04-13 14:47:39 [INFO]\t[TRAIN] Epoch 72 finished, loss_xy=267.39273, loss_wh=154.22107, loss_obj=288.20062, loss_cls=12.135028, loss=721.9494 .\n",
      "2022-04-13 14:47:50 [INFO]\t[TRAIN] Epoch=73/100, Step=6/87, loss_xy=225.319702, loss_wh=189.624695, loss_obj=112.374657, loss_cls=9.495016, loss=536.814026, lr=0.001000, time_each_step=1.59s, eta=1:5:9\n",
      "2022-04-13 14:48:04 [INFO]\t[TRAIN] Epoch=73/100, Step=16/87, loss_xy=231.559143, loss_wh=132.109573, loss_obj=245.778152, loss_cls=10.349051, loss=619.795898, lr=0.001000, time_each_step=1.45s, eta=0:59:11\n",
      "2022-04-13 14:48:20 [INFO]\t[TRAIN] Epoch=73/100, Step=26/87, loss_xy=229.867432, loss_wh=95.887726, loss_obj=208.862610, loss_cls=11.111296, loss=545.729065, lr=0.001000, time_each_step=1.59s, eta=1:4:29\n",
      "2022-04-13 14:48:38 [INFO]\t[TRAIN] Epoch=73/100, Step=36/87, loss_xy=198.971115, loss_wh=117.157562, loss_obj=276.838562, loss_cls=9.716902, loss=602.684143, lr=0.001000, time_each_step=1.8s, eta=1:12:41\n",
      "2022-04-13 14:48:51 [INFO]\t[TRAIN] Epoch=73/100, Step=46/87, loss_xy=354.218903, loss_wh=283.988739, loss_obj=292.264862, loss_cls=14.981934, loss=945.454468, lr=0.001000, time_each_step=1.31s, eta=0:53:3\n",
      "2022-04-13 14:49:06 [INFO]\t[TRAIN] Epoch=73/100, Step=56/87, loss_xy=307.811340, loss_wh=122.986252, loss_obj=325.027100, loss_cls=13.614851, loss=769.439575, lr=0.001000, time_each_step=1.47s, eta=0:58:57\n",
      "2022-04-13 14:49:16 [INFO]\t[TRAIN] Epoch=73/100, Step=66/87, loss_xy=230.707031, loss_wh=84.698204, loss_obj=331.107788, loss_cls=11.080931, loss=657.593994, lr=0.001000, time_each_step=1.06s, eta=0:42:36\n",
      "2022-04-13 14:49:32 [INFO]\t[TRAIN] Epoch=73/100, Step=76/87, loss_xy=274.995544, loss_wh=103.472305, loss_obj=304.012970, loss_cls=12.542138, loss=695.022949, lr=0.001000, time_each_step=1.61s, eta=1:4:10\n",
      "2022-04-13 14:49:45 [INFO]\t[TRAIN] Epoch=73/100, Step=86/87, loss_xy=225.547379, loss_wh=73.464348, loss_obj=277.197998, loss_cls=10.391438, loss=586.601135, lr=0.001000, time_each_step=1.22s, eta=0:48:21\n",
      "2022-04-13 14:49:45 [INFO]\t[TRAIN] Epoch 73 finished, loss_xy=270.3581, loss_wh=163.1367, loss_obj=268.5413, loss_cls=12.291991, loss=714.3282 .\n",
      "2022-04-13 14:49:56 [INFO]\t[TRAIN] Epoch=74/100, Step=9/87, loss_xy=297.868164, loss_wh=177.247833, loss_obj=341.679169, loss_cls=14.403299, loss=831.198486, lr=0.001000, time_each_step=1.15s, eta=0:45:46\n",
      "2022-04-13 14:50:11 [INFO]\t[TRAIN] Epoch=74/100, Step=19/87, loss_xy=349.527893, loss_wh=167.018646, loss_obj=404.652954, loss_cls=15.474811, loss=936.674255, lr=0.001000, time_each_step=1.45s, eta=0:56:58\n",
      "2022-04-13 14:50:25 [INFO]\t[TRAIN] Epoch=74/100, Step=29/87, loss_xy=135.702042, loss_wh=188.763794, loss_obj=47.344555, loss_cls=5.762415, loss=377.572784, lr=0.001000, time_each_step=1.42s, eta=0:55:43\n",
      "2022-04-13 14:50:40 [INFO]\t[TRAIN] Epoch=74/100, Step=39/87, loss_xy=370.714661, loss_wh=95.640846, loss_obj=318.194031, loss_cls=16.222885, loss=800.772461, lr=0.001000, time_each_step=1.54s, eta=1:0:7\n",
      "2022-04-13 14:50:57 [INFO]\t[TRAIN] Epoch=74/100, Step=49/87, loss_xy=219.492050, loss_wh=89.960205, loss_obj=312.375244, loss_cls=9.931911, loss=631.759399, lr=0.001000, time_each_step=1.68s, eta=1:5:6\n",
      "2022-04-13 14:51:09 [INFO]\t[TRAIN] Epoch=74/100, Step=59/87, loss_xy=426.014404, loss_wh=491.344086, loss_obj=471.169769, loss_cls=19.751860, loss=1408.280151, lr=0.001000, time_each_step=1.15s, eta=0:44:30\n",
      "2022-04-13 14:51:21 [INFO]\t[TRAIN] Epoch=74/100, Step=69/87, loss_xy=175.187668, loss_wh=55.421291, loss_obj=165.190796, loss_cls=7.884727, loss=403.684479, lr=0.001000, time_each_step=1.27s, eta=0:48:51\n",
      "2022-04-13 14:51:34 [INFO]\t[TRAIN] Epoch=74/100, Step=79/87, loss_xy=310.424988, loss_wh=104.894791, loss_obj=261.717224, loss_cls=13.501838, loss=690.538818, lr=0.001000, time_each_step=1.29s, eta=0:49:28\n",
      "2022-04-13 14:51:47 [INFO]\t[TRAIN] Epoch 74 finished, loss_xy=274.41818, loss_wh=158.71404, loss_obj=300.65247, loss_cls=12.487004, loss=746.2717 .\n",
      "2022-04-13 14:51:51 [INFO]\t[TRAIN] Epoch=75/100, Step=2/87, loss_xy=226.066498, loss_wh=125.465332, loss_obj=252.306107, loss_cls=10.222783, loss=614.060730, lr=0.001000, time_each_step=1.64s, eta=1:2:33\n",
      "2022-04-13 14:52:02 [INFO]\t[TRAIN] Epoch=75/100, Step=12/87, loss_xy=378.431885, loss_wh=191.783157, loss_obj=510.454071, loss_cls=17.160479, loss=1097.829590, lr=0.001000, time_each_step=1.16s, eta=0:44:7\n",
      "2022-04-13 14:52:20 [INFO]\t[TRAIN] Epoch=75/100, Step=22/87, loss_xy=273.964539, loss_wh=90.039871, loss_obj=345.291809, loss_cls=12.520910, loss=721.817139, lr=0.001000, time_each_step=1.79s, eta=1:7:21\n",
      "2022-04-13 14:52:31 [INFO]\t[TRAIN] Epoch=75/100, Step=32/87, loss_xy=489.356689, loss_wh=212.976486, loss_obj=345.874054, loss_cls=20.751890, loss=1068.959106, lr=0.001000, time_each_step=1.11s, eta=0:41:53\n",
      "2022-04-13 14:52:47 [INFO]\t[TRAIN] Epoch=75/100, Step=42/87, loss_xy=231.506256, loss_wh=150.699280, loss_obj=245.713318, loss_cls=10.390447, loss=638.309265, lr=0.001000, time_each_step=1.56s, eta=0:58:18\n",
      "2022-04-13 14:52:58 [INFO]\t[TRAIN] Epoch=75/100, Step=52/87, loss_xy=406.512512, loss_wh=147.536743, loss_obj=507.288574, loss_cls=18.687584, loss=1080.025513, lr=0.001000, time_each_step=1.11s, eta=0:41:38\n",
      "2022-04-13 14:53:11 [INFO]\t[TRAIN] Epoch=75/100, Step=62/87, loss_xy=168.867691, loss_wh=55.027431, loss_obj=253.468369, loss_cls=8.445793, loss=485.809296, lr=0.001000, time_each_step=1.24s, eta=0:45:54\n",
      "2022-04-13 14:53:25 [INFO]\t[TRAIN] Epoch=75/100, Step=72/87, loss_xy=158.786713, loss_wh=240.467896, loss_obj=257.088593, loss_cls=6.941758, loss=663.284973, lr=0.001000, time_each_step=1.49s, eta=0:54:57\n",
      "2022-04-13 14:53:38 [INFO]\t[TRAIN] Epoch=75/100, Step=82/87, loss_xy=236.588898, loss_wh=124.224197, loss_obj=161.884750, loss_cls=10.265254, loss=532.963135, lr=0.001000, time_each_step=1.3s, eta=0:47:51\n",
      "2022-04-13 14:53:45 [INFO]\t[TRAIN] Epoch 75 finished, loss_xy=262.9844, loss_wh=176.66394, loss_obj=280.73068, loss_cls=12.019856, loss=732.3989 .\n",
      "2022-04-13 14:53:45 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 14:53:46 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 14:53:51 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 14:53:51 [INFO]\t[EVAL] Finished, Epoch=75, bbox_map=0.761542 .\n",
      "2022-04-13 14:53:51 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_65, bbox_map=44.74818137437224\n",
      "2022-04-13 14:53:53 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_75.\n",
      "2022-04-13 14:54:06 [INFO]\t[TRAIN] Epoch=76/100, Step=5/87, loss_xy=106.282303, loss_wh=75.043060, loss_obj=154.322067, loss_cls=5.100298, loss=340.747742, lr=0.001000, time_each_step=1.96s, eta=1:11:14\n",
      "2022-04-13 14:54:21 [INFO]\t[TRAIN] Epoch=76/100, Step=15/87, loss_xy=226.123077, loss_wh=147.628632, loss_obj=232.228851, loss_cls=10.351985, loss=616.332581, lr=0.001000, time_each_step=1.45s, eta=0:52:35\n",
      "2022-04-13 14:54:34 [INFO]\t[TRAIN] Epoch=76/100, Step=25/87, loss_xy=233.282562, loss_wh=96.257828, loss_obj=185.346466, loss_cls=10.960852, loss=525.847717, lr=0.001000, time_each_step=1.4s, eta=0:50:34\n",
      "2022-04-13 14:54:46 [INFO]\t[TRAIN] Epoch=76/100, Step=35/87, loss_xy=293.229431, loss_wh=181.391510, loss_obj=313.884369, loss_cls=14.230760, loss=802.736084, lr=0.001000, time_each_step=1.13s, eta=0:40:50\n",
      "2022-04-13 14:54:59 [INFO]\t[TRAIN] Epoch=76/100, Step=45/87, loss_xy=145.873291, loss_wh=30.734419, loss_obj=199.705505, loss_cls=6.964844, loss=383.278076, lr=0.001000, time_each_step=1.35s, eta=0:48:34\n",
      "2022-04-13 14:55:11 [INFO]\t[TRAIN] Epoch=76/100, Step=55/87, loss_xy=239.669128, loss_wh=109.713608, loss_obj=259.113220, loss_cls=10.938190, loss=619.434143, lr=0.001000, time_each_step=1.21s, eta=0:43:14\n",
      "2022-04-13 14:55:27 [INFO]\t[TRAIN] Epoch=76/100, Step=65/87, loss_xy=245.967743, loss_wh=57.838360, loss_obj=272.809113, loss_cls=10.810473, loss=587.425720, lr=0.001000, time_each_step=1.6s, eta=0:56:50\n",
      "2022-04-13 14:55:41 [INFO]\t[TRAIN] Epoch=76/100, Step=75/87, loss_xy=324.463043, loss_wh=109.080208, loss_obj=232.752213, loss_cls=14.073704, loss=680.369202, lr=0.001000, time_each_step=1.32s, eta=0:46:44\n",
      "2022-04-13 14:55:56 [INFO]\t[TRAIN] Epoch=76/100, Step=85/87, loss_xy=128.755341, loss_wh=81.378227, loss_obj=143.306885, loss_cls=6.601734, loss=360.042206, lr=0.001000, time_each_step=1.56s, eta=0:55:1\n",
      "2022-04-13 14:55:59 [INFO]\t[TRAIN] Epoch 76 finished, loss_xy=271.1224, loss_wh=138.63086, loss_obj=282.802, loss_cls=12.381387, loss=704.93665 .\n",
      "2022-04-13 14:56:11 [INFO]\t[TRAIN] Epoch=77/100, Step=8/87, loss_xy=359.464661, loss_wh=187.503693, loss_obj=443.368744, loss_cls=16.902466, loss=1007.239624, lr=0.001000, time_each_step=1.48s, eta=0:51:41\n",
      "2022-04-13 14:56:23 [INFO]\t[TRAIN] Epoch=77/100, Step=18/87, loss_xy=239.813904, loss_wh=153.260559, loss_obj=192.603317, loss_cls=10.373772, loss=596.051575, lr=0.001000, time_each_step=1.2s, eta=0:41:59\n",
      "2022-04-13 14:56:37 [INFO]\t[TRAIN] Epoch=77/100, Step=28/87, loss_xy=215.160217, loss_wh=147.767349, loss_obj=242.588913, loss_cls=9.836041, loss=615.352539, lr=0.001000, time_each_step=1.39s, eta=0:48:18\n",
      "2022-04-13 14:56:52 [INFO]\t[TRAIN] Epoch=77/100, Step=38/87, loss_xy=239.903748, loss_wh=171.484421, loss_obj=227.742477, loss_cls=10.928906, loss=650.059570, lr=0.001000, time_each_step=1.47s, eta=0:50:41\n",
      "2022-04-13 14:57:06 [INFO]\t[TRAIN] Epoch=77/100, Step=48/87, loss_xy=161.392838, loss_wh=41.852028, loss_obj=227.560089, loss_cls=7.736294, loss=438.541260, lr=0.001000, time_each_step=1.44s, eta=0:49:36\n",
      "2022-04-13 14:57:21 [INFO]\t[TRAIN] Epoch=77/100, Step=58/87, loss_xy=214.006256, loss_wh=107.828407, loss_obj=282.143646, loss_cls=10.334041, loss=614.312317, lr=0.001000, time_each_step=1.45s, eta=0:49:29\n",
      "2022-04-13 14:57:34 [INFO]\t[TRAIN] Epoch=77/100, Step=68/87, loss_xy=174.681732, loss_wh=65.093307, loss_obj=192.504669, loss_cls=7.670402, loss=439.950134, lr=0.001000, time_each_step=1.35s, eta=0:45:56\n",
      "2022-04-13 14:57:47 [INFO]\t[TRAIN] Epoch=77/100, Step=78/87, loss_xy=178.550964, loss_wh=45.663063, loss_obj=289.382385, loss_cls=8.640297, loss=522.236755, lr=0.001000, time_each_step=1.33s, eta=0:45:12\n",
      "2022-04-13 14:58:00 [INFO]\t[TRAIN] Epoch 77 finished, loss_xy=263.38492, loss_wh=134.10689, loss_obj=292.8653, loss_cls=12.049055, loss=702.4062 .\n",
      "2022-04-13 14:58:04 [INFO]\t[TRAIN] Epoch=78/100, Step=1/87, loss_xy=207.799530, loss_wh=83.618660, loss_obj=341.180145, loss_cls=9.188531, loss=641.786865, lr=0.001000, time_each_step=1.68s, eta=0:56:24\n",
      "2022-04-13 14:58:19 [INFO]\t[TRAIN] Epoch=78/100, Step=11/87, loss_xy=399.606812, loss_wh=280.925690, loss_obj=382.451904, loss_cls=18.201275, loss=1081.185669, lr=0.001000, time_each_step=1.47s, eta=0:49:8\n",
      "2022-04-13 14:58:33 [INFO]\t[TRAIN] Epoch=78/100, Step=21/87, loss_xy=288.174866, loss_wh=212.310242, loss_obj=363.008484, loss_cls=14.134173, loss=877.627747, lr=0.001000, time_each_step=1.37s, eta=0:45:44\n",
      "2022-04-13 14:58:46 [INFO]\t[TRAIN] Epoch=78/100, Step=31/87, loss_xy=409.550537, loss_wh=179.592224, loss_obj=388.073029, loss_cls=19.234221, loss=996.450012, lr=0.001000, time_each_step=1.32s, eta=0:43:57\n",
      "2022-04-13 14:58:59 [INFO]\t[TRAIN] Epoch=78/100, Step=41/87, loss_xy=190.660706, loss_wh=103.897072, loss_obj=220.143005, loss_cls=8.651284, loss=523.352112, lr=0.001000, time_each_step=1.26s, eta=0:41:36\n",
      "2022-04-13 14:59:13 [INFO]\t[TRAIN] Epoch=78/100, Step=51/87, loss_xy=408.537628, loss_wh=202.107941, loss_obj=446.366821, loss_cls=18.456577, loss=1075.468994, lr=0.001000, time_each_step=1.43s, eta=0:47:9\n",
      "2022-04-13 14:59:33 [INFO]\t[TRAIN] Epoch=78/100, Step=61/87, loss_xy=260.691284, loss_wh=92.052597, loss_obj=329.079163, loss_cls=11.969985, loss=693.793030, lr=0.001000, time_each_step=1.97s, eta=1:4:5\n",
      "2022-04-13 14:59:44 [INFO]\t[TRAIN] Epoch=78/100, Step=71/87, loss_xy=228.293274, loss_wh=86.110870, loss_obj=162.456985, loss_cls=9.789415, loss=486.650574, lr=0.001000, time_each_step=1.19s, eta=0:38:49\n",
      "2022-04-13 15:00:01 [INFO]\t[TRAIN] Epoch=78/100, Step=81/87, loss_xy=200.928940, loss_wh=123.444946, loss_obj=182.646713, loss_cls=8.871286, loss=515.891907, lr=0.001000, time_each_step=1.63s, eta=0:52:44\n",
      "2022-04-13 15:00:07 [INFO]\t[TRAIN] Epoch 78 finished, loss_xy=267.56448, loss_wh=123.74516, loss_obj=276.4154, loss_cls=12.221628, loss=679.9467 .\n",
      "2022-04-13 15:00:14 [INFO]\t[TRAIN] Epoch=79/100, Step=4/87, loss_xy=101.700371, loss_wh=78.893585, loss_obj=145.065292, loss_cls=4.529973, loss=330.189209, lr=0.001000, time_each_step=1.27s, eta=0:40:59\n",
      "2022-04-13 15:00:28 [INFO]\t[TRAIN] Epoch=79/100, Step=14/87, loss_xy=434.246002, loss_wh=124.482124, loss_obj=498.581329, loss_cls=20.530245, loss=1077.839722, lr=0.001000, time_each_step=1.4s, eta=0:44:45\n",
      "2022-04-13 15:00:42 [INFO]\t[TRAIN] Epoch=79/100, Step=24/87, loss_xy=247.294296, loss_wh=81.159180, loss_obj=359.722412, loss_cls=11.974651, loss=700.150574, lr=0.001000, time_each_step=1.44s, eta=0:45:53\n",
      "2022-04-13 15:00:56 [INFO]\t[TRAIN] Epoch=79/100, Step=34/87, loss_xy=157.911240, loss_wh=60.417370, loss_obj=214.307083, loss_cls=7.466971, loss=440.102661, lr=0.001000, time_each_step=1.37s, eta=0:43:30\n",
      "2022-04-13 15:01:08 [INFO]\t[TRAIN] Epoch=79/100, Step=44/87, loss_xy=183.817520, loss_wh=55.020119, loss_obj=257.429626, loss_cls=8.500881, loss=504.768158, lr=0.001000, time_each_step=1.24s, eta=0:39:16\n",
      "2022-04-13 15:01:23 [INFO]\t[TRAIN] Epoch=79/100, Step=54/87, loss_xy=514.414062, loss_wh=317.021942, loss_obj=625.128845, loss_cls=23.882900, loss=1480.447876, lr=0.001000, time_each_step=1.44s, eta=0:45:9\n",
      "2022-04-13 15:01:37 [INFO]\t[TRAIN] Epoch=79/100, Step=64/87, loss_xy=227.114014, loss_wh=65.169296, loss_obj=317.630341, loss_cls=10.551525, loss=620.465210, lr=0.001000, time_each_step=1.47s, eta=0:45:52\n",
      "2022-04-13 15:01:51 [INFO]\t[TRAIN] Epoch=79/100, Step=74/87, loss_xy=367.723755, loss_wh=252.233704, loss_obj=457.647675, loss_cls=16.404564, loss=1094.009644, lr=0.001000, time_each_step=1.37s, eta=0:42:26\n",
      "2022-04-13 15:02:08 [INFO]\t[TRAIN] Epoch=79/100, Step=84/87, loss_xy=333.935089, loss_wh=173.067291, loss_obj=411.269928, loss_cls=16.320377, loss=934.592712, lr=0.001000, time_each_step=1.7s, eta=0:52:23\n",
      "2022-04-13 15:02:14 [INFO]\t[TRAIN] Epoch 79 finished, loss_xy=274.99637, loss_wh=141.65842, loss_obj=291.01395, loss_cls=12.531299, loss=720.2001 .\n",
      "2022-04-13 15:02:24 [INFO]\t[TRAIN] Epoch=80/100, Step=7/87, loss_xy=142.385712, loss_wh=61.948849, loss_obj=183.214981, loss_cls=6.701936, loss=394.251495, lr=0.001000, time_each_step=1.54s, eta=0:47:12\n",
      "2022-04-13 15:02:37 [INFO]\t[TRAIN] Epoch=80/100, Step=17/87, loss_xy=223.451370, loss_wh=113.026993, loss_obj=232.661850, loss_cls=10.129214, loss=579.269409, lr=0.001000, time_each_step=1.38s, eta=0:42:2\n",
      "2022-04-13 15:02:53 [INFO]\t[TRAIN] Epoch=80/100, Step=27/87, loss_xy=206.168213, loss_wh=195.554260, loss_obj=166.495041, loss_cls=8.973133, loss=577.190674, lr=0.001000, time_each_step=1.58s, eta=0:47:41\n",
      "2022-04-13 15:03:09 [INFO]\t[TRAIN] Epoch=80/100, Step=37/87, loss_xy=259.047546, loss_wh=183.952423, loss_obj=331.878113, loss_cls=11.880417, loss=786.758484, lr=0.001000, time_each_step=1.63s, eta=0:49:9\n",
      "2022-04-13 15:03:24 [INFO]\t[TRAIN] Epoch=80/100, Step=47/87, loss_xy=294.624969, loss_wh=239.061783, loss_obj=305.876251, loss_cls=13.219434, loss=852.782410, lr=0.001000, time_each_step=1.46s, eta=0:43:38\n",
      "2022-04-13 15:03:38 [INFO]\t[TRAIN] Epoch=80/100, Step=57/87, loss_xy=300.703064, loss_wh=77.011620, loss_obj=424.230072, loss_cls=14.350860, loss=816.295593, lr=0.001000, time_each_step=1.38s, eta=0:41:13\n",
      "2022-04-13 15:03:50 [INFO]\t[TRAIN] Epoch=80/100, Step=67/87, loss_xy=177.846924, loss_wh=97.174652, loss_obj=171.397888, loss_cls=7.801867, loss=454.221344, lr=0.001000, time_each_step=1.23s, eta=0:36:32\n",
      "2022-04-13 15:04:03 [INFO]\t[TRAIN] Epoch=80/100, Step=77/87, loss_xy=191.543503, loss_wh=151.661636, loss_obj=158.120819, loss_cls=8.388205, loss=509.714172, lr=0.001000, time_each_step=1.26s, eta=0:37:7\n",
      "2022-04-13 15:04:16 [INFO]\t[TRAIN] Epoch=80/100, Step=87/87, loss_xy=277.078308, loss_wh=122.083488, loss_obj=272.997101, loss_cls=12.541031, loss=684.699951, lr=0.001000, time_each_step=1.3s, eta=0:38:12\n",
      "2022-04-13 15:04:16 [INFO]\t[TRAIN] Epoch 80 finished, loss_xy=278.02664, loss_wh=137.88419, loss_obj=293.2613, loss_cls=12.653871, loss=721.826 .\n",
      "2022-04-13 15:04:16 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:04:16 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:04:23 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:04:23 [INFO]\t[EVAL] Finished, Epoch=80, bbox_map=57.398677 .\n",
      "2022-04-13 15:04:28 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 15:04:28 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_80, bbox_map=57.39867716289374\n",
      "2022-04-13 15:04:29 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_80.\n",
      "2022-04-13 15:04:44 [INFO]\t[TRAIN] Epoch=81/100, Step=10/87, loss_xy=175.779099, loss_wh=70.879395, loss_obj=206.280945, loss_cls=8.100317, loss=461.039764, lr=0.001000, time_each_step=1.47s, eta=0:43:11\n",
      "2022-04-13 15:04:57 [INFO]\t[TRAIN] Epoch=81/100, Step=20/87, loss_xy=173.913116, loss_wh=46.719246, loss_obj=198.757782, loss_cls=8.736673, loss=428.126801, lr=0.001000, time_each_step=1.32s, eta=0:38:39\n",
      "2022-04-13 15:05:09 [INFO]\t[TRAIN] Epoch=81/100, Step=30/87, loss_xy=150.783020, loss_wh=71.869370, loss_obj=114.870552, loss_cls=7.028472, loss=344.551422, lr=0.001000, time_each_step=1.19s, eta=0:34:42\n",
      "2022-04-13 15:05:23 [INFO]\t[TRAIN] Epoch=81/100, Step=40/87, loss_xy=262.407959, loss_wh=65.546310, loss_obj=371.344604, loss_cls=12.035307, loss=711.334167, lr=0.001000, time_each_step=1.37s, eta=0:39:41\n",
      "2022-04-13 15:05:36 [INFO]\t[TRAIN] Epoch=81/100, Step=50/87, loss_xy=297.158295, loss_wh=207.002594, loss_obj=365.699585, loss_cls=13.994684, loss=883.855164, lr=0.001000, time_each_step=1.31s, eta=0:37:38\n",
      "2022-04-13 15:05:50 [INFO]\t[TRAIN] Epoch=81/100, Step=60/87, loss_xy=357.134796, loss_wh=172.151291, loss_obj=231.349640, loss_cls=17.263033, loss=777.898804, lr=0.001000, time_each_step=1.44s, eta=0:41:6\n",
      "2022-04-13 15:06:02 [INFO]\t[TRAIN] Epoch=81/100, Step=70/87, loss_xy=135.910110, loss_wh=36.318153, loss_obj=148.200943, loss_cls=6.218954, loss=326.648163, lr=0.001000, time_each_step=1.16s, eta=0:33:13\n",
      "2022-04-13 15:06:15 [INFO]\t[TRAIN] Epoch=81/100, Step=80/87, loss_xy=395.327698, loss_wh=260.894806, loss_obj=488.931366, loss_cls=18.612101, loss=1163.765991, lr=0.001000, time_each_step=1.27s, eta=0:35:50\n",
      "2022-04-13 15:06:30 [INFO]\t[TRAIN] Epoch 81 finished, loss_xy=270.49603, loss_wh=129.62549, loss_obj=253.64973, loss_cls=12.482676, loss=666.2539 .\n",
      "2022-04-13 15:06:35 [INFO]\t[TRAIN] Epoch=82/100, Step=3/87, loss_xy=197.971848, loss_wh=99.725433, loss_obj=171.425323, loss_cls=8.814745, loss=477.937347, lr=0.001000, time_each_step=2.0s, eta=0:55:50\n",
      "2022-04-13 15:06:52 [INFO]\t[TRAIN] Epoch=82/100, Step=13/87, loss_xy=224.506470, loss_wh=85.640381, loss_obj=175.585724, loss_cls=9.494041, loss=495.226624, lr=0.001000, time_each_step=1.68s, eta=0:46:36\n",
      "2022-04-13 15:07:04 [INFO]\t[TRAIN] Epoch=82/100, Step=23/87, loss_xy=287.104370, loss_wh=314.829803, loss_obj=293.911987, loss_cls=14.327137, loss=910.173340, lr=0.001000, time_each_step=1.22s, eta=0:33:59\n",
      "2022-04-13 15:07:19 [INFO]\t[TRAIN] Epoch=82/100, Step=33/87, loss_xy=265.758636, loss_wh=188.973480, loss_obj=246.350479, loss_cls=11.681342, loss=712.763916, lr=0.001000, time_each_step=1.52s, eta=0:41:51\n",
      "2022-04-13 15:07:35 [INFO]\t[TRAIN] Epoch=82/100, Step=43/87, loss_xy=245.387863, loss_wh=231.889236, loss_obj=267.427643, loss_cls=11.244221, loss=755.948914, lr=0.001000, time_each_step=1.59s, eta=0:43:28\n",
      "2022-04-13 15:07:49 [INFO]\t[TRAIN] Epoch=82/100, Step=53/87, loss_xy=294.878937, loss_wh=181.644623, loss_obj=195.426453, loss_cls=13.686485, loss=685.636475, lr=0.001000, time_each_step=1.36s, eta=0:37:8\n",
      "2022-04-13 15:08:02 [INFO]\t[TRAIN] Epoch=82/100, Step=63/87, loss_xy=187.055740, loss_wh=148.248413, loss_obj=85.958412, loss_cls=8.591340, loss=429.853882, lr=0.001000, time_each_step=1.3s, eta=0:35:11\n",
      "2022-04-13 15:08:19 [INFO]\t[TRAIN] Epoch=82/100, Step=73/87, loss_xy=205.908569, loss_wh=93.790962, loss_obj=204.307129, loss_cls=9.300144, loss=513.306824, lr=0.001000, time_each_step=1.74s, eta=0:46:45\n",
      "2022-04-13 15:08:32 [INFO]\t[TRAIN] Epoch=82/100, Step=83/87, loss_xy=283.288177, loss_wh=114.550652, loss_obj=287.347076, loss_cls=14.144140, loss=699.330078, lr=0.001000, time_each_step=1.35s, eta=0:36:3\n",
      "2022-04-13 15:08:37 [INFO]\t[TRAIN] Epoch 82 finished, loss_xy=269.4242, loss_wh=150.10507, loss_obj=266.51636, loss_cls=12.330902, loss=698.37646 .\n",
      "2022-04-13 15:08:47 [INFO]\t[TRAIN] Epoch=83/100, Step=6/87, loss_xy=367.510254, loss_wh=166.150269, loss_obj=705.539368, loss_cls=16.895365, loss=1256.095337, lr=0.001000, time_each_step=1.47s, eta=0:39:5\n",
      "2022-04-13 15:09:02 [INFO]\t[TRAIN] Epoch=83/100, Step=16/87, loss_xy=293.156342, loss_wh=135.384460, loss_obj=305.191956, loss_cls=15.041131, loss=748.773926, lr=0.001000, time_each_step=1.51s, eta=0:39:42\n",
      "2022-04-13 15:09:20 [INFO]\t[TRAIN] Epoch=83/100, Step=26/87, loss_xy=280.074341, loss_wh=188.620911, loss_obj=250.749588, loss_cls=12.870840, loss=732.315674, lr=0.001000, time_each_step=1.78s, eta=0:46:29\n",
      "2022-04-13 15:09:36 [INFO]\t[TRAIN] Epoch=83/100, Step=36/87, loss_xy=342.633759, loss_wh=196.810471, loss_obj=290.655487, loss_cls=15.024450, loss=845.124207, lr=0.001000, time_each_step=1.58s, eta=0:41:1\n",
      "2022-04-13 15:09:48 [INFO]\t[TRAIN] Epoch=83/100, Step=46/87, loss_xy=200.517365, loss_wh=90.074417, loss_obj=274.429626, loss_cls=9.498724, loss=574.520142, lr=0.001000, time_each_step=1.15s, eta=0:30:0\n",
      "2022-04-13 15:09:59 [INFO]\t[TRAIN] Epoch=83/100, Step=56/87, loss_xy=179.317566, loss_wh=31.162527, loss_obj=298.657806, loss_cls=8.294168, loss=517.432068, lr=0.001000, time_each_step=1.17s, eta=0:30:20\n",
      "2022-04-13 15:10:13 [INFO]\t[TRAIN] Epoch=83/100, Step=66/87, loss_xy=293.970978, loss_wh=100.296394, loss_obj=272.493317, loss_cls=13.436149, loss=680.196838, lr=0.001000, time_each_step=1.39s, eta=0:35:36\n",
      "2022-04-13 15:10:30 [INFO]\t[TRAIN] Epoch=83/100, Step=76/87, loss_xy=251.793854, loss_wh=146.610794, loss_obj=118.313332, loss_cls=10.593746, loss=527.311768, lr=0.001000, time_each_step=1.65s, eta=0:41:46\n",
      "2022-04-13 15:10:41 [INFO]\t[TRAIN] Epoch=83/100, Step=86/87, loss_xy=197.799438, loss_wh=67.186424, loss_obj=255.657379, loss_cls=9.094961, loss=529.738220, lr=0.001000, time_each_step=1.13s, eta=0:28:41\n",
      "2022-04-13 15:10:41 [INFO]\t[TRAIN] Epoch 83 finished, loss_xy=262.90817, loss_wh=116.31543, loss_obj=273.14865, loss_cls=12.116236, loss=664.4885 .\n",
      "2022-04-13 15:10:54 [INFO]\t[TRAIN] Epoch=84/100, Step=9/87, loss_xy=285.435028, loss_wh=266.638916, loss_obj=291.489868, loss_cls=13.760455, loss=857.324280, lr=0.001000, time_each_step=1.31s, eta=0:32:54\n",
      "2022-04-13 15:11:08 [INFO]\t[TRAIN] Epoch=84/100, Step=19/87, loss_xy=252.851837, loss_wh=66.458817, loss_obj=229.249252, loss_cls=12.599144, loss=561.159058, lr=0.001000, time_each_step=1.35s, eta=0:33:39\n",
      "2022-04-13 15:11:20 [INFO]\t[TRAIN] Epoch=84/100, Step=29/87, loss_xy=193.185760, loss_wh=71.767746, loss_obj=263.931854, loss_cls=9.162302, loss=538.047668, lr=0.001000, time_each_step=1.18s, eta=0:29:26\n",
      "2022-04-13 15:11:33 [INFO]\t[TRAIN] Epoch=84/100, Step=39/87, loss_xy=472.804443, loss_wh=265.324310, loss_obj=404.937439, loss_cls=21.280376, loss=1164.346558, lr=0.001000, time_each_step=1.33s, eta=0:32:38\n",
      "2022-04-13 15:11:48 [INFO]\t[TRAIN] Epoch=84/100, Step=49/87, loss_xy=366.556946, loss_wh=870.481934, loss_obj=273.268646, loss_cls=15.696153, loss=1526.003662, lr=0.001000, time_each_step=1.49s, eta=0:36:17\n",
      "2022-04-13 15:12:03 [INFO]\t[TRAIN] Epoch=84/100, Step=59/87, loss_xy=369.616730, loss_wh=481.168671, loss_obj=332.694397, loss_cls=16.157166, loss=1199.636963, lr=0.001000, time_each_step=1.55s, eta=0:37:34\n",
      "2022-04-13 15:12:15 [INFO]\t[TRAIN] Epoch=84/100, Step=69/87, loss_xy=196.078827, loss_wh=59.825500, loss_obj=181.775574, loss_cls=8.844419, loss=446.524323, lr=0.001000, time_each_step=1.22s, eta=0:29:24\n",
      "2022-04-13 15:12:32 [INFO]\t[TRAIN] Epoch=84/100, Step=79/87, loss_xy=223.820633, loss_wh=86.531517, loss_obj=265.378204, loss_cls=10.982038, loss=586.712402, lr=0.001000, time_each_step=1.63s, eta=0:38:56\n",
      "2022-04-13 15:12:41 [INFO]\t[TRAIN] Epoch 84 finished, loss_xy=266.49066, loss_wh=175.18526, loss_obj=269.1678, loss_cls=12.270321, loss=723.1141 .\n",
      "2022-04-13 15:12:46 [INFO]\t[TRAIN] Epoch=85/100, Step=2/87, loss_xy=176.537140, loss_wh=191.546875, loss_obj=83.621582, loss_cls=7.533631, loss=459.239227, lr=0.001000, time_each_step=1.4s, eta=0:33:1\n",
      "2022-04-13 15:13:01 [INFO]\t[TRAIN] Epoch=85/100, Step=12/87, loss_xy=255.839218, loss_wh=111.383011, loss_obj=266.106995, loss_cls=12.342978, loss=645.672180, lr=0.001000, time_each_step=1.53s, eta=0:35:52\n",
      "2022-04-13 15:13:15 [INFO]\t[TRAIN] Epoch=85/100, Step=22/87, loss_xy=176.059601, loss_wh=47.286255, loss_obj=218.023743, loss_cls=8.505413, loss=449.875000, lr=0.001000, time_each_step=1.34s, eta=0:31:5\n",
      "2022-04-13 15:13:29 [INFO]\t[TRAIN] Epoch=85/100, Step=32/87, loss_xy=254.333466, loss_wh=76.149292, loss_obj=199.002319, loss_cls=10.749400, loss=540.234497, lr=0.001000, time_each_step=1.47s, eta=0:34:2\n",
      "2022-04-13 15:13:41 [INFO]\t[TRAIN] Epoch=85/100, Step=42/87, loss_xy=287.592834, loss_wh=75.030334, loss_obj=447.092102, loss_cls=13.650374, loss=823.365662, lr=0.001000, time_each_step=1.2s, eta=0:27:32\n",
      "2022-04-13 15:13:56 [INFO]\t[TRAIN] Epoch=85/100, Step=52/87, loss_xy=206.862549, loss_wh=81.329712, loss_obj=157.621231, loss_cls=9.164916, loss=454.978394, lr=0.001000, time_each_step=1.46s, eta=0:33:17\n",
      "2022-04-13 15:14:13 [INFO]\t[TRAIN] Epoch=85/100, Step=62/87, loss_xy=252.676758, loss_wh=86.759216, loss_obj=154.049393, loss_cls=10.657374, loss=504.142731, lr=0.001000, time_each_step=1.68s, eta=0:37:45\n",
      "2022-04-13 15:14:27 [INFO]\t[TRAIN] Epoch=85/100, Step=72/87, loss_xy=172.995697, loss_wh=34.139019, loss_obj=174.262115, loss_cls=7.671838, loss=389.068695, lr=0.001000, time_each_step=1.38s, eta=0:31:1\n",
      "2022-04-13 15:14:40 [INFO]\t[TRAIN] Epoch=85/100, Step=82/87, loss_xy=494.745544, loss_wh=251.213562, loss_obj=434.441711, loss_cls=22.332964, loss=1202.733887, lr=0.001000, time_each_step=1.37s, eta=0:30:26\n",
      "2022-04-13 15:14:46 [INFO]\t[TRAIN] Epoch 85 finished, loss_xy=260.14932, loss_wh=118.46939, loss_obj=277.69476, loss_cls=12.040683, loss=668.3542 .\n",
      "2022-04-13 15:14:46 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:14:47 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:14:52 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:14:53 [INFO]\t[EVAL] Finished, Epoch=85, bbox_map=18.713775 .\n",
      "2022-04-13 15:14:53 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_80, bbox_map=57.39867716289374\n",
      "2022-04-13 15:14:54 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_85.\n",
      "2022-04-13 15:15:02 [INFO]\t[TRAIN] Epoch=86/100, Step=5/87, loss_xy=150.236908, loss_wh=53.876228, loss_obj=197.240265, loss_cls=6.837666, loss=408.191071, lr=0.001000, time_each_step=1.39s, eta=0:30:26\n",
      "2022-04-13 15:15:15 [INFO]\t[TRAIN] Epoch=86/100, Step=15/87, loss_xy=368.348724, loss_wh=109.202553, loss_obj=416.614685, loss_cls=17.812820, loss=911.978760, lr=0.001000, time_each_step=1.27s, eta=0:27:34\n",
      "2022-04-13 15:15:32 [INFO]\t[TRAIN] Epoch=86/100, Step=25/87, loss_xy=240.389648, loss_wh=198.997787, loss_obj=271.217224, loss_cls=10.749102, loss=721.353760, lr=0.001000, time_each_step=1.68s, eta=0:36:14\n",
      "2022-04-13 15:15:48 [INFO]\t[TRAIN] Epoch=86/100, Step=35/87, loss_xy=347.406616, loss_wh=221.786926, loss_obj=477.906372, loss_cls=15.600922, loss=1062.700806, lr=0.001000, time_each_step=1.65s, eta=0:35:15\n",
      "2022-04-13 15:16:01 [INFO]\t[TRAIN] Epoch=86/100, Step=45/87, loss_xy=264.046143, loss_wh=123.448837, loss_obj=302.105713, loss_cls=13.143318, loss=702.744019, lr=0.001000, time_each_step=1.26s, eta=0:26:42\n",
      "2022-04-13 15:16:16 [INFO]\t[TRAIN] Epoch=86/100, Step=55/87, loss_xy=285.813538, loss_wh=101.348816, loss_obj=153.249435, loss_cls=12.054434, loss=552.466248, lr=0.001000, time_each_step=1.54s, eta=0:32:25\n",
      "2022-04-13 15:16:28 [INFO]\t[TRAIN] Epoch=86/100, Step=65/87, loss_xy=216.666107, loss_wh=51.750072, loss_obj=259.843506, loss_cls=10.093321, loss=538.352966, lr=0.001000, time_each_step=1.15s, eta=0:24:8\n",
      "2022-04-13 15:16:42 [INFO]\t[TRAIN] Epoch=86/100, Step=75/87, loss_xy=247.066315, loss_wh=126.297142, loss_obj=234.330200, loss_cls=11.849518, loss=619.543213, lr=0.001000, time_each_step=1.45s, eta=0:29:58\n",
      "2022-04-13 15:16:56 [INFO]\t[TRAIN] Epoch=86/100, Step=85/87, loss_xy=254.261749, loss_wh=182.281616, loss_obj=211.566193, loss_cls=11.610389, loss=659.719971, lr=0.001000, time_each_step=1.33s, eta=0:27:25\n",
      "2022-04-13 15:16:58 [INFO]\t[TRAIN] Epoch 86 finished, loss_xy=263.77896, loss_wh=131.37395, loss_obj=294.59668, loss_cls=12.211802, loss=701.9615 .\n",
      "2022-04-13 15:17:11 [INFO]\t[TRAIN] Epoch=87/100, Step=8/87, loss_xy=246.712479, loss_wh=72.496414, loss_obj=166.308426, loss_cls=10.734583, loss=496.251923, lr=0.001000, time_each_step=1.54s, eta=0:31:27\n",
      "2022-04-13 15:17:24 [INFO]\t[TRAIN] Epoch=87/100, Step=18/87, loss_xy=489.462830, loss_wh=241.172485, loss_obj=610.447937, loss_cls=23.268360, loss=1364.351562, lr=0.001000, time_each_step=1.31s, eta=0:26:29\n",
      "2022-04-13 15:17:38 [INFO]\t[TRAIN] Epoch=87/100, Step=28/87, loss_xy=140.474060, loss_wh=92.854782, loss_obj=150.508942, loss_cls=6.633988, loss=390.471771, lr=0.001000, time_each_step=1.41s, eta=0:28:17\n",
      "2022-04-13 15:17:52 [INFO]\t[TRAIN] Epoch=87/100, Step=38/87, loss_xy=206.754486, loss_wh=89.737198, loss_obj=223.535782, loss_cls=10.345918, loss=530.373413, lr=0.001000, time_each_step=1.35s, eta=0:26:55\n",
      "2022-04-13 15:18:05 [INFO]\t[TRAIN] Epoch=87/100, Step=48/87, loss_xy=384.528717, loss_wh=133.648300, loss_obj=419.662018, loss_cls=17.180122, loss=955.019104, lr=0.001000, time_each_step=1.26s, eta=0:24:57\n",
      "2022-04-13 15:18:21 [INFO]\t[TRAIN] Epoch=87/100, Step=58/87, loss_xy=290.455017, loss_wh=135.106644, loss_obj=255.753235, loss_cls=12.967655, loss=694.282532, lr=0.001000, time_each_step=1.61s, eta=0:31:31\n",
      "2022-04-13 15:18:33 [INFO]\t[TRAIN] Epoch=87/100, Step=68/87, loss_xy=253.227417, loss_wh=81.343727, loss_obj=214.602844, loss_cls=11.938822, loss=561.112793, lr=0.001000, time_each_step=1.22s, eta=0:23:38\n",
      "2022-04-13 15:18:51 [INFO]\t[TRAIN] Epoch=87/100, Step=78/87, loss_xy=299.298798, loss_wh=200.331955, loss_obj=412.384766, loss_cls=13.631580, loss=925.647095, lr=0.001000, time_each_step=1.83s, eta=0:35:5\n",
      "2022-04-13 15:19:02 [INFO]\t[TRAIN] Epoch 87 finished, loss_xy=277.81674, loss_wh=128.39864, loss_obj=277.5668, loss_cls=12.883005, loss=696.66516 .\n",
      "2022-04-13 15:19:06 [INFO]\t[TRAIN] Epoch=88/100, Step=1/87, loss_xy=240.997162, loss_wh=105.016594, loss_obj=218.847076, loss_cls=10.882822, loss=575.743652, lr=0.001000, time_each_step=1.5s, eta=0:28:29\n",
      "2022-04-13 15:19:21 [INFO]\t[TRAIN] Epoch=88/100, Step=11/87, loss_xy=257.595154, loss_wh=265.258514, loss_obj=273.751648, loss_cls=12.261767, loss=808.867065, lr=0.001000, time_each_step=1.42s, eta=0:26:48\n",
      "2022-04-13 15:19:36 [INFO]\t[TRAIN] Epoch=88/100, Step=21/87, loss_xy=281.971191, loss_wh=98.198509, loss_obj=171.448990, loss_cls=11.914681, loss=563.533386, lr=0.001000, time_each_step=1.59s, eta=0:29:39\n",
      "2022-04-13 15:19:49 [INFO]\t[TRAIN] Epoch=88/100, Step=31/87, loss_xy=224.033875, loss_wh=66.673035, loss_obj=158.803925, loss_cls=9.900119, loss=459.410950, lr=0.001000, time_each_step=1.31s, eta=0:24:17\n",
      "2022-04-13 15:20:05 [INFO]\t[TRAIN] Epoch=88/100, Step=41/87, loss_xy=297.716705, loss_wh=76.919167, loss_obj=231.559677, loss_cls=13.905549, loss=620.101135, lr=0.001000, time_each_step=1.52s, eta=0:28:0\n",
      "2022-04-13 15:20:14 [INFO]\t[TRAIN] Epoch=88/100, Step=51/87, loss_xy=398.782654, loss_wh=126.361099, loss_obj=410.884216, loss_cls=19.263073, loss=955.291016, lr=0.001000, time_each_step=0.98s, eta=0:17:58\n",
      "2022-04-13 15:20:34 [INFO]\t[TRAIN] Epoch=88/100, Step=61/87, loss_xy=186.860992, loss_wh=135.989914, loss_obj=202.579117, loss_cls=8.359808, loss=533.789795, lr=0.001000, time_each_step=1.98s, eta=0:35:35\n",
      "2022-04-13 15:20:45 [INFO]\t[TRAIN] Epoch=88/100, Step=71/87, loss_xy=362.369629, loss_wh=179.786331, loss_obj=416.003174, loss_cls=17.616621, loss=975.775757, lr=0.001000, time_each_step=1.12s, eta=0:20:7\n",
      "2022-04-13 15:21:01 [INFO]\t[TRAIN] Epoch=88/100, Step=81/87, loss_xy=264.632996, loss_wh=139.793198, loss_obj=201.686829, loss_cls=11.952369, loss=618.065430, lr=0.001000, time_each_step=1.59s, eta=0:28:10\n",
      "2022-04-13 15:21:10 [INFO]\t[TRAIN] Epoch 88 finished, loss_xy=263.26828, loss_wh=124.60886, loss_obj=267.60922, loss_cls=12.079986, loss=667.56635 .\n",
      "2022-04-13 15:21:17 [INFO]\t[TRAIN] Epoch=89/100, Step=4/87, loss_xy=218.856995, loss_wh=108.885056, loss_obj=178.644684, loss_cls=9.715198, loss=516.101929, lr=0.001000, time_each_step=1.5s, eta=0:26:20\n",
      "2022-04-13 15:21:33 [INFO]\t[TRAIN] Epoch=89/100, Step=14/87, loss_xy=254.322250, loss_wh=137.613312, loss_obj=233.633026, loss_cls=11.435436, loss=637.004028, lr=0.001000, time_each_step=1.65s, eta=0:28:39\n",
      "2022-04-13 15:21:50 [INFO]\t[TRAIN] Epoch=89/100, Step=24/87, loss_xy=312.042908, loss_wh=99.498558, loss_obj=389.297791, loss_cls=14.413086, loss=815.252319, lr=0.001000, time_each_step=1.68s, eta=0:28:52\n",
      "2022-04-13 15:22:03 [INFO]\t[TRAIN] Epoch=89/100, Step=34/87, loss_xy=205.938171, loss_wh=57.797691, loss_obj=82.677719, loss_cls=8.612253, loss=355.025818, lr=0.001000, time_each_step=1.3s, eta=0:22:15\n",
      "2022-04-13 15:22:16 [INFO]\t[TRAIN] Epoch=89/100, Step=44/87, loss_xy=331.726105, loss_wh=94.556908, loss_obj=268.158356, loss_cls=15.282741, loss=709.724121, lr=0.001000, time_each_step=1.33s, eta=0:22:26\n",
      "2022-04-13 15:22:30 [INFO]\t[TRAIN] Epoch=89/100, Step=54/87, loss_xy=228.690033, loss_wh=157.529846, loss_obj=284.810242, loss_cls=10.720474, loss=681.750610, lr=0.001000, time_each_step=1.41s, eta=0:23:35\n",
      "2022-04-13 15:22:47 [INFO]\t[TRAIN] Epoch=89/100, Step=64/87, loss_xy=248.827454, loss_wh=89.384972, loss_obj=165.331161, loss_cls=10.539967, loss=514.083557, lr=0.001000, time_each_step=1.66s, eta=0:27:30\n",
      "2022-04-13 15:23:03 [INFO]\t[TRAIN] Epoch=89/100, Step=74/87, loss_xy=198.827591, loss_wh=75.139450, loss_obj=177.672836, loss_cls=8.915182, loss=460.555084, lr=0.001000, time_each_step=1.59s, eta=0:25:58\n",
      "2022-04-13 15:23:18 [INFO]\t[TRAIN] Epoch=89/100, Step=84/87, loss_xy=356.388824, loss_wh=86.486351, loss_obj=327.923859, loss_cls=17.910318, loss=788.709412, lr=0.001000, time_each_step=1.57s, eta=0:25:30\n",
      "2022-04-13 15:23:22 [INFO]\t[TRAIN] Epoch 89 finished, loss_xy=256.9271, loss_wh=111.07765, loss_obj=239.2269, loss_cls=11.809406, loss=619.041 .\n",
      "2022-04-13 15:23:34 [INFO]\t[TRAIN] Epoch=90/100, Step=7/87, loss_xy=297.108704, loss_wh=84.213943, loss_obj=362.469971, loss_cls=14.048035, loss=757.840637, lr=0.001000, time_each_step=1.54s, eta=0:24:34\n",
      "2022-04-13 15:23:47 [INFO]\t[TRAIN] Epoch=90/100, Step=17/87, loss_xy=98.382034, loss_wh=22.166225, loss_obj=134.639099, loss_cls=4.403512, loss=259.590881, lr=0.001000, time_each_step=1.27s, eta=0:20:2\n",
      "2022-04-13 15:24:03 [INFO]\t[TRAIN] Epoch=90/100, Step=27/87, loss_xy=204.588394, loss_wh=81.336502, loss_obj=214.470886, loss_cls=10.081545, loss=510.477325, lr=0.001000, time_each_step=1.66s, eta=0:25:58\n",
      "2022-04-13 15:24:17 [INFO]\t[TRAIN] Epoch=90/100, Step=37/87, loss_xy=228.879242, loss_wh=85.958092, loss_obj=287.102783, loss_cls=10.164282, loss=612.104431, lr=0.001000, time_each_step=1.4s, eta=0:21:41\n",
      "2022-04-13 15:24:32 [INFO]\t[TRAIN] Epoch=90/100, Step=47/87, loss_xy=239.761078, loss_wh=145.576965, loss_obj=340.777740, loss_cls=11.558233, loss=737.674011, lr=0.001000, time_each_step=1.49s, eta=0:22:49\n",
      "2022-04-13 15:24:43 [INFO]\t[TRAIN] Epoch=90/100, Step=57/87, loss_xy=222.714905, loss_wh=135.823792, loss_obj=342.262329, loss_cls=10.309317, loss=711.110352, lr=0.001000, time_each_step=1.1s, eta=0:16:46\n",
      "2022-04-13 15:24:59 [INFO]\t[TRAIN] Epoch=90/100, Step=67/87, loss_xy=283.148315, loss_wh=103.094528, loss_obj=350.904663, loss_cls=12.665074, loss=749.812622, lr=0.001000, time_each_step=1.61s, eta=0:24:4\n",
      "2022-04-13 15:25:12 [INFO]\t[TRAIN] Epoch=90/100, Step=77/87, loss_xy=205.089081, loss_wh=55.086853, loss_obj=256.840149, loss_cls=10.199992, loss=527.216125, lr=0.001000, time_each_step=1.25s, eta=0:18:34\n",
      "2022-04-13 15:25:29 [INFO]\t[TRAIN] Epoch=90/100, Step=87/87, loss_xy=278.596924, loss_wh=140.514694, loss_obj=284.504364, loss_cls=13.002373, loss=716.618347, lr=0.001000, time_each_step=1.69s, eta=0:24:45\n",
      "2022-04-13 15:25:29 [INFO]\t[TRAIN] Epoch 90 finished, loss_xy=264.46024, loss_wh=116.642296, loss_obj=291.66385, loss_cls=12.243653, loss=685.01013 .\n",
      "2022-04-13 15:25:29 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:25:29 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:25:35 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:25:35 [INFO]\t[EVAL] Finished, Epoch=90, bbox_map=52.576322 .\n",
      "2022-04-13 15:25:35 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_80, bbox_map=57.39867716289374\n",
      "2022-04-13 15:25:37 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_90.\n",
      "2022-04-13 15:25:54 [INFO]\t[TRAIN] Epoch=91/100, Step=10/87, loss_xy=251.578461, loss_wh=68.774811, loss_obj=278.467285, loss_cls=12.228225, loss=611.048767, lr=0.001000, time_each_step=1.74s, eta=0:25:13\n",
      "2022-04-13 15:26:08 [INFO]\t[TRAIN] Epoch=91/100, Step=20/87, loss_xy=139.766922, loss_wh=69.499603, loss_obj=188.192963, loss_cls=6.949622, loss=404.409088, lr=0.001000, time_each_step=1.37s, eta=0:19:35\n",
      "2022-04-13 15:26:25 [INFO]\t[TRAIN] Epoch=91/100, Step=30/87, loss_xy=186.408081, loss_wh=74.142220, loss_obj=203.935333, loss_cls=8.465352, loss=472.950989, lr=0.001000, time_each_step=1.75s, eta=0:24:41\n",
      "2022-04-13 15:26:43 [INFO]\t[TRAIN] Epoch=91/100, Step=40/87, loss_xy=330.907410, loss_wh=183.965332, loss_obj=125.333092, loss_cls=13.872028, loss=654.077820, lr=0.001000, time_each_step=1.72s, eta=0:24:1\n",
      "2022-04-13 15:27:00 [INFO]\t[TRAIN] Epoch=91/100, Step=50/87, loss_xy=140.330063, loss_wh=103.750580, loss_obj=199.282959, loss_cls=6.104091, loss=449.467682, lr=0.001000, time_each_step=1.75s, eta=0:24:10\n",
      "2022-04-13 15:27:16 [INFO]\t[TRAIN] Epoch=91/100, Step=60/87, loss_xy=369.584595, loss_wh=141.655991, loss_obj=413.700714, loss_cls=17.733130, loss=942.674438, lr=0.001000, time_each_step=1.63s, eta=0:22:13\n",
      "2022-04-13 15:27:31 [INFO]\t[TRAIN] Epoch=91/100, Step=70/87, loss_xy=280.696686, loss_wh=115.897339, loss_obj=343.776672, loss_cls=13.777543, loss=754.148254, lr=0.001000, time_each_step=1.49s, eta=0:20:2\n",
      "2022-04-13 15:27:47 [INFO]\t[TRAIN] Epoch=91/100, Step=80/87, loss_xy=237.198883, loss_wh=76.668137, loss_obj=222.701019, loss_cls=10.655242, loss=547.223206, lr=0.001000, time_each_step=1.54s, eta=0:20:31\n",
      "2022-04-13 15:27:53 [INFO]\t[TRAIN] Epoch 91 finished, loss_xy=251.75128, loss_wh=106.67442, loss_obj=245.01495, loss_cls=11.4886465, loss=614.9292 .\n",
      "2022-04-13 15:27:57 [INFO]\t[TRAIN] Epoch=92/100, Step=3/87, loss_xy=502.610413, loss_wh=110.982651, loss_obj=465.078400, loss_cls=23.025723, loss=1101.697266, lr=0.001000, time_each_step=1.04s, eta=0:13:41\n",
      "2022-04-13 15:28:13 [INFO]\t[TRAIN] Epoch=92/100, Step=13/87, loss_xy=259.282013, loss_wh=133.428818, loss_obj=376.168427, loss_cls=12.140084, loss=781.019348, lr=0.001000, time_each_step=1.6s, eta=0:20:44\n",
      "2022-04-13 15:28:26 [INFO]\t[TRAIN] Epoch=92/100, Step=23/87, loss_xy=241.772842, loss_wh=121.432579, loss_obj=137.981018, loss_cls=10.848814, loss=512.035217, lr=0.001000, time_each_step=1.25s, eta=0:16:1\n",
      "2022-04-13 15:28:40 [INFO]\t[TRAIN] Epoch=92/100, Step=33/87, loss_xy=231.540527, loss_wh=112.887733, loss_obj=216.632767, loss_cls=10.110441, loss=571.171448, lr=0.001000, time_each_step=1.43s, eta=0:18:6\n",
      "2022-04-13 15:28:54 [INFO]\t[TRAIN] Epoch=92/100, Step=43/87, loss_xy=259.467529, loss_wh=111.636299, loss_obj=183.060242, loss_cls=12.332068, loss=566.496155, lr=0.001000, time_each_step=1.43s, eta=0:17:49\n",
      "2022-04-13 15:29:08 [INFO]\t[TRAIN] Epoch=92/100, Step=53/87, loss_xy=161.418732, loss_wh=34.653488, loss_obj=209.658112, loss_cls=7.638010, loss=413.368347, lr=0.001000, time_each_step=1.35s, eta=0:16:41\n",
      "2022-04-13 15:29:24 [INFO]\t[TRAIN] Epoch=92/100, Step=63/87, loss_xy=341.601379, loss_wh=104.950546, loss_obj=183.106262, loss_cls=14.522327, loss=644.180542, lr=0.001000, time_each_step=1.56s, eta=0:18:59\n",
      "2022-04-13 15:29:38 [INFO]\t[TRAIN] Epoch=92/100, Step=73/87, loss_xy=287.342316, loss_wh=279.844238, loss_obj=300.871765, loss_cls=13.741056, loss=881.799316, lr=0.001000, time_each_step=1.43s, eta=0:17:8\n",
      "2022-04-13 15:29:52 [INFO]\t[TRAIN] Epoch=92/100, Step=83/87, loss_xy=205.715775, loss_wh=165.483154, loss_obj=290.480103, loss_cls=9.697563, loss=671.376587, lr=0.001000, time_each_step=1.41s, eta=0:16:37\n",
      "2022-04-13 15:29:56 [INFO]\t[TRAIN] Epoch 92 finished, loss_xy=267.6688, loss_wh=146.30402, loss_obj=265.76315, loss_cls=12.319844, loss=692.05585 .\n",
      "2022-04-13 15:30:04 [INFO]\t[TRAIN] Epoch=93/100, Step=6/87, loss_xy=294.032593, loss_wh=223.947464, loss_obj=223.104065, loss_cls=13.285344, loss=754.369446, lr=0.001000, time_each_step=1.23s, eta=0:14:24\n",
      "2022-04-13 15:30:20 [INFO]\t[TRAIN] Epoch=93/100, Step=16/87, loss_xy=148.551163, loss_wh=67.607162, loss_obj=191.235153, loss_cls=7.087025, loss=414.480530, lr=0.001000, time_each_step=1.55s, eta=0:17:48\n",
      "2022-04-13 15:30:34 [INFO]\t[TRAIN] Epoch=93/100, Step=26/87, loss_xy=196.328751, loss_wh=69.420319, loss_obj=197.350739, loss_cls=9.933937, loss=473.033752, lr=0.001000, time_each_step=1.4s, eta=0:15:51\n",
      "2022-04-13 15:30:46 [INFO]\t[TRAIN] Epoch=93/100, Step=36/87, loss_xy=403.539307, loss_wh=193.005676, loss_obj=183.519287, loss_cls=17.056799, loss=797.121094, lr=0.001000, time_each_step=1.26s, eta=0:14:2\n",
      "2022-04-13 15:31:01 [INFO]\t[TRAIN] Epoch=93/100, Step=46/87, loss_xy=426.456787, loss_wh=119.111519, loss_obj=670.534119, loss_cls=19.393894, loss=1235.496338, lr=0.001000, time_each_step=1.41s, eta=0:15:28\n",
      "2022-04-13 15:31:13 [INFO]\t[TRAIN] Epoch=93/100, Step=56/87, loss_xy=269.640350, loss_wh=92.583397, loss_obj=218.567612, loss_cls=11.886616, loss=592.677979, lr=0.001000, time_each_step=1.23s, eta=0:13:23\n",
      "2022-04-13 15:31:29 [INFO]\t[TRAIN] Epoch=93/100, Step=66/87, loss_xy=259.934265, loss_wh=95.141357, loss_obj=281.446533, loss_cls=12.287276, loss=648.809448, lr=0.001000, time_each_step=1.62s, eta=0:17:12\n",
      "2022-04-13 15:31:40 [INFO]\t[TRAIN] Epoch=93/100, Step=76/87, loss_xy=327.851654, loss_wh=93.452850, loss_obj=348.761627, loss_cls=15.778661, loss=785.844849, lr=0.001000, time_each_step=1.11s, eta=0:11:40\n",
      "2022-04-13 15:31:55 [INFO]\t[TRAIN] Epoch=93/100, Step=86/87, loss_xy=257.080750, loss_wh=93.536652, loss_obj=217.108841, loss_cls=12.956439, loss=580.682678, lr=0.001000, time_each_step=1.46s, eta=0:15:5\n",
      "2022-04-13 15:31:57 [INFO]\t[TRAIN] Epoch 93 finished, loss_xy=258.15054, loss_wh=119.63775, loss_obj=263.16852, loss_cls=11.923307, loss=652.88007 .\n",
      "2022-04-13 15:32:11 [INFO]\t[TRAIN] Epoch=94/100, Step=9/87, loss_xy=254.301285, loss_wh=149.775665, loss_obj=225.423370, loss_cls=12.300494, loss=641.800842, lr=0.001000, time_each_step=1.64s, eta=0:16:37\n",
      "2022-04-13 15:32:26 [INFO]\t[TRAIN] Epoch=94/100, Step=19/87, loss_xy=291.366272, loss_wh=87.529434, loss_obj=227.382904, loss_cls=12.924212, loss=619.202759, lr=0.001000, time_each_step=1.51s, eta=0:15:3\n",
      "2022-04-13 15:32:39 [INFO]\t[TRAIN] Epoch=94/100, Step=29/87, loss_xy=290.189545, loss_wh=104.718826, loss_obj=267.105499, loss_cls=14.177755, loss=676.191650, lr=0.001000, time_each_step=1.27s, eta=0:12:32\n",
      "2022-04-13 15:32:53 [INFO]\t[TRAIN] Epoch=94/100, Step=39/87, loss_xy=206.354904, loss_wh=75.413483, loss_obj=166.933929, loss_cls=9.247885, loss=457.950195, lr=0.001000, time_each_step=1.4s, eta=0:13:28\n",
      "2022-04-13 15:33:09 [INFO]\t[TRAIN] Epoch=94/100, Step=49/87, loss_xy=296.400208, loss_wh=167.956558, loss_obj=247.609467, loss_cls=14.861201, loss=726.827393, lr=0.001000, time_each_step=1.55s, eta=0:14:40\n",
      "2022-04-13 15:33:23 [INFO]\t[TRAIN] Epoch=94/100, Step=59/87, loss_xy=208.721939, loss_wh=58.762486, loss_obj=287.527863, loss_cls=9.795503, loss=564.807861, lr=0.001000, time_each_step=1.47s, eta=0:13:41\n",
      "2022-04-13 15:33:37 [INFO]\t[TRAIN] Epoch=94/100, Step=69/87, loss_xy=148.344330, loss_wh=24.513611, loss_obj=202.046951, loss_cls=6.999332, loss=381.904236, lr=0.001000, time_each_step=1.39s, eta=0:12:45\n",
      "2022-04-13 15:33:50 [INFO]\t[TRAIN] Epoch=94/100, Step=79/87, loss_xy=331.684723, loss_wh=83.194046, loss_obj=212.245972, loss_cls=14.541319, loss=641.666077, lr=0.001000, time_each_step=1.32s, eta=0:11:52\n",
      "2022-04-13 15:34:03 [INFO]\t[TRAIN] Epoch 94 finished, loss_xy=266.26288, loss_wh=116.99419, loss_obj=248.12885, loss_cls=12.323419, loss=643.70935 .\n",
      "2022-04-13 15:34:06 [INFO]\t[TRAIN] Epoch=95/100, Step=2/87, loss_xy=370.116241, loss_wh=195.704117, loss_obj=473.733215, loss_cls=16.661232, loss=1056.214844, lr=0.001000, time_each_step=1.57s, eta=0:13:40\n",
      "2022-04-13 15:34:21 [INFO]\t[TRAIN] Epoch=95/100, Step=12/87, loss_xy=163.628036, loss_wh=80.195366, loss_obj=117.060272, loss_cls=7.550329, loss=368.433990, lr=0.001000, time_each_step=1.44s, eta=0:12:23\n",
      "2022-04-13 15:34:34 [INFO]\t[TRAIN] Epoch=95/100, Step=22/87, loss_xy=140.024445, loss_wh=58.683434, loss_obj=222.835419, loss_cls=6.783071, loss=428.326385, lr=0.001000, time_each_step=1.33s, eta=0:11:12\n",
      "2022-04-13 15:34:47 [INFO]\t[TRAIN] Epoch=95/100, Step=32/87, loss_xy=160.830566, loss_wh=39.980728, loss_obj=157.007904, loss_cls=7.738862, loss=365.558075, lr=0.001000, time_each_step=1.35s, eta=0:11:6\n",
      "2022-04-13 15:35:02 [INFO]\t[TRAIN] Epoch=95/100, Step=42/87, loss_xy=444.917084, loss_wh=309.451721, loss_obj=355.746704, loss_cls=19.656008, loss=1129.771484, lr=0.001000, time_each_step=1.5s, eta=0:12:5\n",
      "2022-04-13 15:35:17 [INFO]\t[TRAIN] Epoch=95/100, Step=52/87, loss_xy=218.253799, loss_wh=138.550476, loss_obj=175.927933, loss_cls=9.798489, loss=542.530640, lr=0.001000, time_each_step=1.47s, eta=0:11:39\n",
      "2022-04-13 15:35:32 [INFO]\t[TRAIN] Epoch=95/100, Step=62/87, loss_xy=176.830811, loss_wh=60.944366, loss_obj=175.212265, loss_cls=8.882315, loss=421.869751, lr=0.001000, time_each_step=1.47s, eta=0:11:20\n",
      "2022-04-13 15:35:43 [INFO]\t[TRAIN] Epoch=95/100, Step=72/87, loss_xy=274.778473, loss_wh=150.398438, loss_obj=237.330933, loss_cls=13.345974, loss=675.853760, lr=0.001000, time_each_step=1.11s, eta=0:8:27\n",
      "2022-04-13 15:35:55 [INFO]\t[TRAIN] Epoch=95/100, Step=82/87, loss_xy=190.984497, loss_wh=41.420238, loss_obj=174.203125, loss_cls=9.582310, loss=416.190155, lr=0.001000, time_each_step=1.16s, eta=0:8:38\n",
      "2022-04-13 15:36:01 [INFO]\t[TRAIN] Epoch 95 finished, loss_xy=255.34337, loss_wh=132.479, loss_obj=240.69579, loss_cls=11.926931, loss=640.44507 .\n",
      "2022-04-13 15:36:01 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:36:02 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:36:08 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:36:08 [INFO]\t[EVAL] Finished, Epoch=95, bbox_map=49.409050 .\n",
      "2022-04-13 15:36:08 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_80, bbox_map=57.39867716289374\n",
      "2022-04-13 15:36:09 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_95.\n",
      "2022-04-13 15:36:18 [INFO]\t[TRAIN] Epoch=96/100, Step=5/87, loss_xy=247.762634, loss_wh=85.251343, loss_obj=161.042618, loss_cls=11.392309, loss=505.448883, lr=0.001000, time_each_step=1.47s, eta=0:10:40\n",
      "2022-04-13 15:36:34 [INFO]\t[TRAIN] Epoch=96/100, Step=15/87, loss_xy=163.719864, loss_wh=57.531441, loss_obj=259.665161, loss_cls=7.894018, loss=488.810486, lr=0.001000, time_each_step=1.62s, eta=0:11:26\n",
      "2022-04-13 15:36:48 [INFO]\t[TRAIN] Epoch=96/100, Step=25/87, loss_xy=165.801361, loss_wh=85.103630, loss_obj=143.371902, loss_cls=7.703152, loss=401.980072, lr=0.001000, time_each_step=1.45s, eta=0:10:1\n",
      "2022-04-13 15:37:01 [INFO]\t[TRAIN] Epoch=96/100, Step=35/87, loss_xy=194.091980, loss_wh=55.054039, loss_obj=195.863678, loss_cls=9.309408, loss=454.319122, lr=0.001000, time_each_step=1.26s, eta=0:8:32\n",
      "2022-04-13 15:37:15 [INFO]\t[TRAIN] Epoch=96/100, Step=45/87, loss_xy=195.442139, loss_wh=107.332489, loss_obj=49.811764, loss_cls=8.190777, loss=360.777161, lr=0.001000, time_each_step=1.45s, eta=0:9:31\n",
      "2022-04-13 15:37:30 [INFO]\t[TRAIN] Epoch=96/100, Step=55/87, loss_xy=266.642090, loss_wh=106.229256, loss_obj=268.749908, loss_cls=12.111616, loss=653.732849, lr=0.001000, time_each_step=1.5s, eta=0:9:35\n",
      "2022-04-13 15:37:46 [INFO]\t[TRAIN] Epoch=96/100, Step=65/87, loss_xy=318.879700, loss_wh=100.773941, loss_obj=297.344757, loss_cls=14.619372, loss=731.617798, lr=0.001000, time_each_step=1.56s, eta=0:9:44\n",
      "2022-04-13 15:37:58 [INFO]\t[TRAIN] Epoch=96/100, Step=75/87, loss_xy=268.506348, loss_wh=82.920700, loss_obj=111.308762, loss_cls=11.336143, loss=474.071991, lr=0.001000, time_each_step=1.25s, eta=0:7:35\n",
      "2022-04-13 15:38:12 [INFO]\t[TRAIN] Epoch=96/100, Step=85/87, loss_xy=272.530334, loss_wh=97.976837, loss_obj=204.237869, loss_cls=12.098825, loss=586.843872, lr=0.001000, time_each_step=1.31s, eta=0:7:44\n",
      "2022-04-13 15:38:13 [INFO]\t[TRAIN] Epoch 96 finished, loss_xy=254.78831, loss_wh=112.97544, loss_obj=247.78815, loss_cls=11.865448, loss=627.41736 .\n",
      "2022-04-13 15:38:24 [INFO]\t[TRAIN] Epoch=97/100, Step=8/87, loss_xy=399.377563, loss_wh=102.412346, loss_obj=380.989685, loss_cls=18.892851, loss=901.672424, lr=0.001000, time_each_step=1.18s, eta=0:6:48\n",
      "2022-04-13 15:38:38 [INFO]\t[TRAIN] Epoch=97/100, Step=18/87, loss_xy=291.664978, loss_wh=126.445091, loss_obj=224.535965, loss_cls=13.053362, loss=655.699402, lr=0.001000, time_each_step=1.47s, eta=0:8:11\n",
      "2022-04-13 15:38:51 [INFO]\t[TRAIN] Epoch=97/100, Step=28/87, loss_xy=152.990829, loss_wh=55.917416, loss_obj=209.739059, loss_cls=7.631208, loss=426.278503, lr=0.001000, time_each_step=1.32s, eta=0:7:10\n",
      "2022-04-13 15:39:05 [INFO]\t[TRAIN] Epoch=97/100, Step=38/87, loss_xy=212.935074, loss_wh=87.387863, loss_obj=275.397583, loss_cls=10.642064, loss=586.362610, lr=0.001000, time_each_step=1.38s, eta=0:7:14\n",
      "2022-04-13 15:39:19 [INFO]\t[TRAIN] Epoch=97/100, Step=48/87, loss_xy=291.941406, loss_wh=158.511154, loss_obj=281.274719, loss_cls=13.172250, loss=744.899536, lr=0.001000, time_each_step=1.36s, eta=0:6:54\n",
      "2022-04-13 15:39:31 [INFO]\t[TRAIN] Epoch=97/100, Step=58/87, loss_xy=166.288422, loss_wh=65.210403, loss_obj=169.862366, loss_cls=7.703641, loss=409.064850, lr=0.001000, time_each_step=1.21s, eta=0:5:57\n",
      "2022-04-13 15:39:49 [INFO]\t[TRAIN] Epoch=97/100, Step=68/87, loss_xy=246.780457, loss_wh=125.717613, loss_obj=137.588684, loss_cls=10.584349, loss=520.671082, lr=0.001000, time_each_step=1.79s, eta=0:8:28\n",
      "2022-04-13 15:40:05 [INFO]\t[TRAIN] Epoch=97/100, Step=78/87, loss_xy=234.610291, loss_wh=50.456692, loss_obj=284.581238, loss_cls=11.321271, loss=580.969482, lr=0.001000, time_each_step=1.65s, eta=0:7:32\n",
      "2022-04-13 15:40:17 [INFO]\t[TRAIN] Epoch 97 finished, loss_xy=264.2078, loss_wh=124.684456, loss_obj=267.57098, loss_cls=12.2202425, loss=668.6834 .\n",
      "2022-04-13 15:40:20 [INFO]\t[TRAIN] Epoch=98/100, Step=1/87, loss_xy=188.614838, loss_wh=179.861206, loss_obj=156.571503, loss_cls=8.874306, loss=533.921875, lr=0.001000, time_each_step=1.39s, eta=0:6:8\n",
      "2022-04-13 15:40:33 [INFO]\t[TRAIN] Epoch=98/100, Step=11/87, loss_xy=312.460632, loss_wh=171.725601, loss_obj=318.781372, loss_cls=15.425426, loss=818.393005, lr=0.001000, time_each_step=1.35s, eta=0:5:45\n",
      "2022-04-13 15:40:46 [INFO]\t[TRAIN] Epoch=98/100, Step=21/87, loss_xy=216.916580, loss_wh=80.012268, loss_obj=210.356354, loss_cls=9.710292, loss=516.995483, lr=0.001000, time_each_step=1.27s, eta=0:5:10\n",
      "2022-04-13 15:41:00 [INFO]\t[TRAIN] Epoch=98/100, Step=31/87, loss_xy=417.492798, loss_wh=228.210220, loss_obj=418.500732, loss_cls=19.076626, loss=1083.280396, lr=0.001000, time_each_step=1.42s, eta=0:5:33\n",
      "2022-04-13 15:41:15 [INFO]\t[TRAIN] Epoch=98/100, Step=41/87, loss_xy=194.818359, loss_wh=157.045563, loss_obj=87.882088, loss_cls=8.515255, loss=448.261261, lr=0.001000, time_each_step=1.47s, eta=0:5:29\n",
      "2022-04-13 15:41:30 [INFO]\t[TRAIN] Epoch=98/100, Step=51/87, loss_xy=229.537628, loss_wh=184.732315, loss_obj=292.026184, loss_cls=11.264965, loss=717.561096, lr=0.001000, time_each_step=1.49s, eta=0:5:18\n",
      "2022-04-13 15:41:44 [INFO]\t[TRAIN] Epoch=98/100, Step=61/87, loss_xy=268.650269, loss_wh=230.625549, loss_obj=412.968109, loss_cls=12.994741, loss=925.238647, lr=0.001000, time_each_step=1.44s, eta=0:4:54\n",
      "2022-04-13 15:41:56 [INFO]\t[TRAIN] Epoch=98/100, Step=71/87, loss_xy=281.233215, loss_wh=102.900711, loss_obj=344.072601, loss_cls=13.429687, loss=741.636230, lr=0.001000, time_each_step=1.18s, eta=0:3:50\n",
      "2022-04-13 15:42:11 [INFO]\t[TRAIN] Epoch=98/100, Step=81/87, loss_xy=161.134445, loss_wh=198.355301, loss_obj=67.316109, loss_cls=6.811570, loss=433.617432, lr=0.001000, time_each_step=1.56s, eta=0:4:47\n",
      "2022-04-13 15:42:20 [INFO]\t[TRAIN] Epoch 98 finished, loss_xy=265.91574, loss_wh=138.23634, loss_obj=281.04483, loss_cls=12.365153, loss=697.5621 .\n",
      "2022-04-13 15:42:27 [INFO]\t[TRAIN] Epoch=99/100, Step=4/87, loss_xy=316.225342, loss_wh=240.221237, loss_obj=372.740784, loss_cls=15.637272, loss=944.824646, lr=0.001000, time_each_step=1.52s, eta=0:4:24\n",
      "2022-04-13 15:42:42 [INFO]\t[TRAIN] Epoch=99/100, Step=14/87, loss_xy=231.169449, loss_wh=106.360542, loss_obj=156.960388, loss_cls=11.234132, loss=505.724518, lr=0.001000, time_each_step=1.51s, eta=0:4:8\n",
      "2022-04-13 15:42:57 [INFO]\t[TRAIN] Epoch=99/100, Step=24/87, loss_xy=411.353607, loss_wh=194.995667, loss_obj=198.958832, loss_cls=17.372593, loss=822.680725, lr=0.001000, time_each_step=1.55s, eta=0:3:58\n",
      "2022-04-13 15:43:12 [INFO]\t[TRAIN] Epoch=99/100, Step=34/87, loss_xy=264.592285, loss_wh=89.055336, loss_obj=72.721786, loss_cls=11.308617, loss=437.678009, lr=0.001000, time_each_step=1.45s, eta=0:3:29\n",
      "2022-04-13 15:43:25 [INFO]\t[TRAIN] Epoch=99/100, Step=44/87, loss_xy=195.334473, loss_wh=185.073013, loss_obj=118.396820, loss_cls=8.873023, loss=507.677307, lr=0.001000, time_each_step=1.32s, eta=0:2:58\n",
      "2022-04-13 15:43:39 [INFO]\t[TRAIN] Epoch=99/100, Step=54/87, loss_xy=201.707565, loss_wh=55.568413, loss_obj=178.859070, loss_cls=10.210917, loss=446.345947, lr=0.001000, time_each_step=1.38s, eta=0:2:52\n",
      "2022-04-13 15:43:54 [INFO]\t[TRAIN] Epoch=99/100, Step=64/87, loss_xy=283.518799, loss_wh=125.480484, loss_obj=358.754272, loss_cls=13.358941, loss=781.112488, lr=0.001000, time_each_step=1.56s, eta=0:2:58\n",
      "2022-04-13 15:44:11 [INFO]\t[TRAIN] Epoch=99/100, Step=74/87, loss_xy=229.056763, loss_wh=70.398438, loss_obj=197.886368, loss_cls=11.419464, loss=508.761017, lr=0.001000, time_each_step=1.71s, eta=0:2:57\n",
      "2022-04-13 15:44:25 [INFO]\t[TRAIN] Epoch=99/100, Step=84/87, loss_xy=163.963165, loss_wh=46.167084, loss_obj=169.758224, loss_cls=7.577473, loss=387.465973, lr=0.001000, time_each_step=1.35s, eta=0:2:8\n",
      "2022-04-13 15:44:29 [INFO]\t[TRAIN] Epoch 99 finished, loss_xy=248.53526, loss_wh=115.657104, loss_obj=233.25287, loss_cls=11.581699, loss=609.0269 .\n",
      "2022-04-13 15:44:40 [INFO]\t[TRAIN] Epoch=100/100, Step=7/87, loss_xy=270.081299, loss_wh=162.243362, loss_obj=172.647049, loss_cls=11.758592, loss=616.730286, lr=0.001000, time_each_step=1.45s, eta=0:1:56\n",
      "2022-04-13 15:44:54 [INFO]\t[TRAIN] Epoch=100/100, Step=17/87, loss_xy=170.952026, loss_wh=35.532494, loss_obj=286.436096, loss_cls=8.315020, loss=501.235657, lr=0.001000, time_each_step=1.4s, eta=0:1:37\n",
      "2022-04-13 15:45:11 [INFO]\t[TRAIN] Epoch=100/100, Step=27/87, loss_xy=176.185455, loss_wh=100.317459, loss_obj=195.575134, loss_cls=8.138029, loss=480.216095, lr=0.001000, time_each_step=1.78s, eta=0:1:47\n",
      "2022-04-13 15:45:24 [INFO]\t[TRAIN] Epoch=100/100, Step=37/87, loss_xy=259.539032, loss_wh=135.599930, loss_obj=247.896179, loss_cls=11.785345, loss=654.820496, lr=0.001000, time_each_step=1.25s, eta=0:1:2\n",
      "2022-04-13 15:45:36 [INFO]\t[TRAIN] Epoch=100/100, Step=47/87, loss_xy=406.197205, loss_wh=134.122437, loss_obj=305.059296, loss_cls=18.668215, loss=864.047119, lr=0.001000, time_each_step=1.26s, eta=0:0:50\n",
      "2022-04-13 15:45:50 [INFO]\t[TRAIN] Epoch=100/100, Step=57/87, loss_xy=204.014984, loss_wh=48.873695, loss_obj=217.957916, loss_cls=10.256865, loss=481.103455, lr=0.001000, time_each_step=1.31s, eta=0:0:39\n",
      "2022-04-13 15:46:03 [INFO]\t[TRAIN] Epoch=100/100, Step=67/87, loss_xy=164.857986, loss_wh=65.622307, loss_obj=172.974976, loss_cls=7.362481, loss=410.817749, lr=0.001000, time_each_step=1.35s, eta=0:0:27\n",
      "2022-04-13 15:46:19 [INFO]\t[TRAIN] Epoch=100/100, Step=77/87, loss_xy=157.224686, loss_wh=65.167503, loss_obj=133.641342, loss_cls=7.155544, loss=363.189056, lr=0.001000, time_each_step=1.55s, eta=0:0:15\n",
      "2022-04-13 15:46:36 [INFO]\t[TRAIN] Epoch=100/100, Step=87/87, loss_xy=274.090576, loss_wh=128.339554, loss_obj=274.393250, loss_cls=13.393556, loss=690.216919, lr=0.001000, time_each_step=1.71s, eta=0:0:0\n",
      "2022-04-13 15:46:36 [INFO]\t[TRAIN] Epoch 100 finished, loss_xy=256.96732, loss_wh=108.55846, loss_obj=245.69807, loss_cls=11.965708, loss=623.1896 .\n",
      "2022-04-13 15:46:36 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:46:36 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:46:42 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:46:42 [INFO]\t[EVAL] Finished, Epoch=100, bbox_map=62.399649 .\n",
      "2022-04-13 15:46:46 [INFO]\tModel saved in output/yolov3_DarkNet53/best_model.\n",
      "2022-04-13 15:46:46 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_100, bbox_map=62.399649300254566\n",
      "2022-04-13 15:46:48 [INFO]\tModel saved in output/yolov3_DarkNet53/epoch_100.\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.labels)\n",
    "model = pdx.det.YOLOv3(num_classes=num_classes, backbone='DarkNet53', label_smooth=True, ignore_threshold=0.7)\n",
    "model.train(\n",
    "    num_epochs=100,                     \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=eval_dataset,           \n",
    "    train_batch_size=2,                  \n",
    "    pretrain_weights='COCO',             \n",
    "    learning_rate=0.001,              \n",
    "    warmup_steps=1000,                   \n",
    "    warmup_start_lr=0.0,                 \n",
    "    save_interval_epochs=5,              \n",
    "    lr_decay_epochs=[210, 240],          \n",
    "    save_dir='output/yolov3_DarkNet53', \n",
    "    use_vdl=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T07:46:48.380949Z",
     "iopub.status.busy": "2022-04-13T07:46:48.380669Z",
     "iopub.status.idle": "2022-04-13T08:29:18.003130Z",
     "shell.execute_reply": "2022-04-13T08:29:18.002175Z",
     "shell.execute_reply.started": "2022-04-13T07:46:48.380919Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 15:46:48 [INFO]\tDownloading DarkNet53_pretrained.pdparams from https://paddledet.bj.bcebos.com/models/pretrained/DarkNet53_pretrained.pdparams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158704/158704 [01:08<00:00, 2305.37KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 15:47:57 [INFO]\tLoading pretrained model from output/YOLO3_DARKNET53/pretrain/DarkNet53_pretrained.pdparams\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv0.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv0.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv0.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv0.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv0.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv1.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv1.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv1.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv1.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv1.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv2.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv2.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv2.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv2.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv2.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv3.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv3.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv3.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv3.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.conv3.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.route.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.route.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.route.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.route.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.conv_module.route.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.tip.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.tip.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.tip.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.tip.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.0.tip.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.0.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.0.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.0.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.0.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.0.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv0.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv0.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv0.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv0.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv0.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv1.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv1.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv1.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv1.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv1.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv2.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv2.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv2.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv2.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv2.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv3.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv3.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv3.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv3.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.conv3.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.route.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.route.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.route.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.route.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.conv_module.route.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.tip.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.tip.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.tip.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.tip.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.1.tip.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.1.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.1.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.1.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.1.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_transition.1.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv0.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv0.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv0.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv0.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv0.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv1.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv1.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv1.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv1.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv1.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv2.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv2.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv2.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv2.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv2.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv3.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv3.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv3.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv3.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.conv3.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.route.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.route.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.route.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.route.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.conv_module.route.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.tip.conv.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.tip.batch_norm.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.tip.batch_norm.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.tip.batch_norm._mean is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tneck.yolo_block.2.tip.batch_norm._variance is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tyolo_head.yolo_output.0.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tyolo_head.yolo_output.0.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tyolo_head.yolo_output.1.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tyolo_head.yolo_output.1.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tyolo_head.yolo_output.2.weight is not in pretrained model\n",
      "2022-04-13 15:47:58 [WARNING]\tyolo_head.yolo_output.2.bias is not in pretrained model\n",
      "2022-04-13 15:47:58 [INFO]\tThere are 260/366 variables loaded into YOLOv3.\n",
      "2022-04-13 15:48:54 [INFO]\t[TRAIN] Epoch=1/18, Step=10/21, loss_xy=286.782654, loss_wh=102.654083, loss_obj=825.649109, loss_cls=49.764324, loss=1264.850098, lr=0.000125, time_each_step=5.62s, eta=0:35:8\n",
      "2022-04-13 15:49:50 [INFO]\t[TRAIN] Epoch=1/18, Step=20/21, loss_xy=281.432251, loss_wh=118.428925, loss_obj=939.640686, loss_cls=29.138273, loss=1368.640137, lr=0.000125, time_each_step=5.51s, eta=0:33:30\n",
      "2022-04-13 15:50:00 [INFO]\t[TRAIN] Epoch 1 finished, loss_xy=295.78015, loss_wh=133.11575, loss_obj=1494.0457, loss_cls=51.883266, loss=1974.825 .\n",
      "2022-04-13 15:50:00 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:50:00 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:50:04 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:50:04 [INFO]\t[EVAL] Finished, Epoch=1, bbox_map=0.000000 .\n",
      "2022-04-13 15:50:06 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 15:50:06 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_1, bbox_map=0.0\n",
      "2022-04-13 15:50:07 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_1.\n",
      "2022-04-13 15:50:58 [INFO]\t[TRAIN] Epoch=2/18, Step=9/21, loss_xy=268.323853, loss_wh=54.617378, loss_obj=547.707092, loss_cls=23.311035, loss=893.959351, lr=0.000125, time_each_step=6.11s, eta=0:37:7\n",
      "2022-04-13 15:52:03 [INFO]\t[TRAIN] Epoch=2/18, Step=19/21, loss_xy=323.398193, loss_wh=128.916504, loss_obj=628.669861, loss_cls=18.041080, loss=1099.025757, lr=0.000125, time_each_step=6.41s, eta=0:37:45\n",
      "2022-04-13 15:52:16 [INFO]\t[TRAIN] Epoch 2 finished, loss_xy=288.37408, loss_wh=92.51566, loss_obj=581.3557, loss_cls=22.556782, loss=984.8022 .\n",
      "2022-04-13 15:52:16 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:52:16 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:52:22 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:52:22 [INFO]\t[EVAL] Finished, Epoch=2, bbox_map=0.191388 .\n",
      "2022-04-13 15:52:27 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 15:52:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_2, bbox_map=0.19138755980861244\n",
      "2022-04-13 15:52:28 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_2.\n",
      "2022-04-13 15:53:19 [INFO]\t[TRAIN] Epoch=3/18, Step=8/21, loss_xy=295.721802, loss_wh=96.329300, loss_obj=441.761169, loss_cls=10.263092, loss=844.075317, lr=0.000125, time_each_step=6.42s, eta=0:37:47\n",
      "2022-04-13 15:54:16 [INFO]\t[TRAIN] Epoch=3/18, Step=18/21, loss_xy=327.361969, loss_wh=98.821136, loss_obj=534.241089, loss_cls=10.366937, loss=970.791138, lr=0.000125, time_each_step=5.7s, eta=0:32:56\n",
      "2022-04-13 15:54:30 [INFO]\t[TRAIN] Epoch 3 finished, loss_xy=290.35736, loss_wh=91.18142, loss_obj=482.32947, loss_cls=11.193772, loss=875.06195 .\n",
      "2022-04-13 15:54:30 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:54:30 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:54:37 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:54:37 [INFO]\t[EVAL] Finished, Epoch=3, bbox_map=1.726682 .\n",
      "2022-04-13 15:54:41 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 15:54:41 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_3, bbox_map=1.72668240850059\n",
      "2022-04-13 15:54:43 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_3.\n",
      "2022-04-13 15:55:32 [INFO]\t[TRAIN] Epoch=4/18, Step=7/21, loss_xy=274.892181, loss_wh=85.052948, loss_obj=368.985657, loss_cls=5.304661, loss=734.235474, lr=0.000125, time_each_step=6.3s, eta=0:35:0\n",
      "2022-04-13 15:56:30 [INFO]\t[TRAIN] Epoch=4/18, Step=17/21, loss_xy=319.500366, loss_wh=112.643303, loss_obj=443.125153, loss_cls=5.890817, loss=881.159607, lr=0.000125, time_each_step=5.72s, eta=0:31:4\n",
      "2022-04-13 15:56:51 [INFO]\t[TRAIN] Epoch 4 finished, loss_xy=290.02405, loss_wh=89.38932, loss_obj=442.4081, loss_cls=7.933617, loss=829.755 .\n",
      "2022-04-13 15:56:51 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:56:51 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:56:57 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:56:58 [INFO]\t[EVAL] Finished, Epoch=4, bbox_map=10.918863 .\n",
      "2022-04-13 15:57:02 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 15:57:02 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_4, bbox_map=10.918862989681832\n",
      "2022-04-13 15:57:04 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_4.\n",
      "2022-04-13 15:57:38 [INFO]\t[TRAIN] Epoch=5/18, Step=6/21, loss_xy=285.459656, loss_wh=76.036331, loss_obj=401.334564, loss_cls=7.496105, loss=770.326660, lr=0.000125, time_each_step=5.63s, eta=0:29:26\n",
      "2022-04-13 15:58:35 [INFO]\t[TRAIN] Epoch=5/18, Step=16/21, loss_xy=320.731049, loss_wh=79.354134, loss_obj=478.823395, loss_cls=7.132057, loss=886.040649, lr=0.000125, time_each_step=5.61s, eta=0:28:23\n",
      "2022-04-13 15:59:09 [INFO]\t[TRAIN] Epoch 5 finished, loss_xy=299.07797, loss_wh=79.44264, loss_obj=465.75436, loss_cls=7.412886, loss=851.68787 .\n",
      "2022-04-13 15:59:09 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 15:59:09 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 15:59:15 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 15:59:15 [INFO]\t[EVAL] Finished, Epoch=5, bbox_map=18.430960 .\n",
      "2022-04-13 15:59:20 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 15:59:20 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=18.430960159838676\n",
      "2022-04-13 15:59:22 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_5.\n",
      "2022-04-13 16:00:00 [INFO]\t[TRAIN] Epoch=6/18, Step=5/21, loss_xy=236.446640, loss_wh=80.779564, loss_obj=320.540955, loss_cls=4.804382, loss=642.571533, lr=0.000125, time_each_step=7.26s, eta=0:34:40\n",
      "2022-04-13 16:00:58 [INFO]\t[TRAIN] Epoch=6/18, Step=15/21, loss_xy=288.002014, loss_wh=82.714676, loss_obj=442.827332, loss_cls=3.188008, loss=816.731995, lr=0.000125, time_each_step=5.78s, eta=0:27:6\n",
      "2022-04-13 16:01:35 [INFO]\t[TRAIN] Epoch 6 finished, loss_xy=294.5994, loss_wh=87.233505, loss_obj=438.50586, loss_cls=4.67866, loss=825.01746 .\n",
      "2022-04-13 16:01:35 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:01:35 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:01:41 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:01:41 [INFO]\t[EVAL] Finished, Epoch=6, bbox_map=16.919384 .\n",
      "2022-04-13 16:01:41 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=18.430960159838676\n",
      "2022-04-13 16:01:43 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_6.\n",
      "2022-04-13 16:02:07 [INFO]\t[TRAIN] Epoch=7/18, Step=4/21, loss_xy=217.478500, loss_wh=64.207428, loss_obj=291.452820, loss_cls=3.413910, loss=576.552673, lr=0.000125, time_each_step=6.15s, eta=0:26:36\n",
      "2022-04-13 16:03:08 [INFO]\t[TRAIN] Epoch=7/18, Step=14/21, loss_xy=238.885422, loss_wh=74.451134, loss_obj=355.410919, loss_cls=3.765596, loss=672.513062, lr=0.000125, time_each_step=6.07s, eta=0:25:15\n",
      "2022-04-13 16:03:52 [INFO]\t[TRAIN] Epoch 7 finished, loss_xy=293.47406, loss_wh=81.27837, loss_obj=432.06863, loss_cls=4.848287, loss=811.66943 .\n",
      "2022-04-13 16:03:52 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:03:53 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:03:59 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:03:59 [INFO]\t[EVAL] Finished, Epoch=7, bbox_map=25.753737 .\n",
      "2022-04-13 16:04:04 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 16:04:04 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_7, bbox_map=25.75373709404199\n",
      "2022-04-13 16:04:05 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_7.\n",
      "2022-04-13 16:04:31 [INFO]\t[TRAIN] Epoch=8/18, Step=3/21, loss_xy=198.912994, loss_wh=47.568279, loss_obj=334.952362, loss_cls=4.135231, loss=585.568909, lr=0.000125, time_each_step=7.0s, eta=0:28:32\n",
      "2022-04-13 16:05:27 [INFO]\t[TRAIN] Epoch=8/18, Step=13/21, loss_xy=313.901367, loss_wh=71.939224, loss_obj=389.295380, loss_cls=2.871719, loss=778.007690, lr=0.000125, time_each_step=5.55s, eta=0:22:6\n",
      "2022-04-13 16:06:11 [INFO]\t[TRAIN] Epoch 8 finished, loss_xy=290.9957, loss_wh=78.206215, loss_obj=411.3653, loss_cls=4.004299, loss=784.57153 .\n",
      "2022-04-13 16:06:11 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:06:11 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:06:17 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:06:17 [INFO]\t[EVAL] Finished, Epoch=8, bbox_map=29.252670 .\n",
      "2022-04-13 16:06:23 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 16:06:23 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, bbox_map=29.25267049401381\n",
      "2022-04-13 16:06:24 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_8.\n",
      "2022-04-13 16:06:36 [INFO]\t[TRAIN] Epoch=9/18, Step=2/21, loss_xy=354.579071, loss_wh=86.870995, loss_obj=420.518555, loss_cls=2.691734, loss=864.660339, lr=0.000125, time_each_step=5.56s, eta=0:21:1\n",
      "2022-04-13 16:07:38 [INFO]\t[TRAIN] Epoch=9/18, Step=12/21, loss_xy=287.706818, loss_wh=105.376854, loss_obj=286.569702, loss_cls=2.507229, loss=682.160583, lr=0.000125, time_each_step=6.2s, eta=0:22:12\n",
      "2022-04-13 16:08:31 [INFO]\t[TRAIN] Epoch 9 finished, loss_xy=288.97504, loss_wh=81.49411, loss_obj=394.5498, loss_cls=3.2438834, loss=768.2628 .\n",
      "2022-04-13 16:08:31 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:08:32 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:08:37 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:08:38 [INFO]\t[EVAL] Finished, Epoch=9, bbox_map=21.856529 .\n",
      "2022-04-13 16:08:38 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, bbox_map=29.25267049401381\n",
      "2022-04-13 16:08:39 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_9.\n",
      "2022-04-13 16:08:50 [INFO]\t[TRAIN] Epoch=10/18, Step=1/21, loss_xy=279.067169, loss_wh=78.674248, loss_obj=375.122009, loss_cls=5.112051, loss=737.975464, lr=0.000125, time_each_step=6.42s, eta=0:20:59\n",
      "2022-04-13 16:09:47 [INFO]\t[TRAIN] Epoch=10/18, Step=11/21, loss_xy=275.920532, loss_wh=70.042137, loss_obj=419.936310, loss_cls=3.867552, loss=769.766541, lr=0.000125, time_each_step=5.73s, eta=0:17:52\n",
      "2022-04-13 16:10:48 [INFO]\t[TRAIN] Epoch=10/18, Step=21/21, loss_xy=258.839783, loss_wh=64.313118, loss_obj=288.318146, loss_cls=2.806106, loss=614.277161, lr=0.000125, time_each_step=6.07s, eta=0:17:52\n",
      "2022-04-13 16:10:48 [INFO]\t[TRAIN] Epoch 10 finished, loss_xy=289.73346, loss_wh=85.92036, loss_obj=373.60443, loss_cls=3.343411, loss=752.6017 .\n",
      "2022-04-13 16:10:48 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:10:49 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:10:55 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:10:55 [INFO]\t[EVAL] Finished, Epoch=10, bbox_map=26.722454 .\n",
      "2022-04-13 16:10:55 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, bbox_map=29.25267049401381\n",
      "2022-04-13 16:10:56 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_10.\n",
      "2022-04-13 16:11:57 [INFO]\t[TRAIN] Epoch=11/18, Step=10/21, loss_xy=230.216263, loss_wh=67.130165, loss_obj=290.711700, loss_cls=2.083281, loss=590.141357, lr=0.000125, time_each_step=6.05s, eta=0:16:40\n",
      "2022-04-13 16:12:48 [INFO]\t[TRAIN] Epoch=11/18, Step=20/21, loss_xy=338.927429, loss_wh=82.258118, loss_obj=365.187653, loss_cls=3.024543, loss=789.397705, lr=0.000125, time_each_step=5.18s, eta=0:13:30\n",
      "2022-04-13 16:12:56 [INFO]\t[TRAIN] Epoch 11 finished, loss_xy=276.52866, loss_wh=74.1068, loss_obj=373.90082, loss_cls=3.1657264, loss=727.70197 .\n",
      "2022-04-13 16:12:56 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:12:57 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:13:03 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:13:04 [INFO]\t[EVAL] Finished, Epoch=11, bbox_map=22.145074 .\n",
      "2022-04-13 16:13:04 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, bbox_map=29.25267049401381\n",
      "2022-04-13 16:13:05 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_11.\n",
      "2022-04-13 16:14:08 [INFO]\t[TRAIN] Epoch=12/18, Step=9/21, loss_xy=218.469421, loss_wh=61.662270, loss_obj=340.092621, loss_cls=2.694515, loss=622.918823, lr=0.000125, time_each_step=7.1s, eta=0:17:3\n",
      "2022-04-13 16:14:59 [INFO]\t[TRAIN] Epoch=12/18, Step=19/21, loss_xy=276.205627, loss_wh=64.010979, loss_obj=393.987946, loss_cls=3.588485, loss=737.793091, lr=0.000125, time_each_step=5.07s, eta=0:11:31\n",
      "2022-04-13 16:15:10 [INFO]\t[TRAIN] Epoch 12 finished, loss_xy=281.22565, loss_wh=82.377235, loss_obj=353.6878, loss_cls=2.814525, loss=720.1051 .\n",
      "2022-04-13 16:15:10 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:15:10 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:15:16 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:15:16 [INFO]\t[EVAL] Finished, Epoch=12, bbox_map=34.160070 .\n",
      "2022-04-13 16:15:22 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 16:15:22 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_12, bbox_map=34.160069589661994\n",
      "2022-04-13 16:15:23 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_12.\n",
      "2022-04-13 16:16:09 [INFO]\t[TRAIN] Epoch=13/18, Step=8/21, loss_xy=350.202728, loss_wh=81.347168, loss_obj=471.260345, loss_cls=3.318004, loss=906.128235, lr=0.000125, time_each_step=5.62s, eta=0:12:4\n",
      "2022-04-13 16:17:08 [INFO]\t[TRAIN] Epoch=13/18, Step=18/21, loss_xy=294.443268, loss_wh=84.165054, loss_obj=388.308807, loss_cls=2.461275, loss=769.378418, lr=0.000125, time_each_step=5.89s, eta=0:11:37\n",
      "2022-04-13 16:17:31 [INFO]\t[TRAIN] Epoch 13 finished, loss_xy=306.4561, loss_wh=78.4024, loss_obj=359.67645, loss_cls=2.502897, loss=747.0378 .\n",
      "2022-04-13 16:17:31 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:17:31 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:17:37 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:17:38 [INFO]\t[EVAL] Finished, Epoch=13, bbox_map=46.539389 .\n",
      "2022-04-13 16:17:42 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 16:17:42 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_13, bbox_map=46.53938924762711\n",
      "2022-04-13 16:17:44 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_13.\n",
      "2022-04-13 16:18:32 [INFO]\t[TRAIN] Epoch=14/18, Step=7/21, loss_xy=243.907150, loss_wh=72.342964, loss_obj=256.262238, loss_cls=1.600430, loss=574.112732, lr=0.000125, time_each_step=7.07s, eta=0:12:18\n",
      "2022-04-13 16:19:26 [INFO]\t[TRAIN] Epoch=14/18, Step=17/21, loss_xy=285.500885, loss_wh=63.642334, loss_obj=335.400024, loss_cls=2.325969, loss=686.869202, lr=0.000125, time_each_step=5.46s, eta=0:8:45\n",
      "2022-04-13 16:19:52 [INFO]\t[TRAIN] Epoch 14 finished, loss_xy=286.2479, loss_wh=77.9483, loss_obj=317.48764, loss_cls=2.5916047, loss=684.27545 .\n",
      "2022-04-13 16:19:52 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:19:53 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:19:59 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:19:59 [INFO]\t[EVAL] Finished, Epoch=14, bbox_map=51.482380 .\n",
      "2022-04-13 16:20:04 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 16:20:04 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_14, bbox_map=51.482380458606706\n",
      "2022-04-13 16:20:06 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_14.\n",
      "2022-04-13 16:20:40 [INFO]\t[TRAIN] Epoch=15/18, Step=6/21, loss_xy=234.154678, loss_wh=80.783363, loss_obj=210.872101, loss_cls=1.294065, loss=527.104248, lr=0.000125, time_each_step=6.06s, eta=0:8:27\n",
      "2022-04-13 16:21:41 [INFO]\t[TRAIN] Epoch=15/18, Step=16/21, loss_xy=289.999908, loss_wh=75.738831, loss_obj=294.452209, loss_cls=2.684560, loss=662.875488, lr=0.000125, time_each_step=6.13s, eta=0:7:31\n",
      "2022-04-13 16:22:18 [INFO]\t[TRAIN] Epoch 15 finished, loss_xy=277.46164, loss_wh=73.00457, loss_obj=295.96454, loss_cls=2.310046, loss=648.7408 .\n",
      "2022-04-13 16:22:18 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:22:19 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:22:24 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:22:25 [INFO]\t[EVAL] Finished, Epoch=15, bbox_map=59.913907 .\n",
      "2022-04-13 16:22:29 [INFO]\tModel saved in output/YOLO3_DARKNET53/best_model.\n",
      "2022-04-13 16:22:29 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_15, bbox_map=59.91390686796688\n",
      "2022-04-13 16:22:31 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_15.\n",
      "2022-04-13 16:23:08 [INFO]\t[TRAIN] Epoch=16/18, Step=5/21, loss_xy=233.806137, loss_wh=46.713989, loss_obj=292.384705, loss_cls=3.390273, loss=576.295105, lr=0.000125, time_each_step=7.39s, eta=0:7:31\n",
      "2022-04-13 16:24:01 [INFO]\t[TRAIN] Epoch=16/18, Step=15/21, loss_xy=265.238373, loss_wh=59.391167, loss_obj=327.053467, loss_cls=1.798627, loss=653.481628, lr=0.000125, time_each_step=5.31s, eta=0:4:37\n",
      "2022-04-13 16:24:34 [INFO]\t[TRAIN] Epoch 16 finished, loss_xy=289.41226, loss_wh=70.826065, loss_obj=307.05045, loss_cls=2.0422802, loss=669.33105 .\n",
      "2022-04-13 16:24:34 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:24:34 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:24:40 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:24:40 [INFO]\t[EVAL] Finished, Epoch=16, bbox_map=52.143455 .\n",
      "2022-04-13 16:24:40 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_15, bbox_map=59.91390686796688\n",
      "2022-04-13 16:24:42 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_16.\n",
      "2022-04-13 16:25:04 [INFO]\t[TRAIN] Epoch=17/18, Step=4/21, loss_xy=272.130707, loss_wh=57.331715, loss_obj=279.297638, loss_cls=1.414320, loss=610.174377, lr=0.000125, time_each_step=5.48s, eta=0:3:34\n",
      "2022-04-13 16:26:04 [INFO]\t[TRAIN] Epoch=17/18, Step=14/21, loss_xy=289.867981, loss_wh=66.212379, loss_obj=293.703766, loss_cls=1.510801, loss=651.294922, lr=0.000125, time_each_step=6.02s, eta=0:2:54\n",
      "2022-04-13 16:26:54 [INFO]\t[TRAIN] Epoch 17 finished, loss_xy=294.71368, loss_wh=69.47006, loss_obj=302.3893, loss_cls=1.6626558, loss=668.2357 .\n",
      "2022-04-13 16:26:54 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:26:55 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:27:01 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:27:01 [INFO]\t[EVAL] Finished, Epoch=17, bbox_map=40.042544 .\n",
      "2022-04-13 16:27:01 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_15, bbox_map=59.91390686796688\n",
      "2022-04-13 16:27:02 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_17.\n",
      "2022-04-13 16:27:23 [INFO]\t[TRAIN] Epoch=18/18, Step=3/21, loss_xy=289.699493, loss_wh=87.793808, loss_obj=274.005066, loss_cls=1.125930, loss=652.624268, lr=0.000125, time_each_step=7.06s, eta=0:2:7\n",
      "2022-04-13 16:28:21 [INFO]\t[TRAIN] Epoch=18/18, Step=13/21, loss_xy=392.001251, loss_wh=107.967453, loss_obj=432.759430, loss_cls=2.587618, loss=935.315796, lr=0.000125, time_each_step=5.74s, eta=0:0:45\n",
      "2022-04-13 16:29:10 [INFO]\t[TRAIN] Epoch 18 finished, loss_xy=289.81592, loss_wh=77.37038, loss_obj=289.37683, loss_cls=1.7171942, loss=658.2804 .\n",
      "2022-04-13 16:29:10 [WARNING]\tDetector only supports single card evaluation with batch_size=1 during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-04-13 16:29:10 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-04-13 16:29:16 [INFO]\tAccumulating evaluatation results...\n",
      "2022-04-13 16:29:16 [INFO]\t[EVAL] Finished, Epoch=18, bbox_map=55.454514 .\n",
      "2022-04-13 16:29:16 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_15, bbox_map=59.91390686796688\n",
      "2022-04-13 16:29:17 [INFO]\tModel saved in output/YOLO3_DARKNET53/epoch_18.\n"
     ]
    }
   ],
   "source": [
    "#更换网络重新训练\n",
    "num_classes = len(train_dataset.labels)\n",
    "model = pdx.det.YOLOv3(num_classes=num_classes, backbone='DarkNet53')\n",
    "model.train(\n",
    "    num_epochs=18,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=8,\n",
    "    eval_dataset=eval_dataset,\n",
    "    learning_rate=0.000125,\n",
    "    lr_decay_epochs=[210, 240],\n",
    "    save_dir='output/YOLO3_DARKNET53',\n",
    "    use_vdl=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T08:47:22.491422Z",
     "iopub.status.busy": "2022-04-13T08:47:22.490650Z",
     "iopub.status.idle": "2022-04-13T08:47:23.394229Z",
     "shell.execute_reply": "2022-04-13T08:47:23.393608Z",
     "shell.execute_reply.started": "2022-04-13T08:47:22.491387Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 16:47:23 [INFO]\tModel[YOLOv3] loaded.\n",
      "2022-04-13 16:47:23 [INFO]\tThe visualized result is saved at ./output/NEW_DF9DBCB9/visualize_DF9DBCB9.jpg\n"
     ]
    }
   ],
   "source": [
    "model = pdx.load_model('output/yolov3_DarkNet53/best_model')\n",
    "image_name = './data/dataset/JPEGImages/DF9DBCB9.jpg'\n",
    "result = model.predict(image_name)\n",
    "pdx.det.visualize(image_name, result, threshold=0.5,save_dir='./output/NEW_DF9DBCB9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/60ff2c3f3c5f452b956d672e794c91804d28a2b0894c42038d1a20cf8064c17e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T06:49:44.178637Z",
     "iopub.status.busy": "2022-04-14T06:49:44.178199Z",
     "iopub.status.idle": "2022-04-14T06:49:59.115793Z",
     "shell.execute_reply": "2022-04-14T06:49:59.114843Z",
     "shell.execute_reply.started": "2022-04-14T06:49:44.178603Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:136: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\n",
      "  \"Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04-14 14:49:45 MainThread @utils.py:79] WRN paddlepaddle version: 2.2.2. The dynamic graph version of PARL is under development, not fully tested and supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'posixpath' from '/opt/conda/envs/python35-paddle120-env/lib/python3.7/posixpath.py'>\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.50s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "--------------analyzing 1-rebar---------------\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "2022-04-14 14:49:57 [INFO]\t--------------saving 1-rebar---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if isinstance(obj, collections.Iterator):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return list(data) if isinstance(data, collections.MappingView) else data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-14 14:49:59 [INFO]\tThe analysis figures are saved in visualize/YOLO3_DARKNET53/ErrorAnay/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import paddlex as paddlex\n",
    "print(os.path)\n",
    "\n",
    "model_dir = './output/YOLO3_DARKNET53/best_model/'\n",
    "save_dir = 'visualize/YOLO3_DARKNET53/ErrorAnay/'\n",
    "if not osp.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "eval_details_file = osp.join(model_dir, 'eval_details.json') \n",
    "paddlex.det.coco_error_analysis(eval_details_file=eval_details_file, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/32c8caa064b34682b4de25b295bd2b9133e01ac6286d4b98873b72f2b1e8443a)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/deaa2cba06594e39becd560430ffe9c1dd84e56feefe4b77b2079634faed6164)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1a256d5399424f7394573395f81c97ba1d668becf07345abb1d671648fa2fbc2)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0474a91af6ab4a8fb57aa016565b8b46799498990b064b6688f8f10a75208305)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f33edf3fd49c47f490b74fce76707be684d96d8ab7b44ac79264e24f65be32f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
